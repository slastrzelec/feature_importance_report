2025-10-28 10:12:03,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:12:03,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:12:03,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:12:03,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:14:49,220:INFO:PyCaret ClassificationExperiment
2025-10-28 10:14:49,222:INFO:Logging name: clf-default-name
2025-10-28 10:14:49,222:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:14:49,222:INFO:version 3.3.2
2025-10-28 10:14:49,222:INFO:Initializing setup()
2025-10-28 10:14:49,222:INFO:self.USI: 01c8
2025-10-28 10:14:49,222:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:14:49,226:INFO:Checking environment
2025-10-28 10:14:49,227:INFO:python_version: 3.11.14
2025-10-28 10:14:49,227:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:14:49,227:INFO:machine: AMD64
2025-10-28 10:14:49,268:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:14:49,269:INFO:Memory: svmem(total=16788250624, available=5147144192, percent=69.3, used=11641106432, free=5147144192)
2025-10-28 10:14:49,269:INFO:Physical Core: 12
2025-10-28 10:14:49,269:INFO:Logical Core: 16
2025-10-28 10:14:49,269:INFO:Checking libraries
2025-10-28 10:14:49,269:INFO:System:
2025-10-28 10:14:49,269:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:14:49,269:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:14:49,269:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:14:49,269:INFO:PyCaret required dependencies:
2025-10-28 10:14:49,272:INFO:                 pip: 25.2
2025-10-28 10:14:49,272:INFO:          setuptools: 80.9.0
2025-10-28 10:14:49,273:INFO:             pycaret: 3.3.2
2025-10-28 10:14:49,273:INFO:             IPython: 9.6.0
2025-10-28 10:14:49,273:INFO:          ipywidgets: 8.1.7
2025-10-28 10:14:49,273:INFO:                tqdm: 4.67.1
2025-10-28 10:14:49,273:INFO:               numpy: 1.26.4
2025-10-28 10:14:49,273:INFO:              pandas: 2.1.4
2025-10-28 10:14:49,273:INFO:              jinja2: 3.1.6
2025-10-28 10:14:49,273:INFO:               scipy: 1.11.4
2025-10-28 10:14:49,273:INFO:              joblib: 1.3.2
2025-10-28 10:14:49,273:INFO:             sklearn: 1.4.2
2025-10-28 10:14:49,273:INFO:                pyod: 2.0.5
2025-10-28 10:14:49,273:INFO:            imblearn: 0.14.0
2025-10-28 10:14:49,273:INFO:   category_encoders: 2.7.0
2025-10-28 10:14:49,273:INFO:            lightgbm: 4.6.0
2025-10-28 10:14:49,273:INFO:               numba: 0.62.1
2025-10-28 10:14:49,273:INFO:            requests: 2.32.5
2025-10-28 10:14:49,273:INFO:          matplotlib: 3.10.7
2025-10-28 10:14:49,273:INFO:          scikitplot: 0.3.7
2025-10-28 10:14:49,274:INFO:         yellowbrick: 1.5
2025-10-28 10:14:49,274:INFO:              plotly: 6.3.1
2025-10-28 10:14:49,274:INFO:    plotly-resampler: Not installed
2025-10-28 10:14:49,274:INFO:             kaleido: 0.2.1
2025-10-28 10:14:49,274:INFO:           schemdraw: 0.15
2025-10-28 10:14:49,274:INFO:         statsmodels: 0.14.5
2025-10-28 10:14:49,274:INFO:              sktime: 0.26.0
2025-10-28 10:14:49,274:INFO:               tbats: 1.1.3
2025-10-28 10:14:49,274:INFO:            pmdarima: 2.0.4
2025-10-28 10:14:49,274:INFO:              psutil: 7.1.1
2025-10-28 10:14:49,274:INFO:          markupsafe: 3.0.3
2025-10-28 10:14:49,275:INFO:             pickle5: Not installed
2025-10-28 10:14:49,275:INFO:         cloudpickle: 3.1.1
2025-10-28 10:14:49,275:INFO:         deprecation: 2.1.0
2025-10-28 10:14:49,275:INFO:              xxhash: 3.6.0
2025-10-28 10:14:49,275:INFO:           wurlitzer: 3.1.1
2025-10-28 10:14:49,275:INFO:PyCaret optional dependencies:
2025-10-28 10:14:49,297:INFO:                shap: Not installed
2025-10-28 10:14:49,298:INFO:           interpret: Not installed
2025-10-28 10:14:49,298:INFO:                umap: 0.5.9.post2
2025-10-28 10:14:49,298:INFO:     ydata_profiling: Not installed
2025-10-28 10:14:49,298:INFO:  explainerdashboard: Not installed
2025-10-28 10:14:49,298:INFO:             autoviz: Not installed
2025-10-28 10:14:49,298:INFO:           fairlearn: Not installed
2025-10-28 10:14:49,298:INFO:          deepchecks: Not installed
2025-10-28 10:14:49,298:INFO:             xgboost: Not installed
2025-10-28 10:14:49,298:INFO:            catboost: Not installed
2025-10-28 10:14:49,298:INFO:              kmodes: Not installed
2025-10-28 10:14:49,298:INFO:             mlxtend: Not installed
2025-10-28 10:14:49,298:INFO:       statsforecast: Not installed
2025-10-28 10:14:49,298:INFO:        tune_sklearn: Not installed
2025-10-28 10:14:49,298:INFO:                 ray: Not installed
2025-10-28 10:14:49,298:INFO:            hyperopt: Not installed
2025-10-28 10:14:49,298:INFO:              optuna: Not installed
2025-10-28 10:14:49,298:INFO:               skopt: Not installed
2025-10-28 10:14:49,298:INFO:              mlflow: Not installed
2025-10-28 10:14:49,298:INFO:              gradio: Not installed
2025-10-28 10:14:49,298:INFO:             fastapi: Not installed
2025-10-28 10:14:49,298:INFO:             uvicorn: Not installed
2025-10-28 10:14:49,300:INFO:              m2cgen: Not installed
2025-10-28 10:14:49,300:INFO:           evidently: Not installed
2025-10-28 10:14:49,300:INFO:               fugue: Not installed
2025-10-28 10:14:49,300:INFO:           streamlit: 1.50.0
2025-10-28 10:14:49,300:INFO:             prophet: Not installed
2025-10-28 10:14:49,300:INFO:None
2025-10-28 10:14:49,300:INFO:Set up data.
2025-10-28 10:14:49,307:INFO:Set up folding strategy.
2025-10-28 10:14:49,307:INFO:Set up train/test split.
2025-10-28 10:14:49,320:INFO:Set up index.
2025-10-28 10:14:49,320:INFO:Assigning column types.
2025-10-28 10:14:49,325:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:14:49,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,410:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:14:49,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,978:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:50,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,015:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:14:50,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,221:INFO:Preparing preprocessing pipeline...
2025-10-28 10:14:50,222:INFO:Set up label encoding.
2025-10-28 10:14:50,222:INFO:Set up simple imputation.
2025-10-28 10:14:50,319:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:14:50,328:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:14:50,328:INFO:Creating final display dataframe.
2025-10-28 10:14:50,476:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               01c8
2025-10-28 10:14:50,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,668:INFO:setup() successfully completed in 1.47s...............
2025-10-28 10:15:01,000:INFO:PyCaret ClassificationExperiment
2025-10-28 10:15:01,001:INFO:Logging name: clf-default-name
2025-10-28 10:15:01,001:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:15:01,001:INFO:version 3.3.2
2025-10-28 10:15:01,001:INFO:Initializing setup()
2025-10-28 10:15:01,001:INFO:self.USI: f1e3
2025-10-28 10:15:01,001:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:15:01,001:INFO:Checking environment
2025-10-28 10:15:01,001:INFO:python_version: 3.11.14
2025-10-28 10:15:01,001:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:15:01,001:INFO:machine: AMD64
2025-10-28 10:15:01,001:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:15:01,001:INFO:Memory: svmem(total=16788250624, available=5319151616, percent=68.3, used=11469099008, free=5319151616)
2025-10-28 10:15:01,001:INFO:Physical Core: 12
2025-10-28 10:15:01,001:INFO:Logical Core: 16
2025-10-28 10:15:01,001:INFO:Checking libraries
2025-10-28 10:15:01,002:INFO:System:
2025-10-28 10:15:01,002:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:15:01,002:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:15:01,002:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:15:01,002:INFO:PyCaret required dependencies:
2025-10-28 10:15:01,002:INFO:                 pip: 25.2
2025-10-28 10:15:01,002:INFO:          setuptools: 80.9.0
2025-10-28 10:15:01,002:INFO:             pycaret: 3.3.2
2025-10-28 10:15:01,002:INFO:             IPython: 9.6.0
2025-10-28 10:15:01,002:INFO:          ipywidgets: 8.1.7
2025-10-28 10:15:01,002:INFO:                tqdm: 4.67.1
2025-10-28 10:15:01,002:INFO:               numpy: 1.26.4
2025-10-28 10:15:01,002:INFO:              pandas: 2.1.4
2025-10-28 10:15:01,002:INFO:              jinja2: 3.1.6
2025-10-28 10:15:01,002:INFO:               scipy: 1.11.4
2025-10-28 10:15:01,002:INFO:              joblib: 1.3.2
2025-10-28 10:15:01,002:INFO:             sklearn: 1.4.2
2025-10-28 10:15:01,002:INFO:                pyod: 2.0.5
2025-10-28 10:15:01,002:INFO:            imblearn: 0.14.0
2025-10-28 10:15:01,002:INFO:   category_encoders: 2.7.0
2025-10-28 10:15:01,002:INFO:            lightgbm: 4.6.0
2025-10-28 10:15:01,002:INFO:               numba: 0.62.1
2025-10-28 10:15:01,002:INFO:            requests: 2.32.5
2025-10-28 10:15:01,002:INFO:          matplotlib: 3.10.7
2025-10-28 10:15:01,002:INFO:          scikitplot: 0.3.7
2025-10-28 10:15:01,002:INFO:         yellowbrick: 1.5
2025-10-28 10:15:01,002:INFO:              plotly: 6.3.1
2025-10-28 10:15:01,002:INFO:    plotly-resampler: Not installed
2025-10-28 10:15:01,002:INFO:             kaleido: 0.2.1
2025-10-28 10:15:01,003:INFO:           schemdraw: 0.15
2025-10-28 10:15:01,003:INFO:         statsmodels: 0.14.5
2025-10-28 10:15:01,003:INFO:              sktime: 0.26.0
2025-10-28 10:15:01,003:INFO:               tbats: 1.1.3
2025-10-28 10:15:01,003:INFO:            pmdarima: 2.0.4
2025-10-28 10:15:01,003:INFO:              psutil: 7.1.1
2025-10-28 10:15:01,003:INFO:          markupsafe: 3.0.3
2025-10-28 10:15:01,003:INFO:             pickle5: Not installed
2025-10-28 10:15:01,003:INFO:         cloudpickle: 3.1.1
2025-10-28 10:15:01,003:INFO:         deprecation: 2.1.0
2025-10-28 10:15:01,003:INFO:              xxhash: 3.6.0
2025-10-28 10:15:01,003:INFO:           wurlitzer: 3.1.1
2025-10-28 10:15:01,003:INFO:PyCaret optional dependencies:
2025-10-28 10:15:01,003:INFO:                shap: Not installed
2025-10-28 10:15:01,003:INFO:           interpret: Not installed
2025-10-28 10:15:01,003:INFO:                umap: 0.5.9.post2
2025-10-28 10:15:01,003:INFO:     ydata_profiling: Not installed
2025-10-28 10:15:01,003:INFO:  explainerdashboard: Not installed
2025-10-28 10:15:01,003:INFO:             autoviz: Not installed
2025-10-28 10:15:01,003:INFO:           fairlearn: Not installed
2025-10-28 10:15:01,003:INFO:          deepchecks: Not installed
2025-10-28 10:15:01,003:INFO:             xgboost: Not installed
2025-10-28 10:15:01,003:INFO:            catboost: Not installed
2025-10-28 10:15:01,003:INFO:              kmodes: Not installed
2025-10-28 10:15:01,003:INFO:             mlxtend: Not installed
2025-10-28 10:15:01,003:INFO:       statsforecast: Not installed
2025-10-28 10:15:01,003:INFO:        tune_sklearn: Not installed
2025-10-28 10:15:01,003:INFO:                 ray: Not installed
2025-10-28 10:15:01,003:INFO:            hyperopt: Not installed
2025-10-28 10:15:01,004:INFO:              optuna: Not installed
2025-10-28 10:15:01,004:INFO:               skopt: Not installed
2025-10-28 10:15:01,004:INFO:              mlflow: Not installed
2025-10-28 10:15:01,004:INFO:              gradio: Not installed
2025-10-28 10:15:01,004:INFO:             fastapi: Not installed
2025-10-28 10:15:01,004:INFO:             uvicorn: Not installed
2025-10-28 10:15:01,004:INFO:              m2cgen: Not installed
2025-10-28 10:15:01,004:INFO:           evidently: Not installed
2025-10-28 10:15:01,004:INFO:               fugue: Not installed
2025-10-28 10:15:01,004:INFO:           streamlit: 1.50.0
2025-10-28 10:15:01,004:INFO:             prophet: Not installed
2025-10-28 10:15:01,004:INFO:None
2025-10-28 10:15:01,004:INFO:Set up data.
2025-10-28 10:15:01,007:INFO:Set up folding strategy.
2025-10-28 10:15:01,007:INFO:Set up train/test split.
2025-10-28 10:15:01,011:INFO:Set up index.
2025-10-28 10:15:01,011:INFO:Assigning column types.
2025-10-28 10:15:01,014:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:15:01,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,189:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:15:01,238:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,347:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:15:01,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,500:INFO:Preparing preprocessing pipeline...
2025-10-28 10:15:01,501:INFO:Set up label encoding.
2025-10-28 10:15:01,501:INFO:Set up simple imputation.
2025-10-28 10:15:01,527:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:15:01,530:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:15:01,530:INFO:Creating final display dataframe.
2025-10-28 10:15:01,616:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               f1e3
2025-10-28 10:15:01,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,775:INFO:setup() successfully completed in 0.78s...............
2025-10-28 10:15:25,030:INFO:PyCaret ClassificationExperiment
2025-10-28 10:15:25,030:INFO:Logging name: clf-default-name
2025-10-28 10:15:25,030:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:15:25,030:INFO:version 3.3.2
2025-10-28 10:15:25,030:INFO:Initializing setup()
2025-10-28 10:15:25,030:INFO:self.USI: 1386
2025-10-28 10:15:25,030:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:15:25,034:INFO:Checking environment
2025-10-28 10:15:25,034:INFO:python_version: 3.11.14
2025-10-28 10:15:25,034:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:15:25,034:INFO:machine: AMD64
2025-10-28 10:15:25,034:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:15:25,034:INFO:Memory: svmem(total=16788250624, available=5386625024, percent=67.9, used=11401625600, free=5386625024)
2025-10-28 10:15:25,034:INFO:Physical Core: 12
2025-10-28 10:15:25,034:INFO:Logical Core: 16
2025-10-28 10:15:25,034:INFO:Checking libraries
2025-10-28 10:15:25,034:INFO:System:
2025-10-28 10:15:25,034:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:15:25,034:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:15:25,034:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:15:25,034:INFO:PyCaret required dependencies:
2025-10-28 10:15:25,036:INFO:                 pip: 25.2
2025-10-28 10:15:25,036:INFO:          setuptools: 80.9.0
2025-10-28 10:15:25,036:INFO:             pycaret: 3.3.2
2025-10-28 10:15:25,036:INFO:             IPython: 9.6.0
2025-10-28 10:15:25,037:INFO:          ipywidgets: 8.1.7
2025-10-28 10:15:25,037:INFO:                tqdm: 4.67.1
2025-10-28 10:15:25,037:INFO:               numpy: 1.26.4
2025-10-28 10:15:25,037:INFO:              pandas: 2.1.4
2025-10-28 10:15:25,037:INFO:              jinja2: 3.1.6
2025-10-28 10:15:25,037:INFO:               scipy: 1.11.4
2025-10-28 10:15:25,037:INFO:              joblib: 1.3.2
2025-10-28 10:15:25,037:INFO:             sklearn: 1.4.2
2025-10-28 10:15:25,038:INFO:                pyod: 2.0.5
2025-10-28 10:15:25,038:INFO:            imblearn: 0.14.0
2025-10-28 10:15:25,038:INFO:   category_encoders: 2.7.0
2025-10-28 10:15:25,038:INFO:            lightgbm: 4.6.0
2025-10-28 10:15:25,038:INFO:               numba: 0.62.1
2025-10-28 10:15:25,038:INFO:            requests: 2.32.5
2025-10-28 10:15:25,038:INFO:          matplotlib: 3.10.7
2025-10-28 10:15:25,038:INFO:          scikitplot: 0.3.7
2025-10-28 10:15:25,038:INFO:         yellowbrick: 1.5
2025-10-28 10:15:25,038:INFO:              plotly: 6.3.1
2025-10-28 10:15:25,038:INFO:    plotly-resampler: Not installed
2025-10-28 10:15:25,038:INFO:             kaleido: 0.2.1
2025-10-28 10:15:25,038:INFO:           schemdraw: 0.15
2025-10-28 10:15:25,038:INFO:         statsmodels: 0.14.5
2025-10-28 10:15:25,038:INFO:              sktime: 0.26.0
2025-10-28 10:15:25,038:INFO:               tbats: 1.1.3
2025-10-28 10:15:25,039:INFO:            pmdarima: 2.0.4
2025-10-28 10:15:25,039:INFO:              psutil: 7.1.1
2025-10-28 10:15:25,040:INFO:          markupsafe: 3.0.3
2025-10-28 10:15:25,041:INFO:             pickle5: Not installed
2025-10-28 10:15:25,042:INFO:         cloudpickle: 3.1.1
2025-10-28 10:15:25,042:INFO:         deprecation: 2.1.0
2025-10-28 10:15:25,043:INFO:              xxhash: 3.6.0
2025-10-28 10:15:25,043:INFO:           wurlitzer: 3.1.1
2025-10-28 10:15:25,043:INFO:PyCaret optional dependencies:
2025-10-28 10:15:25,043:INFO:                shap: Not installed
2025-10-28 10:15:25,043:INFO:           interpret: Not installed
2025-10-28 10:15:25,043:INFO:                umap: 0.5.9.post2
2025-10-28 10:15:25,043:INFO:     ydata_profiling: Not installed
2025-10-28 10:15:25,043:INFO:  explainerdashboard: Not installed
2025-10-28 10:15:25,043:INFO:             autoviz: Not installed
2025-10-28 10:15:25,044:INFO:           fairlearn: Not installed
2025-10-28 10:15:25,044:INFO:          deepchecks: Not installed
2025-10-28 10:15:25,044:INFO:             xgboost: Not installed
2025-10-28 10:15:25,044:INFO:            catboost: Not installed
2025-10-28 10:15:25,044:INFO:              kmodes: Not installed
2025-10-28 10:15:25,044:INFO:             mlxtend: Not installed
2025-10-28 10:15:25,044:INFO:       statsforecast: Not installed
2025-10-28 10:15:25,045:INFO:        tune_sklearn: Not installed
2025-10-28 10:15:25,045:INFO:                 ray: Not installed
2025-10-28 10:15:25,045:INFO:            hyperopt: Not installed
2025-10-28 10:15:25,045:INFO:              optuna: Not installed
2025-10-28 10:15:25,045:INFO:               skopt: Not installed
2025-10-28 10:15:25,046:INFO:              mlflow: Not installed
2025-10-28 10:15:25,046:INFO:              gradio: Not installed
2025-10-28 10:15:25,046:INFO:             fastapi: Not installed
2025-10-28 10:15:25,047:INFO:             uvicorn: Not installed
2025-10-28 10:15:25,047:INFO:              m2cgen: Not installed
2025-10-28 10:15:25,047:INFO:           evidently: Not installed
2025-10-28 10:15:25,048:INFO:               fugue: Not installed
2025-10-28 10:15:25,048:INFO:           streamlit: 1.50.0
2025-10-28 10:15:25,048:INFO:             prophet: Not installed
2025-10-28 10:15:25,048:INFO:None
2025-10-28 10:15:25,048:INFO:Set up data.
2025-10-28 10:15:25,059:INFO:Set up folding strategy.
2025-10-28 10:15:25,060:INFO:Set up train/test split.
2025-10-28 10:25:05,085:INFO:PyCaret RegressionExperiment
2025-10-28 10:25:05,085:INFO:Logging name: reg-default-name
2025-10-28 10:25:05,085:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:25:05,085:INFO:version 3.3.2
2025-10-28 10:25:05,085:INFO:Initializing setup()
2025-10-28 10:25:05,089:INFO:self.USI: d46f
2025-10-28 10:25:05,089:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:25:05,089:INFO:Checking environment
2025-10-28 10:25:05,089:INFO:python_version: 3.11.14
2025-10-28 10:25:05,089:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:05,089:INFO:machine: AMD64
2025-10-28 10:25:05,089:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:05,090:INFO:Memory: svmem(total=16788250624, available=4029124608, percent=76.0, used=12759126016, free=4029124608)
2025-10-28 10:25:05,090:INFO:Physical Core: 12
2025-10-28 10:25:05,090:INFO:Logical Core: 16
2025-10-28 10:25:05,090:INFO:Checking libraries
2025-10-28 10:25:05,090:INFO:System:
2025-10-28 10:25:05,090:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:05,090:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:05,091:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:05,091:INFO:PyCaret required dependencies:
2025-10-28 10:25:05,091:INFO:                 pip: 25.2
2025-10-28 10:25:05,091:INFO:          setuptools: 80.9.0
2025-10-28 10:25:05,093:INFO:             pycaret: 3.3.2
2025-10-28 10:25:05,093:INFO:             IPython: 9.6.0
2025-10-28 10:25:05,093:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:05,093:INFO:                tqdm: 4.67.1
2025-10-28 10:25:05,093:INFO:               numpy: 1.26.4
2025-10-28 10:25:05,094:INFO:              pandas: 2.1.4
2025-10-28 10:25:05,094:INFO:              jinja2: 3.1.6
2025-10-28 10:25:05,094:INFO:               scipy: 1.11.4
2025-10-28 10:25:05,094:INFO:              joblib: 1.3.2
2025-10-28 10:25:05,094:INFO:             sklearn: 1.4.2
2025-10-28 10:25:05,094:INFO:                pyod: 2.0.5
2025-10-28 10:25:05,094:INFO:            imblearn: 0.14.0
2025-10-28 10:25:05,094:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:05,094:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:05,094:INFO:               numba: 0.62.1
2025-10-28 10:25:05,094:INFO:            requests: 2.32.5
2025-10-28 10:25:05,094:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:05,094:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:05,094:INFO:         yellowbrick: 1.5
2025-10-28 10:25:05,094:INFO:              plotly: 6.3.1
2025-10-28 10:25:05,096:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:05,096:INFO:             kaleido: 0.2.1
2025-10-28 10:25:05,096:INFO:           schemdraw: 0.15
2025-10-28 10:25:05,096:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:05,096:INFO:              sktime: 0.26.0
2025-10-28 10:25:05,096:INFO:               tbats: 1.1.3
2025-10-28 10:25:05,096:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:05,096:INFO:              psutil: 7.1.1
2025-10-28 10:25:05,096:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:05,096:INFO:             pickle5: Not installed
2025-10-28 10:25:05,096:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:05,096:INFO:         deprecation: 2.1.0
2025-10-28 10:25:05,096:INFO:              xxhash: 3.6.0
2025-10-28 10:25:05,096:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:05,096:INFO:PyCaret optional dependencies:
2025-10-28 10:25:05,096:INFO:                shap: Not installed
2025-10-28 10:25:05,096:INFO:           interpret: Not installed
2025-10-28 10:25:05,096:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:05,096:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:05,096:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:05,096:INFO:             autoviz: Not installed
2025-10-28 10:25:05,096:INFO:           fairlearn: Not installed
2025-10-28 10:25:05,096:INFO:          deepchecks: Not installed
2025-10-28 10:25:05,096:INFO:             xgboost: Not installed
2025-10-28 10:25:05,096:INFO:            catboost: Not installed
2025-10-28 10:25:05,096:INFO:              kmodes: Not installed
2025-10-28 10:25:05,096:INFO:             mlxtend: Not installed
2025-10-28 10:25:05,096:INFO:       statsforecast: Not installed
2025-10-28 10:25:05,100:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:05,100:INFO:                 ray: Not installed
2025-10-28 10:25:05,100:INFO:            hyperopt: Not installed
2025-10-28 10:25:05,100:INFO:              optuna: Not installed
2025-10-28 10:25:05,100:INFO:               skopt: Not installed
2025-10-28 10:25:05,100:INFO:              mlflow: Not installed
2025-10-28 10:25:05,101:INFO:              gradio: Not installed
2025-10-28 10:25:05,101:INFO:             fastapi: Not installed
2025-10-28 10:25:05,101:INFO:             uvicorn: Not installed
2025-10-28 10:25:05,101:INFO:              m2cgen: Not installed
2025-10-28 10:25:05,102:INFO:           evidently: Not installed
2025-10-28 10:25:05,102:INFO:               fugue: Not installed
2025-10-28 10:25:05,102:INFO:           streamlit: 1.50.0
2025-10-28 10:25:05,103:INFO:             prophet: Not installed
2025-10-28 10:25:05,103:INFO:None
2025-10-28 10:25:05,103:INFO:Set up data.
2025-10-28 10:25:05,119:INFO:Set up folding strategy.
2025-10-28 10:25:05,119:INFO:Set up train/test split.
2025-10-28 10:25:05,129:INFO:Set up index.
2025-10-28 10:25:05,130:INFO:Assigning column types.
2025-10-28 10:25:05,137:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:05,137:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,362:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,370:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,550:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:25:05,559:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,568:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,758:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,766:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,946:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:25:05,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,341:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:25:06,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,728:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:06,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:07,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,127:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:25:07,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,522:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:07,522:INFO:Set up simple imputation.
2025-10-28 10:25:07,526:INFO:Set up encoding of categorical features.
2025-10-28 10:25:07,527:INFO:Set up column name cleaning.
2025-10-28 10:25:07,650:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:07,663:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:25:07,663:INFO:Creating final display dataframe.
2025-10-28 10:25:07,988:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              d46f
2025-10-28 10:25:08,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,371:INFO:setup() successfully completed in 3.29s...............
2025-10-28 10:25:20,165:INFO:PyCaret RegressionExperiment
2025-10-28 10:25:20,165:INFO:Logging name: reg-default-name
2025-10-28 10:25:20,165:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:25:20,165:INFO:version 3.3.2
2025-10-28 10:25:20,165:INFO:Initializing setup()
2025-10-28 10:25:20,165:INFO:self.USI: e94c
2025-10-28 10:25:20,165:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:25:20,165:INFO:Checking environment
2025-10-28 10:25:20,165:INFO:python_version: 3.11.14
2025-10-28 10:25:20,165:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:20,165:INFO:machine: AMD64
2025-10-28 10:25:20,165:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:20,165:INFO:Memory: svmem(total=16788250624, available=4416757760, percent=73.7, used=12371492864, free=4416757760)
2025-10-28 10:25:20,165:INFO:Physical Core: 12
2025-10-28 10:25:20,165:INFO:Logical Core: 16
2025-10-28 10:25:20,165:INFO:Checking libraries
2025-10-28 10:25:20,165:INFO:System:
2025-10-28 10:25:20,165:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:20,165:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:20,165:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:20,165:INFO:PyCaret required dependencies:
2025-10-28 10:25:20,165:INFO:                 pip: 25.2
2025-10-28 10:25:20,165:INFO:          setuptools: 80.9.0
2025-10-28 10:25:20,165:INFO:             pycaret: 3.3.2
2025-10-28 10:25:20,165:INFO:             IPython: 9.6.0
2025-10-28 10:25:20,165:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:20,165:INFO:                tqdm: 4.67.1
2025-10-28 10:25:20,165:INFO:               numpy: 1.26.4
2025-10-28 10:25:20,165:INFO:              pandas: 2.1.4
2025-10-28 10:25:20,165:INFO:              jinja2: 3.1.6
2025-10-28 10:25:20,165:INFO:               scipy: 1.11.4
2025-10-28 10:25:20,165:INFO:              joblib: 1.3.2
2025-10-28 10:25:20,165:INFO:             sklearn: 1.4.2
2025-10-28 10:25:20,165:INFO:                pyod: 2.0.5
2025-10-28 10:25:20,165:INFO:            imblearn: 0.14.0
2025-10-28 10:25:20,165:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:20,165:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:20,171:INFO:               numba: 0.62.1
2025-10-28 10:25:20,171:INFO:            requests: 2.32.5
2025-10-28 10:25:20,171:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:20,171:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:20,171:INFO:         yellowbrick: 1.5
2025-10-28 10:25:20,171:INFO:              plotly: 6.3.1
2025-10-28 10:25:20,171:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:20,171:INFO:             kaleido: 0.2.1
2025-10-28 10:25:20,171:INFO:           schemdraw: 0.15
2025-10-28 10:25:20,171:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:20,171:INFO:              sktime: 0.26.0
2025-10-28 10:25:20,171:INFO:               tbats: 1.1.3
2025-10-28 10:25:20,171:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:20,171:INFO:              psutil: 7.1.1
2025-10-28 10:25:20,171:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:20,171:INFO:             pickle5: Not installed
2025-10-28 10:25:20,171:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:20,171:INFO:         deprecation: 2.1.0
2025-10-28 10:25:20,171:INFO:              xxhash: 3.6.0
2025-10-28 10:25:20,171:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:20,171:INFO:PyCaret optional dependencies:
2025-10-28 10:25:20,176:INFO:                shap: Not installed
2025-10-28 10:25:20,176:INFO:           interpret: Not installed
2025-10-28 10:25:20,176:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:20,176:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:20,176:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:20,176:INFO:             autoviz: Not installed
2025-10-28 10:25:20,176:INFO:           fairlearn: Not installed
2025-10-28 10:25:20,176:INFO:          deepchecks: Not installed
2025-10-28 10:25:20,176:INFO:             xgboost: Not installed
2025-10-28 10:25:20,176:INFO:            catboost: Not installed
2025-10-28 10:25:20,176:INFO:              kmodes: Not installed
2025-10-28 10:25:20,176:INFO:             mlxtend: Not installed
2025-10-28 10:25:20,176:INFO:       statsforecast: Not installed
2025-10-28 10:25:20,176:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:20,176:INFO:                 ray: Not installed
2025-10-28 10:25:20,176:INFO:            hyperopt: Not installed
2025-10-28 10:25:20,176:INFO:              optuna: Not installed
2025-10-28 10:25:20,176:INFO:               skopt: Not installed
2025-10-28 10:25:20,176:INFO:              mlflow: Not installed
2025-10-28 10:25:20,176:INFO:              gradio: Not installed
2025-10-28 10:25:20,179:INFO:             fastapi: Not installed
2025-10-28 10:25:20,179:INFO:             uvicorn: Not installed
2025-10-28 10:25:20,179:INFO:              m2cgen: Not installed
2025-10-28 10:25:20,179:INFO:           evidently: Not installed
2025-10-28 10:25:20,179:INFO:               fugue: Not installed
2025-10-28 10:25:20,179:INFO:           streamlit: 1.50.0
2025-10-28 10:25:20,179:INFO:             prophet: Not installed
2025-10-28 10:25:20,179:INFO:None
2025-10-28 10:25:20,179:INFO:Set up data.
2025-10-28 10:25:20,188:INFO:Set up folding strategy.
2025-10-28 10:25:20,188:INFO:Set up train/test split.
2025-10-28 10:25:20,198:INFO:Set up index.
2025-10-28 10:25:20,198:INFO:Assigning column types.
2025-10-28 10:25:20,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:20,204:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,212:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,220:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,320:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,399:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,406:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,590:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:25:20,598:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,857:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,865:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,048:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:25:21,064:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,440:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:25:21,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,823:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:21,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:22,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:22,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,203:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:25:22,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,617:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:22,617:INFO:Set up simple imputation.
2025-10-28 10:25:22,621:INFO:Set up encoding of categorical features.
2025-10-28 10:25:22,622:INFO:Set up column name cleaning.
2025-10-28 10:25:22,731:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:22,744:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:25:22,744:INFO:Creating final display dataframe.
2025-10-28 10:25:23,096:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              e94c
2025-10-28 10:25:23,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,506:INFO:setup() successfully completed in 3.35s...............
2025-10-28 10:25:35,381:INFO:PyCaret RegressionExperiment
2025-10-28 10:25:35,381:INFO:Logging name: reg-default-name
2025-10-28 10:25:35,381:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:25:35,381:INFO:version 3.3.2
2025-10-28 10:25:35,381:INFO:Initializing setup()
2025-10-28 10:25:35,381:INFO:self.USI: 7bd9
2025-10-28 10:25:35,381:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:25:35,381:INFO:Checking environment
2025-10-28 10:25:35,381:INFO:python_version: 3.11.14
2025-10-28 10:25:35,381:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:35,383:INFO:machine: AMD64
2025-10-28 10:25:35,383:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:35,383:INFO:Memory: svmem(total=16788250624, available=4392570880, percent=73.8, used=12395679744, free=4392570880)
2025-10-28 10:25:35,383:INFO:Physical Core: 12
2025-10-28 10:25:35,383:INFO:Logical Core: 16
2025-10-28 10:25:35,383:INFO:Checking libraries
2025-10-28 10:25:35,388:INFO:System:
2025-10-28 10:25:35,389:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:35,389:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:35,389:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:35,389:INFO:PyCaret required dependencies:
2025-10-28 10:25:35,389:INFO:                 pip: 25.2
2025-10-28 10:25:35,389:INFO:          setuptools: 80.9.0
2025-10-28 10:25:35,389:INFO:             pycaret: 3.3.2
2025-10-28 10:25:35,389:INFO:             IPython: 9.6.0
2025-10-28 10:25:35,389:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:35,389:INFO:                tqdm: 4.67.1
2025-10-28 10:25:35,389:INFO:               numpy: 1.26.4
2025-10-28 10:25:35,390:INFO:              pandas: 2.1.4
2025-10-28 10:25:35,390:INFO:              jinja2: 3.1.6
2025-10-28 10:25:35,390:INFO:               scipy: 1.11.4
2025-10-28 10:25:35,390:INFO:              joblib: 1.3.2
2025-10-28 10:25:35,390:INFO:             sklearn: 1.4.2
2025-10-28 10:25:35,390:INFO:                pyod: 2.0.5
2025-10-28 10:25:35,390:INFO:            imblearn: 0.14.0
2025-10-28 10:25:35,390:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:35,390:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:35,390:INFO:               numba: 0.62.1
2025-10-28 10:25:35,390:INFO:            requests: 2.32.5
2025-10-28 10:25:35,390:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:35,390:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:35,390:INFO:         yellowbrick: 1.5
2025-10-28 10:25:35,390:INFO:              plotly: 6.3.1
2025-10-28 10:25:35,392:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:35,392:INFO:             kaleido: 0.2.1
2025-10-28 10:25:35,392:INFO:           schemdraw: 0.15
2025-10-28 10:25:35,392:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:35,392:INFO:              sktime: 0.26.0
2025-10-28 10:25:35,392:INFO:               tbats: 1.1.3
2025-10-28 10:25:35,392:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:35,393:INFO:              psutil: 7.1.1
2025-10-28 10:25:35,394:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:35,395:INFO:             pickle5: Not installed
2025-10-28 10:25:35,395:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:35,395:INFO:         deprecation: 2.1.0
2025-10-28 10:25:35,395:INFO:              xxhash: 3.6.0
2025-10-28 10:25:35,395:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:35,395:INFO:PyCaret optional dependencies:
2025-10-28 10:25:35,396:INFO:                shap: Not installed
2025-10-28 10:25:35,396:INFO:           interpret: Not installed
2025-10-28 10:25:35,396:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:35,396:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:35,396:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:35,396:INFO:             autoviz: Not installed
2025-10-28 10:25:35,396:INFO:           fairlearn: Not installed
2025-10-28 10:25:35,396:INFO:          deepchecks: Not installed
2025-10-28 10:25:35,396:INFO:             xgboost: Not installed
2025-10-28 10:25:35,396:INFO:            catboost: Not installed
2025-10-28 10:25:35,396:INFO:              kmodes: Not installed
2025-10-28 10:25:35,397:INFO:             mlxtend: Not installed
2025-10-28 10:25:35,397:INFO:       statsforecast: Not installed
2025-10-28 10:25:35,397:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:35,397:INFO:                 ray: Not installed
2025-10-28 10:25:35,398:INFO:            hyperopt: Not installed
2025-10-28 10:25:35,398:INFO:              optuna: Not installed
2025-10-28 10:25:35,398:INFO:               skopt: Not installed
2025-10-28 10:25:35,398:INFO:              mlflow: Not installed
2025-10-28 10:25:35,398:INFO:              gradio: Not installed
2025-10-28 10:25:35,398:INFO:             fastapi: Not installed
2025-10-28 10:25:35,398:INFO:             uvicorn: Not installed
2025-10-28 10:25:35,398:INFO:              m2cgen: Not installed
2025-10-28 10:25:35,398:INFO:           evidently: Not installed
2025-10-28 10:25:35,398:INFO:               fugue: Not installed
2025-10-28 10:25:35,398:INFO:           streamlit: 1.50.0
2025-10-28 10:25:35,398:INFO:             prophet: Not installed
2025-10-28 10:25:35,398:INFO:None
2025-10-28 10:25:35,399:INFO:Set up data.
2025-10-28 10:25:35,407:INFO:Set up folding strategy.
2025-10-28 10:25:35,407:INFO:Set up train/test split.
2025-10-28 10:25:35,413:INFO:Set up index.
2025-10-28 10:25:35,414:INFO:Assigning column types.
2025-10-28 10:25:35,420:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:35,420:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,435:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,612:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,619:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,805:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:25:35,814:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,821:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,924:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,015:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,207:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:25:36,223:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,608:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:25:36,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,003:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:37,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,388:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:25:37,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,785:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:37,785:INFO:Set up simple imputation.
2025-10-28 10:25:37,789:INFO:Set up encoding of categorical features.
2025-10-28 10:25:37,866:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:37,880:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal_width', 'petal_length',
                                             'petal_width'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['species'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['species'],
                                    transformer=OneHotEncoder(cols=['species'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-10-28 10:25:37,881:INFO:Creating final display dataframe.
2025-10-28 10:25:38,156:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      sepal_length
2                   Target type        Regression
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 7)
5   Transformed train set shape          (105, 7)
6    Transformed test set shape           (45, 7)
7              Numeric features                 3
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              7bd9
2025-10-28 10:25:38,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,549:INFO:setup() successfully completed in 3.18s...............
2025-10-28 10:25:41,511:INFO:PyCaret ClassificationExperiment
2025-10-28 10:25:41,511:INFO:Logging name: clf-default-name
2025-10-28 10:25:41,511:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:25:41,511:INFO:version 3.3.2
2025-10-28 10:25:41,515:INFO:Initializing setup()
2025-10-28 10:25:41,515:INFO:self.USI: 6a64
2025-10-28 10:25:41,515:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:25:41,515:INFO:Checking environment
2025-10-28 10:25:41,517:INFO:python_version: 3.11.14
2025-10-28 10:25:41,517:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:41,517:INFO:machine: AMD64
2025-10-28 10:25:41,517:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:41,517:INFO:Memory: svmem(total=16788250624, available=4360937472, percent=74.0, used=12427313152, free=4360937472)
2025-10-28 10:25:41,519:INFO:Physical Core: 12
2025-10-28 10:25:41,519:INFO:Logical Core: 16
2025-10-28 10:25:41,519:INFO:Checking libraries
2025-10-28 10:25:41,519:INFO:System:
2025-10-28 10:25:41,519:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:41,519:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:41,519:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:41,519:INFO:PyCaret required dependencies:
2025-10-28 10:25:41,520:INFO:                 pip: 25.2
2025-10-28 10:25:41,520:INFO:          setuptools: 80.9.0
2025-10-28 10:25:41,520:INFO:             pycaret: 3.3.2
2025-10-28 10:25:41,520:INFO:             IPython: 9.6.0
2025-10-28 10:25:41,520:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:41,520:INFO:                tqdm: 4.67.1
2025-10-28 10:25:41,520:INFO:               numpy: 1.26.4
2025-10-28 10:25:41,520:INFO:              pandas: 2.1.4
2025-10-28 10:25:41,520:INFO:              jinja2: 3.1.6
2025-10-28 10:25:41,520:INFO:               scipy: 1.11.4
2025-10-28 10:25:41,520:INFO:              joblib: 1.3.2
2025-10-28 10:25:41,520:INFO:             sklearn: 1.4.2
2025-10-28 10:25:41,521:INFO:                pyod: 2.0.5
2025-10-28 10:25:41,521:INFO:            imblearn: 0.14.0
2025-10-28 10:25:41,521:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:41,521:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:41,521:INFO:               numba: 0.62.1
2025-10-28 10:25:41,521:INFO:            requests: 2.32.5
2025-10-28 10:25:41,521:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:41,521:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:41,521:INFO:         yellowbrick: 1.5
2025-10-28 10:25:41,521:INFO:              plotly: 6.3.1
2025-10-28 10:25:41,521:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:41,521:INFO:             kaleido: 0.2.1
2025-10-28 10:25:41,521:INFO:           schemdraw: 0.15
2025-10-28 10:25:41,521:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:41,521:INFO:              sktime: 0.26.0
2025-10-28 10:25:41,521:INFO:               tbats: 1.1.3
2025-10-28 10:25:41,522:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:41,522:INFO:              psutil: 7.1.1
2025-10-28 10:25:41,522:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:41,522:INFO:             pickle5: Not installed
2025-10-28 10:25:41,522:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:41,522:INFO:         deprecation: 2.1.0
2025-10-28 10:25:41,522:INFO:              xxhash: 3.6.0
2025-10-28 10:25:41,522:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:41,522:INFO:PyCaret optional dependencies:
2025-10-28 10:25:41,522:INFO:                shap: Not installed
2025-10-28 10:25:41,522:INFO:           interpret: Not installed
2025-10-28 10:25:41,522:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:41,522:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:41,522:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:41,522:INFO:             autoviz: Not installed
2025-10-28 10:25:41,522:INFO:           fairlearn: Not installed
2025-10-28 10:25:41,522:INFO:          deepchecks: Not installed
2025-10-28 10:25:41,523:INFO:             xgboost: Not installed
2025-10-28 10:25:41,523:INFO:            catboost: Not installed
2025-10-28 10:25:41,523:INFO:              kmodes: Not installed
2025-10-28 10:25:41,523:INFO:             mlxtend: Not installed
2025-10-28 10:25:41,524:INFO:       statsforecast: Not installed
2025-10-28 10:25:41,524:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:41,524:INFO:                 ray: Not installed
2025-10-28 10:25:41,524:INFO:            hyperopt: Not installed
2025-10-28 10:25:41,525:INFO:              optuna: Not installed
2025-10-28 10:25:41,525:INFO:               skopt: Not installed
2025-10-28 10:25:41,525:INFO:              mlflow: Not installed
2025-10-28 10:25:41,525:INFO:              gradio: Not installed
2025-10-28 10:25:41,525:INFO:             fastapi: Not installed
2025-10-28 10:25:41,526:INFO:             uvicorn: Not installed
2025-10-28 10:25:41,526:INFO:              m2cgen: Not installed
2025-10-28 10:25:41,526:INFO:           evidently: Not installed
2025-10-28 10:25:41,526:INFO:               fugue: Not installed
2025-10-28 10:25:41,526:INFO:           streamlit: 1.50.0
2025-10-28 10:25:41,526:INFO:             prophet: Not installed
2025-10-28 10:25:41,526:INFO:None
2025-10-28 10:25:41,527:INFO:Set up data.
2025-10-28 10:25:41,534:INFO:Set up folding strategy.
2025-10-28 10:25:41,535:INFO:Set up train/test split.
2025-10-28 10:25:41,543:INFO:Set up index.
2025-10-28 10:25:41,544:INFO:Assigning column types.
2025-10-28 10:25:41,551:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:41,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:41,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,073:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:42,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,133:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:25:42,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,446:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:42,448:INFO:Set up label encoding.
2025-10-28 10:25:42,448:INFO:Set up simple imputation.
2025-10-28 10:25:42,497:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:42,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:25:42,505:INFO:Creating final display dataframe.
2025-10-28 10:25:42,684:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               6a64
2025-10-28 10:25:42,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:43,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:43,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:43,046:INFO:setup() successfully completed in 1.55s...............
2025-10-28 10:26:44,745:INFO:PyCaret ClassificationExperiment
2025-10-28 10:26:44,745:INFO:Logging name: clf-default-name
2025-10-28 10:26:44,747:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:26:44,747:INFO:version 3.3.2
2025-10-28 10:26:44,747:INFO:Initializing setup()
2025-10-28 10:26:44,750:INFO:self.USI: 9f13
2025-10-28 10:26:44,750:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:26:44,750:INFO:Checking environment
2025-10-28 10:26:44,750:INFO:python_version: 3.11.14
2025-10-28 10:26:44,751:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:26:44,753:INFO:machine: AMD64
2025-10-28 10:26:44,753:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:26:44,753:INFO:Memory: svmem(total=16788250624, available=4344684544, percent=74.1, used=12443566080, free=4344684544)
2025-10-28 10:26:44,753:INFO:Physical Core: 12
2025-10-28 10:26:44,753:INFO:Logical Core: 16
2025-10-28 10:26:44,763:INFO:Checking libraries
2025-10-28 10:26:44,764:INFO:System:
2025-10-28 10:26:44,764:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:26:44,764:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:26:44,765:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:26:44,766:INFO:PyCaret required dependencies:
2025-10-28 10:26:44,768:INFO:                 pip: 25.2
2025-10-28 10:26:44,768:INFO:          setuptools: 80.9.0
2025-10-28 10:26:44,769:INFO:             pycaret: 3.3.2
2025-10-28 10:26:44,769:INFO:             IPython: 9.6.0
2025-10-28 10:26:44,769:INFO:          ipywidgets: 8.1.7
2025-10-28 10:26:44,769:INFO:                tqdm: 4.67.1
2025-10-28 10:26:44,769:INFO:               numpy: 1.26.4
2025-10-28 10:26:44,769:INFO:              pandas: 2.1.4
2025-10-28 10:26:44,769:INFO:              jinja2: 3.1.6
2025-10-28 10:26:44,769:INFO:               scipy: 1.11.4
2025-10-28 10:26:44,770:INFO:              joblib: 1.3.2
2025-10-28 10:26:44,770:INFO:             sklearn: 1.4.2
2025-10-28 10:26:44,770:INFO:                pyod: 2.0.5
2025-10-28 10:26:44,770:INFO:            imblearn: 0.14.0
2025-10-28 10:26:44,770:INFO:   category_encoders: 2.7.0
2025-10-28 10:26:44,770:INFO:            lightgbm: 4.6.0
2025-10-28 10:26:44,770:INFO:               numba: 0.62.1
2025-10-28 10:26:44,771:INFO:            requests: 2.32.5
2025-10-28 10:26:44,771:INFO:          matplotlib: 3.10.7
2025-10-28 10:26:44,771:INFO:          scikitplot: 0.3.7
2025-10-28 10:26:44,771:INFO:         yellowbrick: 1.5
2025-10-28 10:26:44,771:INFO:              plotly: 6.3.1
2025-10-28 10:26:44,771:INFO:    plotly-resampler: Not installed
2025-10-28 10:26:44,771:INFO:             kaleido: 0.2.1
2025-10-28 10:26:44,771:INFO:           schemdraw: 0.15
2025-10-28 10:26:44,771:INFO:         statsmodels: 0.14.5
2025-10-28 10:26:44,771:INFO:              sktime: 0.26.0
2025-10-28 10:26:44,771:INFO:               tbats: 1.1.3
2025-10-28 10:26:44,772:INFO:            pmdarima: 2.0.4
2025-10-28 10:26:44,772:INFO:              psutil: 7.1.1
2025-10-28 10:26:44,772:INFO:          markupsafe: 3.0.3
2025-10-28 10:26:44,772:INFO:             pickle5: Not installed
2025-10-28 10:26:44,772:INFO:         cloudpickle: 3.1.1
2025-10-28 10:26:44,772:INFO:         deprecation: 2.1.0
2025-10-28 10:26:44,772:INFO:              xxhash: 3.6.0
2025-10-28 10:26:44,772:INFO:           wurlitzer: 3.1.1
2025-10-28 10:26:44,772:INFO:PyCaret optional dependencies:
2025-10-28 10:26:44,772:INFO:                shap: Not installed
2025-10-28 10:26:44,772:INFO:           interpret: Not installed
2025-10-28 10:26:44,772:INFO:                umap: 0.5.9.post2
2025-10-28 10:26:44,772:INFO:     ydata_profiling: Not installed
2025-10-28 10:26:44,773:INFO:  explainerdashboard: Not installed
2025-10-28 10:26:44,773:INFO:             autoviz: Not installed
2025-10-28 10:26:44,773:INFO:           fairlearn: Not installed
2025-10-28 10:26:44,774:INFO:          deepchecks: Not installed
2025-10-28 10:26:44,774:INFO:             xgboost: Not installed
2025-10-28 10:26:44,774:INFO:            catboost: Not installed
2025-10-28 10:26:44,774:INFO:              kmodes: Not installed
2025-10-28 10:26:44,774:INFO:             mlxtend: Not installed
2025-10-28 10:26:44,774:INFO:       statsforecast: Not installed
2025-10-28 10:26:44,774:INFO:        tune_sklearn: Not installed
2025-10-28 10:26:44,774:INFO:                 ray: Not installed
2025-10-28 10:26:44,774:INFO:            hyperopt: Not installed
2025-10-28 10:26:44,774:INFO:              optuna: Not installed
2025-10-28 10:26:44,774:INFO:               skopt: Not installed
2025-10-28 10:26:44,774:INFO:              mlflow: Not installed
2025-10-28 10:26:44,774:INFO:              gradio: Not installed
2025-10-28 10:26:44,774:INFO:             fastapi: Not installed
2025-10-28 10:26:44,775:INFO:             uvicorn: Not installed
2025-10-28 10:26:44,775:INFO:              m2cgen: Not installed
2025-10-28 10:26:44,775:INFO:           evidently: Not installed
2025-10-28 10:26:44,776:INFO:               fugue: Not installed
2025-10-28 10:26:44,777:INFO:           streamlit: 1.50.0
2025-10-28 10:26:44,777:INFO:             prophet: Not installed
2025-10-28 10:26:44,777:INFO:None
2025-10-28 10:26:44,777:INFO:Set up data.
2025-10-28 10:26:44,787:INFO:Set up folding strategy.
2025-10-28 10:26:44,787:INFO:Set up train/test split.
2025-10-28 10:26:44,794:INFO:Set up index.
2025-10-28 10:26:44,795:INFO:Assigning column types.
2025-10-28 10:26:44,801:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:26:44,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:26:44,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:44,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:44,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:26:45,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,493:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:26:45,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,886:INFO:Preparing preprocessing pipeline...
2025-10-28 10:26:45,888:INFO:Set up label encoding.
2025-10-28 10:26:45,888:INFO:Set up simple imputation.
2025-10-28 10:26:45,943:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:26:45,953:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:26:45,953:INFO:Creating final display dataframe.
2025-10-28 10:26:46,129:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               9f13
2025-10-28 10:26:46,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,398:INFO:setup() successfully completed in 1.66s...............
2025-10-28 10:27:32,655:INFO:PyCaret ClassificationExperiment
2025-10-28 10:27:32,655:INFO:Logging name: clf-default-name
2025-10-28 10:27:32,655:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:27:32,655:INFO:version 3.3.2
2025-10-28 10:27:32,655:INFO:Initializing setup()
2025-10-28 10:27:32,655:INFO:self.USI: 320c
2025-10-28 10:27:32,655:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:27:32,655:INFO:Checking environment
2025-10-28 10:27:32,655:INFO:python_version: 3.11.14
2025-10-28 10:27:32,655:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:27:32,655:INFO:machine: AMD64
2025-10-28 10:27:32,655:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:27:32,655:INFO:Memory: svmem(total=16788250624, available=4493541376, percent=73.2, used=12294709248, free=4493541376)
2025-10-28 10:27:32,655:INFO:Physical Core: 12
2025-10-28 10:27:32,655:INFO:Logical Core: 16
2025-10-28 10:27:32,655:INFO:Checking libraries
2025-10-28 10:27:32,655:INFO:System:
2025-10-28 10:27:32,655:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:27:32,655:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:27:32,655:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:27:32,655:INFO:PyCaret required dependencies:
2025-10-28 10:27:32,655:INFO:                 pip: 25.2
2025-10-28 10:27:32,655:INFO:          setuptools: 80.9.0
2025-10-28 10:27:32,655:INFO:             pycaret: 3.3.2
2025-10-28 10:27:32,655:INFO:             IPython: 9.6.0
2025-10-28 10:27:32,655:INFO:          ipywidgets: 8.1.7
2025-10-28 10:27:32,655:INFO:                tqdm: 4.67.1
2025-10-28 10:27:32,655:INFO:               numpy: 1.26.4
2025-10-28 10:27:32,655:INFO:              pandas: 2.1.4
2025-10-28 10:27:32,655:INFO:              jinja2: 3.1.6
2025-10-28 10:27:32,655:INFO:               scipy: 1.11.4
2025-10-28 10:27:32,655:INFO:              joblib: 1.3.2
2025-10-28 10:27:32,655:INFO:             sklearn: 1.4.2
2025-10-28 10:27:32,655:INFO:                pyod: 2.0.5
2025-10-28 10:27:32,655:INFO:            imblearn: 0.14.0
2025-10-28 10:27:32,655:INFO:   category_encoders: 2.7.0
2025-10-28 10:27:32,655:INFO:            lightgbm: 4.6.0
2025-10-28 10:27:32,655:INFO:               numba: 0.62.1
2025-10-28 10:27:32,655:INFO:            requests: 2.32.5
2025-10-28 10:27:32,655:INFO:          matplotlib: 3.10.7
2025-10-28 10:27:32,655:INFO:          scikitplot: 0.3.7
2025-10-28 10:27:32,655:INFO:         yellowbrick: 1.5
2025-10-28 10:27:32,655:INFO:              plotly: 6.3.1
2025-10-28 10:27:32,655:INFO:    plotly-resampler: Not installed
2025-10-28 10:27:32,655:INFO:             kaleido: 0.2.1
2025-10-28 10:27:32,655:INFO:           schemdraw: 0.15
2025-10-28 10:27:32,655:INFO:         statsmodels: 0.14.5
2025-10-28 10:27:32,655:INFO:              sktime: 0.26.0
2025-10-28 10:27:32,655:INFO:               tbats: 1.1.3
2025-10-28 10:27:32,655:INFO:            pmdarima: 2.0.4
2025-10-28 10:27:32,655:INFO:              psutil: 7.1.1
2025-10-28 10:27:32,655:INFO:          markupsafe: 3.0.3
2025-10-28 10:27:32,655:INFO:             pickle5: Not installed
2025-10-28 10:27:32,655:INFO:         cloudpickle: 3.1.1
2025-10-28 10:27:32,655:INFO:         deprecation: 2.1.0
2025-10-28 10:27:32,655:INFO:              xxhash: 3.6.0
2025-10-28 10:27:32,655:INFO:           wurlitzer: 3.1.1
2025-10-28 10:27:32,655:INFO:PyCaret optional dependencies:
2025-10-28 10:27:32,655:INFO:                shap: Not installed
2025-10-28 10:27:32,655:INFO:           interpret: Not installed
2025-10-28 10:27:32,655:INFO:                umap: 0.5.9.post2
2025-10-28 10:27:32,655:INFO:     ydata_profiling: Not installed
2025-10-28 10:27:32,655:INFO:  explainerdashboard: Not installed
2025-10-28 10:27:32,655:INFO:             autoviz: Not installed
2025-10-28 10:27:32,660:INFO:           fairlearn: Not installed
2025-10-28 10:27:32,660:INFO:          deepchecks: Not installed
2025-10-28 10:27:32,660:INFO:             xgboost: Not installed
2025-10-28 10:27:32,660:INFO:            catboost: Not installed
2025-10-28 10:27:32,660:INFO:              kmodes: Not installed
2025-10-28 10:27:32,660:INFO:             mlxtend: Not installed
2025-10-28 10:27:32,660:INFO:       statsforecast: Not installed
2025-10-28 10:27:32,660:INFO:        tune_sklearn: Not installed
2025-10-28 10:27:32,660:INFO:                 ray: Not installed
2025-10-28 10:27:32,660:INFO:            hyperopt: Not installed
2025-10-28 10:27:32,660:INFO:              optuna: Not installed
2025-10-28 10:27:32,660:INFO:               skopt: Not installed
2025-10-28 10:27:32,660:INFO:              mlflow: Not installed
2025-10-28 10:27:32,660:INFO:              gradio: Not installed
2025-10-28 10:27:32,660:INFO:             fastapi: Not installed
2025-10-28 10:27:32,660:INFO:             uvicorn: Not installed
2025-10-28 10:27:32,660:INFO:              m2cgen: Not installed
2025-10-28 10:27:32,660:INFO:           evidently: Not installed
2025-10-28 10:27:32,660:INFO:               fugue: Not installed
2025-10-28 10:27:32,660:INFO:           streamlit: 1.50.0
2025-10-28 10:27:32,660:INFO:             prophet: Not installed
2025-10-28 10:27:32,660:INFO:None
2025-10-28 10:27:32,660:INFO:Set up data.
2025-10-28 10:27:32,665:INFO:Set up folding strategy.
2025-10-28 10:27:32,665:INFO:Set up train/test split.
2025-10-28 10:27:32,672:INFO:Set up index.
2025-10-28 10:27:32,672:INFO:Assigning column types.
2025-10-28 10:27:32,676:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:27:32,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,848:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:27:32,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:33,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,040:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:27:33,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,205:INFO:Preparing preprocessing pipeline...
2025-10-28 10:27:33,206:INFO:Set up label encoding.
2025-10-28 10:27:33,206:INFO:Set up simple imputation.
2025-10-28 10:27:33,244:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:27:33,249:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:27:33,249:INFO:Creating final display dataframe.
2025-10-28 10:27:33,336:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               320c
2025-10-28 10:27:33,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,523:INFO:setup() successfully completed in 0.87s...............
2025-10-28 10:31:08,850:INFO:PyCaret RegressionExperiment
2025-10-28 10:31:08,850:INFO:Logging name: reg-default-name
2025-10-28 10:31:08,850:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:31:08,850:INFO:version 3.3.2
2025-10-28 10:31:08,850:INFO:Initializing setup()
2025-10-28 10:31:08,850:INFO:self.USI: 69e1
2025-10-28 10:31:08,850:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:31:08,850:INFO:Checking environment
2025-10-28 10:31:08,852:INFO:python_version: 3.11.14
2025-10-28 10:31:08,852:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:31:08,852:INFO:machine: AMD64
2025-10-28 10:31:08,853:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:31:08,853:INFO:Memory: svmem(total=16788250624, available=3938975744, percent=76.5, used=12849274880, free=3938975744)
2025-10-28 10:31:08,853:INFO:Physical Core: 12
2025-10-28 10:31:08,853:INFO:Logical Core: 16
2025-10-28 10:31:08,853:INFO:Checking libraries
2025-10-28 10:31:08,853:INFO:System:
2025-10-28 10:31:08,861:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:31:08,862:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:31:08,863:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:31:08,866:INFO:PyCaret required dependencies:
2025-10-28 10:31:08,866:INFO:                 pip: 25.2
2025-10-28 10:31:08,866:INFO:          setuptools: 80.9.0
2025-10-28 10:31:08,866:INFO:             pycaret: 3.3.2
2025-10-28 10:31:08,866:INFO:             IPython: 9.6.0
2025-10-28 10:31:08,867:INFO:          ipywidgets: 8.1.7
2025-10-28 10:31:08,867:INFO:                tqdm: 4.67.1
2025-10-28 10:31:08,867:INFO:               numpy: 1.26.4
2025-10-28 10:31:08,868:INFO:              pandas: 2.1.4
2025-10-28 10:31:08,869:INFO:              jinja2: 3.1.6
2025-10-28 10:31:08,869:INFO:               scipy: 1.11.4
2025-10-28 10:31:08,870:INFO:              joblib: 1.3.2
2025-10-28 10:31:08,870:INFO:             sklearn: 1.4.2
2025-10-28 10:31:08,870:INFO:                pyod: 2.0.5
2025-10-28 10:31:08,870:INFO:            imblearn: 0.14.0
2025-10-28 10:31:08,871:INFO:   category_encoders: 2.7.0
2025-10-28 10:31:08,871:INFO:            lightgbm: 4.6.0
2025-10-28 10:31:08,871:INFO:               numba: 0.62.1
2025-10-28 10:31:08,874:INFO:            requests: 2.32.5
2025-10-28 10:31:08,876:INFO:          matplotlib: 3.10.7
2025-10-28 10:31:08,877:INFO:          scikitplot: 0.3.7
2025-10-28 10:31:08,877:INFO:         yellowbrick: 1.5
2025-10-28 10:31:08,878:INFO:              plotly: 6.3.1
2025-10-28 10:31:08,878:INFO:    plotly-resampler: Not installed
2025-10-28 10:31:08,879:INFO:             kaleido: 0.2.1
2025-10-28 10:31:08,879:INFO:           schemdraw: 0.15
2025-10-28 10:31:08,879:INFO:         statsmodels: 0.14.5
2025-10-28 10:31:08,879:INFO:              sktime: 0.26.0
2025-10-28 10:31:08,879:INFO:               tbats: 1.1.3
2025-10-28 10:31:08,880:INFO:            pmdarima: 2.0.4
2025-10-28 10:31:08,880:INFO:              psutil: 7.1.1
2025-10-28 10:31:08,881:INFO:          markupsafe: 3.0.3
2025-10-28 10:31:08,882:INFO:             pickle5: Not installed
2025-10-28 10:31:08,882:INFO:         cloudpickle: 3.1.1
2025-10-28 10:31:08,882:INFO:         deprecation: 2.1.0
2025-10-28 10:31:08,882:INFO:              xxhash: 3.6.0
2025-10-28 10:31:08,882:INFO:           wurlitzer: 3.1.1
2025-10-28 10:31:08,882:INFO:PyCaret optional dependencies:
2025-10-28 10:31:08,884:INFO:                shap: Not installed
2025-10-28 10:31:08,885:INFO:           interpret: Not installed
2025-10-28 10:31:08,886:INFO:                umap: 0.5.9.post2
2025-10-28 10:31:08,886:INFO:     ydata_profiling: Not installed
2025-10-28 10:31:08,887:INFO:  explainerdashboard: Not installed
2025-10-28 10:31:08,887:INFO:             autoviz: Not installed
2025-10-28 10:31:08,888:INFO:           fairlearn: Not installed
2025-10-28 10:31:08,888:INFO:          deepchecks: Not installed
2025-10-28 10:31:08,889:INFO:             xgboost: Not installed
2025-10-28 10:31:08,890:INFO:            catboost: Not installed
2025-10-28 10:31:08,890:INFO:              kmodes: Not installed
2025-10-28 10:31:08,891:INFO:             mlxtend: Not installed
2025-10-28 10:31:08,891:INFO:       statsforecast: Not installed
2025-10-28 10:31:08,891:INFO:        tune_sklearn: Not installed
2025-10-28 10:31:08,891:INFO:                 ray: Not installed
2025-10-28 10:31:08,891:INFO:            hyperopt: Not installed
2025-10-28 10:31:08,891:INFO:              optuna: Not installed
2025-10-28 10:31:08,891:INFO:               skopt: Not installed
2025-10-28 10:31:08,891:INFO:              mlflow: Not installed
2025-10-28 10:31:08,891:INFO:              gradio: Not installed
2025-10-28 10:31:08,891:INFO:             fastapi: Not installed
2025-10-28 10:31:08,891:INFO:             uvicorn: Not installed
2025-10-28 10:31:08,892:INFO:              m2cgen: Not installed
2025-10-28 10:31:08,892:INFO:           evidently: Not installed
2025-10-28 10:31:08,892:INFO:               fugue: Not installed
2025-10-28 10:31:08,892:INFO:           streamlit: 1.50.0
2025-10-28 10:31:08,892:INFO:             prophet: Not installed
2025-10-28 10:31:08,892:INFO:None
2025-10-28 10:31:08,892:INFO:Set up data.
2025-10-28 10:31:08,901:INFO:Set up folding strategy.
2025-10-28 10:31:08,901:INFO:Set up train/test split.
2025-10-28 10:31:08,909:INFO:Set up index.
2025-10-28 10:31:08,909:INFO:Assigning column types.
2025-10-28 10:31:08,916:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:31:08,916:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:31:08,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:08,934:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,130:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,146:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,336:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:31:09,346:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,355:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,804:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:31:09,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,234:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:31:10,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,563:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,643:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:31:10,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:11,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,054:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:31:11,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,670:INFO:Preparing preprocessing pipeline...
2025-10-28 10:31:11,670:INFO:Set up simple imputation.
2025-10-28 10:31:11,678:INFO:Set up encoding of categorical features.
2025-10-28 10:31:11,679:INFO:Set up column name cleaning.
2025-10-28 10:31:11,841:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:31:11,860:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:31:11,861:INFO:Creating final display dataframe.
2025-10-28 10:31:12,277:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              69e1
2025-10-28 10:31:12,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,877:INFO:setup() successfully completed in 4.03s...............
2025-10-28 10:50:43,212:INFO:PyCaret RegressionExperiment
2025-10-28 10:50:43,212:INFO:Logging name: reg-default-name
2025-10-28 10:50:43,212:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:50:43,212:INFO:version 3.3.2
2025-10-28 10:50:43,212:INFO:Initializing setup()
2025-10-28 10:50:43,212:INFO:self.USI: fd6b
2025-10-28 10:50:43,212:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:50:43,212:INFO:Checking environment
2025-10-28 10:50:43,212:INFO:python_version: 3.11.14
2025-10-28 10:50:43,212:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:50:43,212:INFO:machine: AMD64
2025-10-28 10:50:43,212:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:50:43,212:INFO:Memory: svmem(total=16788250624, available=3230248960, percent=80.8, used=13558001664, free=3230248960)
2025-10-28 10:50:43,212:INFO:Physical Core: 12
2025-10-28 10:50:43,212:INFO:Logical Core: 16
2025-10-28 10:50:43,212:INFO:Checking libraries
2025-10-28 10:50:43,212:INFO:System:
2025-10-28 10:50:43,212:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:50:43,212:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:50:43,212:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:50:43,212:INFO:PyCaret required dependencies:
2025-10-28 10:50:43,213:INFO:                 pip: 25.2
2025-10-28 10:50:43,213:INFO:          setuptools: 80.9.0
2025-10-28 10:50:43,213:INFO:             pycaret: 3.3.2
2025-10-28 10:50:43,213:INFO:             IPython: 9.6.0
2025-10-28 10:50:43,213:INFO:          ipywidgets: 8.1.7
2025-10-28 10:50:43,213:INFO:                tqdm: 4.67.1
2025-10-28 10:50:43,213:INFO:               numpy: 1.26.4
2025-10-28 10:50:43,213:INFO:              pandas: 2.1.4
2025-10-28 10:50:43,213:INFO:              jinja2: 3.1.6
2025-10-28 10:50:43,213:INFO:               scipy: 1.11.4
2025-10-28 10:50:43,213:INFO:              joblib: 1.3.2
2025-10-28 10:50:43,213:INFO:             sklearn: 1.4.2
2025-10-28 10:50:43,213:INFO:                pyod: 2.0.5
2025-10-28 10:50:43,213:INFO:            imblearn: 0.14.0
2025-10-28 10:50:43,213:INFO:   category_encoders: 2.7.0
2025-10-28 10:50:43,213:INFO:            lightgbm: 4.6.0
2025-10-28 10:50:43,213:INFO:               numba: 0.62.1
2025-10-28 10:50:43,213:INFO:            requests: 2.32.5
2025-10-28 10:50:43,213:INFO:          matplotlib: 3.10.7
2025-10-28 10:50:43,213:INFO:          scikitplot: 0.3.7
2025-10-28 10:50:43,213:INFO:         yellowbrick: 1.5
2025-10-28 10:50:43,213:INFO:              plotly: 6.3.1
2025-10-28 10:50:43,213:INFO:    plotly-resampler: Not installed
2025-10-28 10:50:43,213:INFO:             kaleido: 0.2.1
2025-10-28 10:50:43,213:INFO:           schemdraw: 0.15
2025-10-28 10:50:43,213:INFO:         statsmodels: 0.14.5
2025-10-28 10:50:43,213:INFO:              sktime: 0.26.0
2025-10-28 10:50:43,214:INFO:               tbats: 1.1.3
2025-10-28 10:50:43,214:INFO:            pmdarima: 2.0.4
2025-10-28 10:50:43,214:INFO:              psutil: 7.1.1
2025-10-28 10:50:43,214:INFO:          markupsafe: 3.0.3
2025-10-28 10:50:43,214:INFO:             pickle5: Not installed
2025-10-28 10:50:43,214:INFO:         cloudpickle: 3.1.1
2025-10-28 10:50:43,214:INFO:         deprecation: 2.1.0
2025-10-28 10:50:43,214:INFO:              xxhash: 3.6.0
2025-10-28 10:50:43,214:INFO:           wurlitzer: 3.1.1
2025-10-28 10:50:43,214:INFO:PyCaret optional dependencies:
2025-10-28 10:50:43,215:INFO:                shap: Not installed
2025-10-28 10:50:43,215:INFO:           interpret: Not installed
2025-10-28 10:50:43,216:INFO:                umap: 0.5.9.post2
2025-10-28 10:50:43,216:INFO:     ydata_profiling: Not installed
2025-10-28 10:50:43,216:INFO:  explainerdashboard: Not installed
2025-10-28 10:50:43,216:INFO:             autoviz: Not installed
2025-10-28 10:50:43,217:INFO:           fairlearn: Not installed
2025-10-28 10:50:43,217:INFO:          deepchecks: Not installed
2025-10-28 10:50:43,217:INFO:             xgboost: Not installed
2025-10-28 10:50:43,217:INFO:            catboost: Not installed
2025-10-28 10:50:43,217:INFO:              kmodes: Not installed
2025-10-28 10:50:43,217:INFO:             mlxtend: Not installed
2025-10-28 10:50:43,217:INFO:       statsforecast: Not installed
2025-10-28 10:50:43,217:INFO:        tune_sklearn: Not installed
2025-10-28 10:50:43,219:INFO:                 ray: Not installed
2025-10-28 10:50:43,219:INFO:            hyperopt: Not installed
2025-10-28 10:50:43,219:INFO:              optuna: Not installed
2025-10-28 10:50:43,219:INFO:               skopt: Not installed
2025-10-28 10:50:43,219:INFO:              mlflow: Not installed
2025-10-28 10:50:43,220:INFO:              gradio: Not installed
2025-10-28 10:50:43,220:INFO:             fastapi: Not installed
2025-10-28 10:50:43,220:INFO:             uvicorn: Not installed
2025-10-28 10:50:43,220:INFO:              m2cgen: Not installed
2025-10-28 10:50:43,220:INFO:           evidently: Not installed
2025-10-28 10:50:43,220:INFO:               fugue: Not installed
2025-10-28 10:50:43,220:INFO:           streamlit: 1.50.0
2025-10-28 10:50:43,221:INFO:             prophet: Not installed
2025-10-28 10:50:43,221:INFO:None
2025-10-28 10:50:43,221:INFO:Set up data.
2025-10-28 10:50:43,230:INFO:Set up folding strategy.
2025-10-28 10:50:43,230:INFO:Set up train/test split.
2025-10-28 10:50:43,237:INFO:Set up index.
2025-10-28 10:50:43,237:INFO:Assigning column types.
2025-10-28 10:50:43,243:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:50:43,244:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,259:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,509:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,517:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,524:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,649:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:50:43,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,831:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,846:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,980:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:50:43,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,237:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:50:44,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,643:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:50:44,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:45,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,049:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:50:45,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,391:INFO:Preparing preprocessing pipeline...
2025-10-28 10:50:45,391:INFO:Set up simple imputation.
2025-10-28 10:50:45,395:INFO:Set up encoding of categorical features.
2025-10-28 10:50:45,396:INFO:Set up column name cleaning.
2025-10-28 10:50:45,470:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:50:45,481:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:50:45,482:INFO:Creating final display dataframe.
2025-10-28 10:50:45,717:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              fd6b
2025-10-28 10:50:45,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:46,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:46,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:46,036:INFO:setup() successfully completed in 2.83s...............
2025-10-28 10:50:46,036:INFO:Initializing compare_models()
2025-10-28 10:50:46,036:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 10:50:46,036:INFO:Checking exceptions
2025-10-28 10:50:46,039:INFO:Preparing display monitor
2025-10-28 10:50:46,045:INFO:Initializing Linear Regression
2025-10-28 10:50:46,046:INFO:Total runtime is 1.694361368815104e-05 minutes
2025-10-28 10:50:46,046:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:46,047:INFO:Initializing create_model()
2025-10-28 10:50:46,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:46,047:INFO:Checking exceptions
2025-10-28 10:50:46,047:INFO:Importing libraries
2025-10-28 10:50:46,047:INFO:Copying training dataset
2025-10-28 10:50:46,052:INFO:Defining folds
2025-10-28 10:50:46,052:INFO:Declaring metric variables
2025-10-28 10:50:46,053:INFO:Importing untrained model
2025-10-28 10:50:46,053:INFO:Linear Regression Imported successfully
2025-10-28 10:50:46,054:INFO:Starting cross validation
2025-10-28 10:50:46,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:50,175:INFO:Calculating mean and std
2025-10-28 10:50:50,177:INFO:Creating metrics dataframe
2025-10-28 10:50:50,184:INFO:Uploading results into container
2025-10-28 10:50:50,185:INFO:Uploading model into container now
2025-10-28 10:50:50,186:INFO:_master_model_container: 1
2025-10-28 10:50:50,186:INFO:_display_container: 2
2025-10-28 10:50:50,187:INFO:LinearRegression(n_jobs=-1)
2025-10-28 10:50:50,187:INFO:create_model() successfully completed......................................
2025-10-28 10:50:50,370:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:50,370:INFO:Creating metrics dataframe
2025-10-28 10:50:50,374:INFO:Initializing Lasso Regression
2025-10-28 10:50:50,375:INFO:Total runtime is 0.07217872540156046 minutes
2025-10-28 10:50:50,375:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:50,375:INFO:Initializing create_model()
2025-10-28 10:50:50,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:50,376:INFO:Checking exceptions
2025-10-28 10:50:50,376:INFO:Importing libraries
2025-10-28 10:50:50,376:INFO:Copying training dataset
2025-10-28 10:50:50,384:INFO:Defining folds
2025-10-28 10:50:50,384:INFO:Declaring metric variables
2025-10-28 10:50:50,384:INFO:Importing untrained model
2025-10-28 10:50:50,385:INFO:Lasso Regression Imported successfully
2025-10-28 10:50:50,385:INFO:Starting cross validation
2025-10-28 10:50:50,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:53,329:INFO:Calculating mean and std
2025-10-28 10:50:53,331:INFO:Creating metrics dataframe
2025-10-28 10:50:53,336:INFO:Uploading results into container
2025-10-28 10:50:53,337:INFO:Uploading model into container now
2025-10-28 10:50:53,339:INFO:_master_model_container: 2
2025-10-28 10:50:53,339:INFO:_display_container: 2
2025-10-28 10:50:53,340:INFO:Lasso(random_state=123)
2025-10-28 10:50:53,340:INFO:create_model() successfully completed......................................
2025-10-28 10:50:53,487:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:53,487:INFO:Creating metrics dataframe
2025-10-28 10:50:53,495:INFO:Initializing Ridge Regression
2025-10-28 10:50:53,495:INFO:Total runtime is 0.12417167027791341 minutes
2025-10-28 10:50:53,496:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:53,496:INFO:Initializing create_model()
2025-10-28 10:50:53,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:53,496:INFO:Checking exceptions
2025-10-28 10:50:53,496:INFO:Importing libraries
2025-10-28 10:50:53,496:INFO:Copying training dataset
2025-10-28 10:50:53,513:INFO:Defining folds
2025-10-28 10:50:53,513:INFO:Declaring metric variables
2025-10-28 10:50:53,513:INFO:Importing untrained model
2025-10-28 10:50:53,514:INFO:Ridge Regression Imported successfully
2025-10-28 10:50:53,515:INFO:Starting cross validation
2025-10-28 10:50:53,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:53,659:INFO:Calculating mean and std
2025-10-28 10:50:53,661:INFO:Creating metrics dataframe
2025-10-28 10:50:53,664:INFO:Uploading results into container
2025-10-28 10:50:53,665:INFO:Uploading model into container now
2025-10-28 10:50:53,666:INFO:_master_model_container: 3
2025-10-28 10:50:53,666:INFO:_display_container: 2
2025-10-28 10:50:53,666:INFO:Ridge(random_state=123)
2025-10-28 10:50:53,666:INFO:create_model() successfully completed......................................
2025-10-28 10:50:53,819:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:53,820:INFO:Creating metrics dataframe
2025-10-28 10:50:53,827:INFO:Initializing Elastic Net
2025-10-28 10:50:53,827:INFO:Total runtime is 0.1297106186548869 minutes
2025-10-28 10:50:53,827:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:53,829:INFO:Initializing create_model()
2025-10-28 10:50:53,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:53,829:INFO:Checking exceptions
2025-10-28 10:50:53,830:INFO:Importing libraries
2025-10-28 10:50:53,831:INFO:Copying training dataset
2025-10-28 10:50:53,845:INFO:Defining folds
2025-10-28 10:50:53,846:INFO:Declaring metric variables
2025-10-28 10:50:53,846:INFO:Importing untrained model
2025-10-28 10:50:53,847:INFO:Elastic Net Imported successfully
2025-10-28 10:50:53,849:INFO:Starting cross validation
2025-10-28 10:50:53,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:53,960:INFO:Calculating mean and std
2025-10-28 10:50:53,961:INFO:Creating metrics dataframe
2025-10-28 10:50:53,965:INFO:Uploading results into container
2025-10-28 10:50:53,967:INFO:Uploading model into container now
2025-10-28 10:50:53,967:INFO:_master_model_container: 4
2025-10-28 10:50:53,967:INFO:_display_container: 2
2025-10-28 10:50:53,969:INFO:ElasticNet(random_state=123)
2025-10-28 10:50:53,969:INFO:create_model() successfully completed......................................
2025-10-28 10:50:54,097:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:54,097:INFO:Creating metrics dataframe
2025-10-28 10:50:54,102:INFO:Initializing Least Angle Regression
2025-10-28 10:50:54,103:INFO:Total runtime is 0.1343059857686361 minutes
2025-10-28 10:50:54,103:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:54,104:INFO:Initializing create_model()
2025-10-28 10:50:54,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:54,104:INFO:Checking exceptions
2025-10-28 10:50:54,104:INFO:Importing libraries
2025-10-28 10:50:54,104:INFO:Copying training dataset
2025-10-28 10:50:54,116:INFO:Defining folds
2025-10-28 10:50:54,116:INFO:Declaring metric variables
2025-10-28 10:50:54,117:INFO:Importing untrained model
2025-10-28 10:50:54,118:INFO:Least Angle Regression Imported successfully
2025-10-28 10:50:54,120:INFO:Starting cross validation
2025-10-28 10:50:54,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:54,369:INFO:Calculating mean and std
2025-10-28 10:50:54,370:INFO:Creating metrics dataframe
2025-10-28 10:50:54,372:INFO:Uploading results into container
2025-10-28 10:50:54,373:INFO:Uploading model into container now
2025-10-28 10:50:54,373:INFO:_master_model_container: 5
2025-10-28 10:50:54,374:INFO:_display_container: 2
2025-10-28 10:50:54,374:INFO:Lars(random_state=123)
2025-10-28 10:50:54,374:INFO:create_model() successfully completed......................................
2025-10-28 10:50:54,505:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:54,506:INFO:Creating metrics dataframe
2025-10-28 10:50:54,511:INFO:Initializing Lasso Least Angle Regression
2025-10-28 10:50:54,511:INFO:Total runtime is 0.1411040226618449 minutes
2025-10-28 10:50:54,511:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:54,511:INFO:Initializing create_model()
2025-10-28 10:50:54,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:54,511:INFO:Checking exceptions
2025-10-28 10:50:54,511:INFO:Importing libraries
2025-10-28 10:50:54,511:INFO:Copying training dataset
2025-10-28 10:50:54,518:INFO:Defining folds
2025-10-28 10:50:54,518:INFO:Declaring metric variables
2025-10-28 10:50:54,519:INFO:Importing untrained model
2025-10-28 10:50:54,519:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 10:50:54,519:INFO:Starting cross validation
2025-10-28 10:50:54,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:54,689:INFO:Calculating mean and std
2025-10-28 10:50:54,691:INFO:Creating metrics dataframe
2025-10-28 10:50:54,694:INFO:Uploading results into container
2025-10-28 10:50:54,695:INFO:Uploading model into container now
2025-10-28 10:50:54,696:INFO:_master_model_container: 6
2025-10-28 10:50:54,697:INFO:_display_container: 2
2025-10-28 10:50:54,697:INFO:LassoLars(random_state=123)
2025-10-28 10:50:54,697:INFO:create_model() successfully completed......................................
2025-10-28 10:50:54,851:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:54,851:INFO:Creating metrics dataframe
2025-10-28 10:50:54,857:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 10:50:54,857:INFO:Total runtime is 0.14687641461690268 minutes
2025-10-28 10:50:54,859:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:54,859:INFO:Initializing create_model()
2025-10-28 10:50:54,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:54,859:INFO:Checking exceptions
2025-10-28 10:50:54,859:INFO:Importing libraries
2025-10-28 10:50:54,860:INFO:Copying training dataset
2025-10-28 10:50:54,868:INFO:Defining folds
2025-10-28 10:50:54,868:INFO:Declaring metric variables
2025-10-28 10:50:54,868:INFO:Importing untrained model
2025-10-28 10:50:54,868:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 10:50:54,868:INFO:Starting cross validation
2025-10-28 10:50:54,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:55,031:INFO:Calculating mean and std
2025-10-28 10:50:55,033:INFO:Creating metrics dataframe
2025-10-28 10:50:55,035:INFO:Uploading results into container
2025-10-28 10:50:55,036:INFO:Uploading model into container now
2025-10-28 10:50:55,037:INFO:_master_model_container: 7
2025-10-28 10:50:55,037:INFO:_display_container: 2
2025-10-28 10:50:55,037:INFO:OrthogonalMatchingPursuit()
2025-10-28 10:50:55,037:INFO:create_model() successfully completed......................................
2025-10-28 10:50:55,159:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:55,159:INFO:Creating metrics dataframe
2025-10-28 10:50:55,163:INFO:Initializing Bayesian Ridge
2025-10-28 10:50:55,163:INFO:Total runtime is 0.1519800106684367 minutes
2025-10-28 10:50:55,164:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:55,164:INFO:Initializing create_model()
2025-10-28 10:50:55,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:55,164:INFO:Checking exceptions
2025-10-28 10:50:55,164:INFO:Importing libraries
2025-10-28 10:50:55,164:INFO:Copying training dataset
2025-10-28 10:50:55,177:INFO:Defining folds
2025-10-28 10:50:55,177:INFO:Declaring metric variables
2025-10-28 10:50:55,177:INFO:Importing untrained model
2025-10-28 10:50:55,178:INFO:Bayesian Ridge Imported successfully
2025-10-28 10:50:55,178:INFO:Starting cross validation
2025-10-28 10:50:55,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:55,414:INFO:Calculating mean and std
2025-10-28 10:50:55,415:INFO:Creating metrics dataframe
2025-10-28 10:50:55,417:INFO:Uploading results into container
2025-10-28 10:50:55,417:INFO:Uploading model into container now
2025-10-28 10:50:55,419:INFO:_master_model_container: 8
2025-10-28 10:50:55,419:INFO:_display_container: 2
2025-10-28 10:50:55,419:INFO:BayesianRidge()
2025-10-28 10:50:55,419:INFO:create_model() successfully completed......................................
2025-10-28 10:50:55,538:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:55,538:INFO:Creating metrics dataframe
2025-10-28 10:50:55,542:INFO:Initializing Passive Aggressive Regressor
2025-10-28 10:50:55,542:INFO:Total runtime is 0.1582977016766866 minutes
2025-10-28 10:50:55,543:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:55,543:INFO:Initializing create_model()
2025-10-28 10:50:55,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:55,543:INFO:Checking exceptions
2025-10-28 10:50:55,543:INFO:Importing libraries
2025-10-28 10:50:55,543:INFO:Copying training dataset
2025-10-28 10:50:55,552:INFO:Defining folds
2025-10-28 10:50:55,552:INFO:Declaring metric variables
2025-10-28 10:50:55,552:INFO:Importing untrained model
2025-10-28 10:50:55,552:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 10:50:55,553:INFO:Starting cross validation
2025-10-28 10:50:55,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:55,736:INFO:Calculating mean and std
2025-10-28 10:50:55,737:INFO:Creating metrics dataframe
2025-10-28 10:50:55,740:INFO:Uploading results into container
2025-10-28 10:50:55,740:INFO:Uploading model into container now
2025-10-28 10:50:55,741:INFO:_master_model_container: 9
2025-10-28 10:50:55,741:INFO:_display_container: 2
2025-10-28 10:50:55,741:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-28 10:50:55,741:INFO:create_model() successfully completed......................................
2025-10-28 10:50:55,867:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:55,869:INFO:Creating metrics dataframe
2025-10-28 10:50:55,875:INFO:Initializing Huber Regressor
2025-10-28 10:50:55,875:INFO:Total runtime is 0.1638387084007263 minutes
2025-10-28 10:50:55,876:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:55,876:INFO:Initializing create_model()
2025-10-28 10:50:55,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:55,877:INFO:Checking exceptions
2025-10-28 10:50:55,877:INFO:Importing libraries
2025-10-28 10:50:55,877:INFO:Copying training dataset
2025-10-28 10:50:55,882:INFO:Defining folds
2025-10-28 10:50:55,882:INFO:Declaring metric variables
2025-10-28 10:50:55,883:INFO:Importing untrained model
2025-10-28 10:50:55,883:INFO:Huber Regressor Imported successfully
2025-10-28 10:50:55,883:INFO:Starting cross validation
2025-10-28 10:50:55,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:56,013:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,017:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,017:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,029:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,036:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,045:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,047:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,052:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,062:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,089:INFO:Calculating mean and std
2025-10-28 10:50:56,090:INFO:Creating metrics dataframe
2025-10-28 10:50:56,093:INFO:Uploading results into container
2025-10-28 10:50:56,094:INFO:Uploading model into container now
2025-10-28 10:50:56,094:INFO:_master_model_container: 10
2025-10-28 10:50:56,094:INFO:_display_container: 2
2025-10-28 10:50:56,095:INFO:HuberRegressor()
2025-10-28 10:50:56,095:INFO:create_model() successfully completed......................................
2025-10-28 10:50:56,234:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:56,234:INFO:Creating metrics dataframe
2025-10-28 10:50:56,236:INFO:Initializing K Neighbors Regressor
2025-10-28 10:50:56,236:INFO:Total runtime is 0.16985756953557332 minutes
2025-10-28 10:50:56,236:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:56,236:INFO:Initializing create_model()
2025-10-28 10:50:56,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:56,236:INFO:Checking exceptions
2025-10-28 10:50:56,236:INFO:Importing libraries
2025-10-28 10:50:56,236:INFO:Copying training dataset
2025-10-28 10:50:56,242:INFO:Defining folds
2025-10-28 10:50:56,243:INFO:Declaring metric variables
2025-10-28 10:50:56,243:INFO:Importing untrained model
2025-10-28 10:50:56,243:INFO:K Neighbors Regressor Imported successfully
2025-10-28 10:50:56,243:INFO:Starting cross validation
2025-10-28 10:50:56,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:56,435:INFO:Calculating mean and std
2025-10-28 10:50:56,436:INFO:Creating metrics dataframe
2025-10-28 10:50:56,441:INFO:Uploading results into container
2025-10-28 10:50:56,442:INFO:Uploading model into container now
2025-10-28 10:50:56,443:INFO:_master_model_container: 11
2025-10-28 10:50:56,443:INFO:_display_container: 2
2025-10-28 10:50:56,444:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 10:50:56,444:INFO:create_model() successfully completed......................................
2025-10-28 10:50:56,595:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:56,595:INFO:Creating metrics dataframe
2025-10-28 10:50:56,600:INFO:Initializing Decision Tree Regressor
2025-10-28 10:50:56,600:INFO:Total runtime is 0.17593318223953247 minutes
2025-10-28 10:50:56,600:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:56,602:INFO:Initializing create_model()
2025-10-28 10:50:56,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:56,602:INFO:Checking exceptions
2025-10-28 10:50:56,602:INFO:Importing libraries
2025-10-28 10:50:56,602:INFO:Copying training dataset
2025-10-28 10:50:56,609:INFO:Defining folds
2025-10-28 10:50:56,609:INFO:Declaring metric variables
2025-10-28 10:50:56,609:INFO:Importing untrained model
2025-10-28 10:50:56,611:INFO:Decision Tree Regressor Imported successfully
2025-10-28 10:50:56,611:INFO:Starting cross validation
2025-10-28 10:50:56,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:56,777:INFO:Calculating mean and std
2025-10-28 10:50:56,778:INFO:Creating metrics dataframe
2025-10-28 10:50:56,782:INFO:Uploading results into container
2025-10-28 10:50:56,782:INFO:Uploading model into container now
2025-10-28 10:50:56,783:INFO:_master_model_container: 12
2025-10-28 10:50:56,783:INFO:_display_container: 2
2025-10-28 10:50:56,783:INFO:DecisionTreeRegressor(random_state=123)
2025-10-28 10:50:56,784:INFO:create_model() successfully completed......................................
2025-10-28 10:50:56,939:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:56,939:INFO:Creating metrics dataframe
2025-10-28 10:50:56,943:INFO:Initializing Random Forest Regressor
2025-10-28 10:50:56,944:INFO:Total runtime is 0.18163890441258748 minutes
2025-10-28 10:50:56,944:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:56,944:INFO:Initializing create_model()
2025-10-28 10:50:56,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:56,945:INFO:Checking exceptions
2025-10-28 10:50:56,945:INFO:Importing libraries
2025-10-28 10:50:56,945:INFO:Copying training dataset
2025-10-28 10:50:56,951:INFO:Defining folds
2025-10-28 10:50:56,951:INFO:Declaring metric variables
2025-10-28 10:50:56,951:INFO:Importing untrained model
2025-10-28 10:50:56,951:INFO:Random Forest Regressor Imported successfully
2025-10-28 10:50:56,951:INFO:Starting cross validation
2025-10-28 10:50:56,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:58,257:INFO:Calculating mean and std
2025-10-28 10:50:58,257:INFO:Creating metrics dataframe
2025-10-28 10:50:58,260:INFO:Uploading results into container
2025-10-28 10:50:58,261:INFO:Uploading model into container now
2025-10-28 10:50:58,262:INFO:_master_model_container: 13
2025-10-28 10:50:58,262:INFO:_display_container: 2
2025-10-28 10:50:58,262:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:50:58,262:INFO:create_model() successfully completed......................................
2025-10-28 10:50:58,404:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:58,405:INFO:Creating metrics dataframe
2025-10-28 10:50:58,409:INFO:Initializing Extra Trees Regressor
2025-10-28 10:50:58,409:INFO:Total runtime is 0.20608212153116862 minutes
2025-10-28 10:50:58,409:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:58,409:INFO:Initializing create_model()
2025-10-28 10:50:58,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:58,410:INFO:Checking exceptions
2025-10-28 10:50:58,410:INFO:Importing libraries
2025-10-28 10:50:58,410:INFO:Copying training dataset
2025-10-28 10:50:58,420:INFO:Defining folds
2025-10-28 10:50:58,421:INFO:Declaring metric variables
2025-10-28 10:50:58,421:INFO:Importing untrained model
2025-10-28 10:50:58,421:INFO:Extra Trees Regressor Imported successfully
2025-10-28 10:50:58,421:INFO:Starting cross validation
2025-10-28 10:50:58,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:59,163:INFO:Calculating mean and std
2025-10-28 10:50:59,165:INFO:Creating metrics dataframe
2025-10-28 10:50:59,167:INFO:Uploading results into container
2025-10-28 10:50:59,167:INFO:Uploading model into container now
2025-10-28 10:50:59,167:INFO:_master_model_container: 14
2025-10-28 10:50:59,167:INFO:_display_container: 2
2025-10-28 10:50:59,169:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:50:59,169:INFO:create_model() successfully completed......................................
2025-10-28 10:50:59,291:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:59,292:INFO:Creating metrics dataframe
2025-10-28 10:50:59,297:INFO:Initializing AdaBoost Regressor
2025-10-28 10:50:59,297:INFO:Total runtime is 0.22087352275848388 minutes
2025-10-28 10:50:59,297:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:59,297:INFO:Initializing create_model()
2025-10-28 10:50:59,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:59,297:INFO:Checking exceptions
2025-10-28 10:50:59,297:INFO:Importing libraries
2025-10-28 10:50:59,297:INFO:Copying training dataset
2025-10-28 10:50:59,307:INFO:Defining folds
2025-10-28 10:50:59,307:INFO:Declaring metric variables
2025-10-28 10:50:59,307:INFO:Importing untrained model
2025-10-28 10:50:59,307:INFO:AdaBoost Regressor Imported successfully
2025-10-28 10:50:59,307:INFO:Starting cross validation
2025-10-28 10:50:59,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:59,790:INFO:Calculating mean and std
2025-10-28 10:50:59,791:INFO:Creating metrics dataframe
2025-10-28 10:50:59,793:INFO:Uploading results into container
2025-10-28 10:50:59,794:INFO:Uploading model into container now
2025-10-28 10:50:59,794:INFO:_master_model_container: 15
2025-10-28 10:50:59,795:INFO:_display_container: 2
2025-10-28 10:50:59,795:INFO:AdaBoostRegressor(random_state=123)
2025-10-28 10:50:59,795:INFO:create_model() successfully completed......................................
2025-10-28 10:50:59,917:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:59,917:INFO:Creating metrics dataframe
2025-10-28 10:50:59,922:INFO:Initializing Gradient Boosting Regressor
2025-10-28 10:50:59,922:INFO:Total runtime is 0.231285019715627 minutes
2025-10-28 10:50:59,922:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:59,922:INFO:Initializing create_model()
2025-10-28 10:50:59,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:59,922:INFO:Checking exceptions
2025-10-28 10:50:59,923:INFO:Importing libraries
2025-10-28 10:50:59,923:INFO:Copying training dataset
2025-10-28 10:50:59,930:INFO:Defining folds
2025-10-28 10:50:59,930:INFO:Declaring metric variables
2025-10-28 10:50:59,930:INFO:Importing untrained model
2025-10-28 10:50:59,931:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 10:50:59,931:INFO:Starting cross validation
2025-10-28 10:50:59,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:51:00,689:INFO:Calculating mean and std
2025-10-28 10:51:00,690:INFO:Creating metrics dataframe
2025-10-28 10:51:00,692:INFO:Uploading results into container
2025-10-28 10:51:00,693:INFO:Uploading model into container now
2025-10-28 10:51:00,693:INFO:_master_model_container: 16
2025-10-28 10:51:00,693:INFO:_display_container: 2
2025-10-28 10:51:00,694:INFO:GradientBoostingRegressor(random_state=123)
2025-10-28 10:51:00,694:INFO:create_model() successfully completed......................................
2025-10-28 10:51:00,831:INFO:SubProcess create_model() end ==================================
2025-10-28 10:51:00,831:INFO:Creating metrics dataframe
2025-10-28 10:51:00,835:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 10:51:00,836:INFO:Total runtime is 0.24651980797449746 minutes
2025-10-28 10:51:00,836:INFO:SubProcess create_model() called ==================================
2025-10-28 10:51:00,836:INFO:Initializing create_model()
2025-10-28 10:51:00,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:51:00,837:INFO:Checking exceptions
2025-10-28 10:51:00,837:INFO:Importing libraries
2025-10-28 10:51:00,837:INFO:Copying training dataset
2025-10-28 10:51:00,844:INFO:Defining folds
2025-10-28 10:51:00,845:INFO:Declaring metric variables
2025-10-28 10:51:00,845:INFO:Importing untrained model
2025-10-28 10:51:00,847:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 10:51:00,849:INFO:Starting cross validation
2025-10-28 10:51:00,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:51:02,344:INFO:Calculating mean and std
2025-10-28 10:51:02,345:INFO:Creating metrics dataframe
2025-10-28 10:51:02,348:INFO:Uploading results into container
2025-10-28 10:51:02,349:INFO:Uploading model into container now
2025-10-28 10:51:02,349:INFO:_master_model_container: 17
2025-10-28 10:51:02,349:INFO:_display_container: 2
2025-10-28 10:51:02,350:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:51:02,350:INFO:create_model() successfully completed......................................
2025-10-28 10:51:02,464:INFO:SubProcess create_model() end ==================================
2025-10-28 10:51:02,465:INFO:Creating metrics dataframe
2025-10-28 10:51:02,468:INFO:Initializing Dummy Regressor
2025-10-28 10:51:02,468:INFO:Total runtime is 0.27373257478078206 minutes
2025-10-28 10:51:02,469:INFO:SubProcess create_model() called ==================================
2025-10-28 10:51:02,469:INFO:Initializing create_model()
2025-10-28 10:51:02,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:51:02,469:INFO:Checking exceptions
2025-10-28 10:51:02,469:INFO:Importing libraries
2025-10-28 10:51:02,469:INFO:Copying training dataset
2025-10-28 10:51:02,478:INFO:Defining folds
2025-10-28 10:51:02,478:INFO:Declaring metric variables
2025-10-28 10:51:02,478:INFO:Importing untrained model
2025-10-28 10:51:02,478:INFO:Dummy Regressor Imported successfully
2025-10-28 10:51:02,478:INFO:Starting cross validation
2025-10-28 10:51:02,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:51:02,650:INFO:Calculating mean and std
2025-10-28 10:51:02,651:INFO:Creating metrics dataframe
2025-10-28 10:51:02,653:INFO:Uploading results into container
2025-10-28 10:51:02,654:INFO:Uploading model into container now
2025-10-28 10:51:02,654:INFO:_master_model_container: 18
2025-10-28 10:51:02,654:INFO:_display_container: 2
2025-10-28 10:51:02,655:INFO:DummyRegressor()
2025-10-28 10:51:02,655:INFO:create_model() successfully completed......................................
2025-10-28 10:51:02,795:INFO:SubProcess create_model() end ==================================
2025-10-28 10:51:02,795:INFO:Creating metrics dataframe
2025-10-28 10:51:02,805:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 10:51:02,807:INFO:Initializing create_model()
2025-10-28 10:51:02,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:51:02,809:INFO:Checking exceptions
2025-10-28 10:51:02,810:INFO:Importing libraries
2025-10-28 10:51:02,810:INFO:Copying training dataset
2025-10-28 10:51:02,818:INFO:Defining folds
2025-10-28 10:51:02,818:INFO:Declaring metric variables
2025-10-28 10:51:02,819:INFO:Importing untrained model
2025-10-28 10:51:02,819:INFO:Declaring custom model
2025-10-28 10:51:02,819:INFO:Extra Trees Regressor Imported successfully
2025-10-28 10:51:02,821:INFO:Cross validation set to False
2025-10-28 10:51:02,821:INFO:Fitting Model
2025-10-28 10:51:02,999:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:51:02,999:INFO:create_model() successfully completed......................................
2025-10-28 10:51:03,160:INFO:_master_model_container: 18
2025-10-28 10:51:03,160:INFO:_display_container: 2
2025-10-28 10:51:03,161:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:51:03,161:INFO:compare_models() successfully completed......................................
2025-10-28 10:51:28,802:INFO:Initializing plot_model()
2025-10-28 10:51:28,802:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), plot=feature, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-28 10:51:28,802:INFO:Checking exceptions
2025-10-28 10:51:28,848:INFO:Preloading libraries
2025-10-28 10:51:28,915:INFO:Copying training dataset
2025-10-28 10:51:28,915:INFO:Plot type: feature
2025-10-28 10:51:28,915:WARNING:No coef_ found. Trying feature_importances_
2025-10-28 10:51:29,099:INFO:Saving 'Feature Importance.png'
2025-10-28 10:51:29,343:INFO:Visual Rendered Successfully
2025-10-28 10:51:29,469:INFO:plot_model() successfully completed......................................
2025-10-28 10:51:29,525:INFO:Initializing predict_model()
2025-10-28 10:51:29,525:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000218D405EDE0>)
2025-10-28 10:51:29,525:INFO:Checking exceptions
2025-10-28 10:51:29,525:INFO:Preloading libraries
2025-10-28 10:51:29,526:INFO:Set up data.
2025-10-28 10:51:29,535:INFO:Set up index.
2025-10-28 10:51:29,659:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-10-28 10:55:42,797:INFO:Initializing load_model()
2025-10-28 10:55:42,797:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 10:56:43,412:INFO:Initializing load_model()
2025-10-28 10:56:43,412:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 10:56:50,993:INFO:Initializing load_model()
2025-10-28 10:56:50,993:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 10:56:55,622:INFO:Initializing load_model()
2025-10-28 10:56:55,623:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 11:01:53,301:INFO:Initializing load_model()
2025-10-28 11:01:53,301:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 11:01:53,301:INFO:Initializing load_model()
2025-10-28 11:01:53,301:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 11:07:12,907:INFO:PyCaret ClassificationExperiment
2025-10-28 11:07:12,907:INFO:Logging name: clf-default-name
2025-10-28 11:07:12,907:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 11:07:12,908:INFO:version 3.3.2
2025-10-28 11:07:12,908:INFO:Initializing setup()
2025-10-28 11:07:12,908:INFO:self.USI: 6f69
2025-10-28 11:07:12,908:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 11:07:12,908:INFO:Checking environment
2025-10-28 11:07:12,908:INFO:python_version: 3.11.14
2025-10-28 11:07:12,908:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 11:07:12,908:INFO:machine: AMD64
2025-10-28 11:07:12,908:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 11:07:12,909:INFO:Memory: svmem(total=16788250624, available=4903288832, percent=70.8, used=11884961792, free=4903288832)
2025-10-28 11:07:12,909:INFO:Physical Core: 12
2025-10-28 11:07:12,909:INFO:Logical Core: 16
2025-10-28 11:07:12,909:INFO:Checking libraries
2025-10-28 11:07:12,909:INFO:System:
2025-10-28 11:07:12,909:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 11:07:12,909:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 11:07:12,909:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 11:07:12,909:INFO:PyCaret required dependencies:
2025-10-28 11:07:12,910:INFO:                 pip: 25.2
2025-10-28 11:07:12,910:INFO:          setuptools: 80.9.0
2025-10-28 11:07:12,910:INFO:             pycaret: 3.3.2
2025-10-28 11:07:12,910:INFO:             IPython: 9.6.0
2025-10-28 11:07:12,911:INFO:          ipywidgets: 8.1.7
2025-10-28 11:07:12,911:INFO:                tqdm: 4.67.1
2025-10-28 11:07:12,911:INFO:               numpy: 1.26.4
2025-10-28 11:07:12,911:INFO:              pandas: 2.1.4
2025-10-28 11:07:12,912:INFO:              jinja2: 3.1.6
2025-10-28 11:07:12,912:INFO:               scipy: 1.11.4
2025-10-28 11:07:12,912:INFO:              joblib: 1.3.2
2025-10-28 11:07:12,912:INFO:             sklearn: 1.4.2
2025-10-28 11:07:12,914:INFO:                pyod: 2.0.5
2025-10-28 11:07:12,914:INFO:            imblearn: 0.14.0
2025-10-28 11:07:12,914:INFO:   category_encoders: 2.7.0
2025-10-28 11:07:12,914:INFO:            lightgbm: 4.6.0
2025-10-28 11:07:12,914:INFO:               numba: 0.62.1
2025-10-28 11:07:12,914:INFO:            requests: 2.32.5
2025-10-28 11:07:12,914:INFO:          matplotlib: 3.10.7
2025-10-28 11:07:12,914:INFO:          scikitplot: 0.3.7
2025-10-28 11:07:12,915:INFO:         yellowbrick: 1.5
2025-10-28 11:07:12,915:INFO:              plotly: 6.3.1
2025-10-28 11:07:12,915:INFO:    plotly-resampler: Not installed
2025-10-28 11:07:12,915:INFO:             kaleido: 0.2.1
2025-10-28 11:07:12,915:INFO:           schemdraw: 0.15
2025-10-28 11:07:12,915:INFO:         statsmodels: 0.14.5
2025-10-28 11:07:12,916:INFO:              sktime: 0.26.0
2025-10-28 11:07:12,916:INFO:               tbats: 1.1.3
2025-10-28 11:07:12,916:INFO:            pmdarima: 2.0.4
2025-10-28 11:07:12,916:INFO:              psutil: 7.1.1
2025-10-28 11:07:12,916:INFO:          markupsafe: 3.0.3
2025-10-28 11:07:12,917:INFO:             pickle5: Not installed
2025-10-28 11:07:12,917:INFO:         cloudpickle: 3.1.1
2025-10-28 11:07:12,917:INFO:         deprecation: 2.1.0
2025-10-28 11:07:12,917:INFO:              xxhash: 3.6.0
2025-10-28 11:07:12,917:INFO:           wurlitzer: 3.1.1
2025-10-28 11:07:12,917:INFO:PyCaret optional dependencies:
2025-10-28 11:07:12,918:INFO:                shap: Not installed
2025-10-28 11:07:12,918:INFO:           interpret: Not installed
2025-10-28 11:07:12,918:INFO:                umap: 0.5.9.post2
2025-10-28 11:07:12,918:INFO:     ydata_profiling: Not installed
2025-10-28 11:07:12,919:INFO:  explainerdashboard: Not installed
2025-10-28 11:07:12,919:INFO:             autoviz: Not installed
2025-10-28 11:07:12,919:INFO:           fairlearn: Not installed
2025-10-28 11:07:12,919:INFO:          deepchecks: Not installed
2025-10-28 11:07:12,920:INFO:             xgboost: Not installed
2025-10-28 11:07:12,920:INFO:            catboost: Not installed
2025-10-28 11:07:12,920:INFO:              kmodes: Not installed
2025-10-28 11:07:12,920:INFO:             mlxtend: Not installed
2025-10-28 11:07:12,920:INFO:       statsforecast: Not installed
2025-10-28 11:07:12,920:INFO:        tune_sklearn: Not installed
2025-10-28 11:07:12,921:INFO:                 ray: Not installed
2025-10-28 11:07:12,921:INFO:            hyperopt: Not installed
2025-10-28 11:07:12,921:INFO:              optuna: Not installed
2025-10-28 11:07:12,921:INFO:               skopt: Not installed
2025-10-28 11:07:12,921:INFO:              mlflow: Not installed
2025-10-28 11:07:12,922:INFO:              gradio: Not installed
2025-10-28 11:07:12,922:INFO:             fastapi: Not installed
2025-10-28 11:07:12,922:INFO:             uvicorn: Not installed
2025-10-28 11:07:12,922:INFO:              m2cgen: Not installed
2025-10-28 11:07:12,922:INFO:           evidently: Not installed
2025-10-28 11:07:12,922:INFO:               fugue: Not installed
2025-10-28 11:07:12,923:INFO:           streamlit: 1.50.0
2025-10-28 11:07:12,923:INFO:             prophet: Not installed
2025-10-28 11:07:12,924:INFO:None
2025-10-28 11:07:12,925:INFO:Set up data.
2025-10-28 11:07:12,932:INFO:Set up folding strategy.
2025-10-28 11:07:12,932:INFO:Set up train/test split.
2025-10-28 11:07:12,943:INFO:Set up index.
2025-10-28 11:07:12,943:INFO:Assigning column types.
2025-10-28 11:07:12,950:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 11:07:13,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,274:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 11:07:13,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,432:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 11:07:13,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,678:INFO:Preparing preprocessing pipeline...
2025-10-28 11:07:13,679:INFO:Set up simple imputation.
2025-10-28 11:07:13,680:INFO:Set up column name cleaning.
2025-10-28 11:07:13,702:INFO:Finished creating preprocessing pipeline.
2025-10-28 11:07:13,708:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-28 11:07:13,708:INFO:Creating final display dataframe.
2025-10-28 11:07:13,784:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6f69
2025-10-28 11:07:13,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,986:INFO:setup() successfully completed in 1.08s...............
2025-10-28 11:07:13,986:INFO:Initializing compare_models()
2025-10-28 11:07:13,986:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-28 11:07:13,986:INFO:Checking exceptions
2025-10-28 11:07:13,991:INFO:Preparing display monitor
2025-10-28 11:07:13,993:INFO:Initializing Logistic Regression
2025-10-28 11:07:13,993:INFO:Total runtime is 0.0 minutes
2025-10-28 11:07:13,993:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:13,993:INFO:Initializing create_model()
2025-10-28 11:07:13,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:13,993:INFO:Checking exceptions
2025-10-28 11:07:13,993:INFO:Importing libraries
2025-10-28 11:07:13,993:INFO:Copying training dataset
2025-10-28 11:07:13,996:INFO:Defining folds
2025-10-28 11:07:13,996:INFO:Declaring metric variables
2025-10-28 11:07:13,996:INFO:Importing untrained model
2025-10-28 11:07:13,996:INFO:Logistic Regression Imported successfully
2025-10-28 11:07:13,997:INFO:Starting cross validation
2025-10-28 11:07:13,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:17,862:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,870:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,874:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,877:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,877:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,890:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,894:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,901:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,902:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,923:INFO:Calculating mean and std
2025-10-28 11:07:17,924:INFO:Creating metrics dataframe
2025-10-28 11:07:17,928:INFO:Uploading results into container
2025-10-28 11:07:17,929:INFO:Uploading model into container now
2025-10-28 11:07:17,929:INFO:_master_model_container: 1
2025-10-28 11:07:17,929:INFO:_display_container: 2
2025-10-28 11:07:17,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:07:17,930:INFO:create_model() successfully completed......................................
2025-10-28 11:07:18,091:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:18,091:INFO:Creating metrics dataframe
2025-10-28 11:07:18,094:INFO:Initializing K Neighbors Classifier
2025-10-28 11:07:18,094:INFO:Total runtime is 0.06834901968638102 minutes
2025-10-28 11:07:18,094:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:18,095:INFO:Initializing create_model()
2025-10-28 11:07:18,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:18,095:INFO:Checking exceptions
2025-10-28 11:07:18,095:INFO:Importing libraries
2025-10-28 11:07:18,095:INFO:Copying training dataset
2025-10-28 11:07:18,100:INFO:Defining folds
2025-10-28 11:07:18,100:INFO:Declaring metric variables
2025-10-28 11:07:18,101:INFO:Importing untrained model
2025-10-28 11:07:18,101:INFO:K Neighbors Classifier Imported successfully
2025-10-28 11:07:18,102:INFO:Starting cross validation
2025-10-28 11:07:18,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:20,896:INFO:Calculating mean and std
2025-10-28 11:07:20,899:INFO:Creating metrics dataframe
2025-10-28 11:07:20,901:INFO:Uploading results into container
2025-10-28 11:07:20,902:INFO:Uploading model into container now
2025-10-28 11:07:20,902:INFO:_master_model_container: 2
2025-10-28 11:07:20,902:INFO:_display_container: 2
2025-10-28 11:07:20,903:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-28 11:07:20,903:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,039:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,039:INFO:Creating metrics dataframe
2025-10-28 11:07:21,046:INFO:Initializing Naive Bayes
2025-10-28 11:07:21,046:INFO:Total runtime is 0.11754014094670613 minutes
2025-10-28 11:07:21,046:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,047:INFO:Initializing create_model()
2025-10-28 11:07:21,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,047:INFO:Checking exceptions
2025-10-28 11:07:21,047:INFO:Importing libraries
2025-10-28 11:07:21,047:INFO:Copying training dataset
2025-10-28 11:07:21,052:INFO:Defining folds
2025-10-28 11:07:21,052:INFO:Declaring metric variables
2025-10-28 11:07:21,052:INFO:Importing untrained model
2025-10-28 11:07:21,053:INFO:Naive Bayes Imported successfully
2025-10-28 11:07:21,053:INFO:Starting cross validation
2025-10-28 11:07:21,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,132:INFO:Calculating mean and std
2025-10-28 11:07:21,133:INFO:Creating metrics dataframe
2025-10-28 11:07:21,137:INFO:Uploading results into container
2025-10-28 11:07:21,138:INFO:Uploading model into container now
2025-10-28 11:07:21,139:INFO:_master_model_container: 3
2025-10-28 11:07:21,139:INFO:_display_container: 2
2025-10-28 11:07:21,140:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-28 11:07:21,140:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,265:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,265:INFO:Creating metrics dataframe
2025-10-28 11:07:21,268:INFO:Initializing Decision Tree Classifier
2025-10-28 11:07:21,268:INFO:Total runtime is 0.12124522527058919 minutes
2025-10-28 11:07:21,268:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,268:INFO:Initializing create_model()
2025-10-28 11:07:21,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,268:INFO:Checking exceptions
2025-10-28 11:07:21,268:INFO:Importing libraries
2025-10-28 11:07:21,269:INFO:Copying training dataset
2025-10-28 11:07:21,274:INFO:Defining folds
2025-10-28 11:07:21,274:INFO:Declaring metric variables
2025-10-28 11:07:21,274:INFO:Importing untrained model
2025-10-28 11:07:21,274:INFO:Decision Tree Classifier Imported successfully
2025-10-28 11:07:21,274:INFO:Starting cross validation
2025-10-28 11:07:21,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,330:INFO:Calculating mean and std
2025-10-28 11:07:21,331:INFO:Creating metrics dataframe
2025-10-28 11:07:21,334:INFO:Uploading results into container
2025-10-28 11:07:21,335:INFO:Uploading model into container now
2025-10-28 11:07:21,336:INFO:_master_model_container: 4
2025-10-28 11:07:21,337:INFO:_display_container: 2
2025-10-28 11:07:21,337:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-28 11:07:21,337:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,471:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,472:INFO:Creating metrics dataframe
2025-10-28 11:07:21,477:INFO:Initializing SVM - Linear Kernel
2025-10-28 11:07:21,477:INFO:Total runtime is 0.1247215469678243 minutes
2025-10-28 11:07:21,477:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,477:INFO:Initializing create_model()
2025-10-28 11:07:21,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,477:INFO:Checking exceptions
2025-10-28 11:07:21,477:INFO:Importing libraries
2025-10-28 11:07:21,477:INFO:Copying training dataset
2025-10-28 11:07:21,481:INFO:Defining folds
2025-10-28 11:07:21,481:INFO:Declaring metric variables
2025-10-28 11:07:21,481:INFO:Importing untrained model
2025-10-28 11:07:21,482:INFO:SVM - Linear Kernel Imported successfully
2025-10-28 11:07:21,482:INFO:Starting cross validation
2025-10-28 11:07:21,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,535:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,535:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,536:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,537:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,541:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,542:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,542:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,557:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,558:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,560:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,562:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,562:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,563:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,564:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,577:INFO:Calculating mean and std
2025-10-28 11:07:21,579:INFO:Creating metrics dataframe
2025-10-28 11:07:21,584:INFO:Uploading results into container
2025-10-28 11:07:21,586:INFO:Uploading model into container now
2025-10-28 11:07:21,587:INFO:_master_model_container: 5
2025-10-28 11:07:21,587:INFO:_display_container: 2
2025-10-28 11:07:21,588:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-28 11:07:21,588:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,733:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,733:INFO:Creating metrics dataframe
2025-10-28 11:07:21,739:INFO:Initializing Ridge Classifier
2025-10-28 11:07:21,739:INFO:Total runtime is 0.12908904949824015 minutes
2025-10-28 11:07:21,739:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,739:INFO:Initializing create_model()
2025-10-28 11:07:21,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,740:INFO:Checking exceptions
2025-10-28 11:07:21,740:INFO:Importing libraries
2025-10-28 11:07:21,740:INFO:Copying training dataset
2025-10-28 11:07:21,744:INFO:Defining folds
2025-10-28 11:07:21,744:INFO:Declaring metric variables
2025-10-28 11:07:21,746:INFO:Importing untrained model
2025-10-28 11:07:21,746:INFO:Ridge Classifier Imported successfully
2025-10-28 11:07:21,747:INFO:Starting cross validation
2025-10-28 11:07:21,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,822:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,822:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,822:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,824:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,827:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,827:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,827:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,828:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,831:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,845:INFO:Calculating mean and std
2025-10-28 11:07:21,846:INFO:Creating metrics dataframe
2025-10-28 11:07:21,852:INFO:Uploading results into container
2025-10-28 11:07:21,853:INFO:Uploading model into container now
2025-10-28 11:07:21,853:INFO:_master_model_container: 6
2025-10-28 11:07:21,853:INFO:_display_container: 2
2025-10-28 11:07:21,854:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-28 11:07:21,854:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,987:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,988:INFO:Creating metrics dataframe
2025-10-28 11:07:21,992:INFO:Initializing Random Forest Classifier
2025-10-28 11:07:21,992:INFO:Total runtime is 0.13331883748372397 minutes
2025-10-28 11:07:21,992:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,992:INFO:Initializing create_model()
2025-10-28 11:07:21,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,992:INFO:Checking exceptions
2025-10-28 11:07:21,992:INFO:Importing libraries
2025-10-28 11:07:21,992:INFO:Copying training dataset
2025-10-28 11:07:21,997:INFO:Defining folds
2025-10-28 11:07:21,997:INFO:Declaring metric variables
2025-10-28 11:07:21,997:INFO:Importing untrained model
2025-10-28 11:07:21,998:INFO:Random Forest Classifier Imported successfully
2025-10-28 11:07:21,999:INFO:Starting cross validation
2025-10-28 11:07:22,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:22,310:INFO:Calculating mean and std
2025-10-28 11:07:22,310:INFO:Creating metrics dataframe
2025-10-28 11:07:22,313:INFO:Uploading results into container
2025-10-28 11:07:22,315:INFO:Uploading model into container now
2025-10-28 11:07:22,315:INFO:_master_model_container: 7
2025-10-28 11:07:22,315:INFO:_display_container: 2
2025-10-28 11:07:22,316:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-28 11:07:22,316:INFO:create_model() successfully completed......................................
2025-10-28 11:07:22,444:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:22,444:INFO:Creating metrics dataframe
2025-10-28 11:07:22,448:INFO:Initializing Quadratic Discriminant Analysis
2025-10-28 11:07:22,448:INFO:Total runtime is 0.1409042278925578 minutes
2025-10-28 11:07:22,449:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:22,449:INFO:Initializing create_model()
2025-10-28 11:07:22,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:22,449:INFO:Checking exceptions
2025-10-28 11:07:22,449:INFO:Importing libraries
2025-10-28 11:07:22,449:INFO:Copying training dataset
2025-10-28 11:07:22,452:INFO:Defining folds
2025-10-28 11:07:22,452:INFO:Declaring metric variables
2025-10-28 11:07:22,453:INFO:Importing untrained model
2025-10-28 11:07:22,453:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-28 11:07:22,453:INFO:Starting cross validation
2025-10-28 11:07:22,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:22,524:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,526:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,527:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,528:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,529:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,533:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,536:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,542:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,572:INFO:Calculating mean and std
2025-10-28 11:07:22,572:INFO:Creating metrics dataframe
2025-10-28 11:07:22,574:INFO:Uploading results into container
2025-10-28 11:07:22,574:INFO:Uploading model into container now
2025-10-28 11:07:22,574:INFO:_master_model_container: 8
2025-10-28 11:07:22,574:INFO:_display_container: 2
2025-10-28 11:07:22,574:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-28 11:07:22,574:INFO:create_model() successfully completed......................................
2025-10-28 11:07:22,695:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:22,695:INFO:Creating metrics dataframe
2025-10-28 11:07:22,704:INFO:Initializing Ada Boost Classifier
2025-10-28 11:07:22,704:INFO:Total runtime is 0.1451822876930237 minutes
2025-10-28 11:07:22,704:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:22,704:INFO:Initializing create_model()
2025-10-28 11:07:22,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:22,704:INFO:Checking exceptions
2025-10-28 11:07:22,704:INFO:Importing libraries
2025-10-28 11:07:22,704:INFO:Copying training dataset
2025-10-28 11:07:22,708:INFO:Defining folds
2025-10-28 11:07:22,708:INFO:Declaring metric variables
2025-10-28 11:07:22,708:INFO:Importing untrained model
2025-10-28 11:07:22,708:INFO:Ada Boost Classifier Imported successfully
2025-10-28 11:07:22,708:INFO:Starting cross validation
2025-10-28 11:07:22,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:22,750:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,752:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,754:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,761:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,761:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,765:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,767:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,768:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,772:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,925:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,926:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,931:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,933:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,935:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,939:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,939:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,941:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,950:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,950:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,968:INFO:Calculating mean and std
2025-10-28 11:07:22,968:INFO:Creating metrics dataframe
2025-10-28 11:07:22,971:INFO:Uploading results into container
2025-10-28 11:07:22,971:INFO:Uploading model into container now
2025-10-28 11:07:22,971:INFO:_master_model_container: 9
2025-10-28 11:07:22,971:INFO:_display_container: 2
2025-10-28 11:07:22,971:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-28 11:07:22,971:INFO:create_model() successfully completed......................................
2025-10-28 11:07:23,113:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:23,113:INFO:Creating metrics dataframe
2025-10-28 11:07:23,117:INFO:Initializing Gradient Boosting Classifier
2025-10-28 11:07:23,117:INFO:Total runtime is 0.1520699461301168 minutes
2025-10-28 11:07:23,117:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:23,117:INFO:Initializing create_model()
2025-10-28 11:07:23,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:23,122:INFO:Checking exceptions
2025-10-28 11:07:23,122:INFO:Importing libraries
2025-10-28 11:07:23,122:INFO:Copying training dataset
2025-10-28 11:07:23,126:INFO:Defining folds
2025-10-28 11:07:23,126:INFO:Declaring metric variables
2025-10-28 11:07:23,130:INFO:Importing untrained model
2025-10-28 11:07:23,130:INFO:Gradient Boosting Classifier Imported successfully
2025-10-28 11:07:23,130:INFO:Starting cross validation
2025-10-28 11:07:23,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:23,537:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,543:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,545:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,557:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,562:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,573:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,588:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,609:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,626:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,649:INFO:Calculating mean and std
2025-10-28 11:07:23,649:INFO:Creating metrics dataframe
2025-10-28 11:07:23,651:INFO:Uploading results into container
2025-10-28 11:07:23,652:INFO:Uploading model into container now
2025-10-28 11:07:23,652:INFO:_master_model_container: 10
2025-10-28 11:07:23,652:INFO:_display_container: 2
2025-10-28 11:07:23,652:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-28 11:07:23,652:INFO:create_model() successfully completed......................................
2025-10-28 11:07:23,785:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:23,785:INFO:Creating metrics dataframe
2025-10-28 11:07:23,789:INFO:Initializing Linear Discriminant Analysis
2025-10-28 11:07:23,789:INFO:Total runtime is 0.16325873533884686 minutes
2025-10-28 11:07:23,789:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:23,789:INFO:Initializing create_model()
2025-10-28 11:07:23,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:23,790:INFO:Checking exceptions
2025-10-28 11:07:23,790:INFO:Importing libraries
2025-10-28 11:07:23,790:INFO:Copying training dataset
2025-10-28 11:07:23,794:INFO:Defining folds
2025-10-28 11:07:23,794:INFO:Declaring metric variables
2025-10-28 11:07:23,794:INFO:Importing untrained model
2025-10-28 11:07:23,794:INFO:Linear Discriminant Analysis Imported successfully
2025-10-28 11:07:23,794:INFO:Starting cross validation
2025-10-28 11:07:23,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:23,857:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,857:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,860:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,862:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,863:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,863:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,900:INFO:Calculating mean and std
2025-10-28 11:07:23,903:INFO:Creating metrics dataframe
2025-10-28 11:07:23,908:INFO:Uploading results into container
2025-10-28 11:07:23,909:INFO:Uploading model into container now
2025-10-28 11:07:23,910:INFO:_master_model_container: 11
2025-10-28 11:07:23,911:INFO:_display_container: 2
2025-10-28 11:07:23,912:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-28 11:07:23,912:INFO:create_model() successfully completed......................................
2025-10-28 11:07:24,046:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:24,046:INFO:Creating metrics dataframe
2025-10-28 11:07:24,049:INFO:Initializing Extra Trees Classifier
2025-10-28 11:07:24,051:INFO:Total runtime is 0.16762837171554568 minutes
2025-10-28 11:07:24,051:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:24,051:INFO:Initializing create_model()
2025-10-28 11:07:24,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:24,051:INFO:Checking exceptions
2025-10-28 11:07:24,052:INFO:Importing libraries
2025-10-28 11:07:24,052:INFO:Copying training dataset
2025-10-28 11:07:24,056:INFO:Defining folds
2025-10-28 11:07:24,056:INFO:Declaring metric variables
2025-10-28 11:07:24,056:INFO:Importing untrained model
2025-10-28 11:07:24,056:INFO:Extra Trees Classifier Imported successfully
2025-10-28 11:07:24,056:INFO:Starting cross validation
2025-10-28 11:07:24,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:24,391:INFO:Calculating mean and std
2025-10-28 11:07:24,393:INFO:Creating metrics dataframe
2025-10-28 11:07:24,395:INFO:Uploading results into container
2025-10-28 11:07:24,396:INFO:Uploading model into container now
2025-10-28 11:07:24,397:INFO:_master_model_container: 12
2025-10-28 11:07:24,397:INFO:_display_container: 2
2025-10-28 11:07:24,398:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-28 11:07:24,398:INFO:create_model() successfully completed......................................
2025-10-28 11:07:24,532:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:24,532:INFO:Creating metrics dataframe
2025-10-28 11:07:24,540:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 11:07:24,540:INFO:Total runtime is 0.1757723649342855 minutes
2025-10-28 11:07:24,540:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:24,541:INFO:Initializing create_model()
2025-10-28 11:07:24,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:24,541:INFO:Checking exceptions
2025-10-28 11:07:24,541:INFO:Importing libraries
2025-10-28 11:07:24,541:INFO:Copying training dataset
2025-10-28 11:07:24,548:INFO:Defining folds
2025-10-28 11:07:24,548:INFO:Declaring metric variables
2025-10-28 11:07:24,549:INFO:Importing untrained model
2025-10-28 11:07:24,550:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 11:07:24,550:INFO:Starting cross validation
2025-10-28 11:07:24,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:25,678:INFO:Calculating mean and std
2025-10-28 11:07:25,679:INFO:Creating metrics dataframe
2025-10-28 11:07:25,681:INFO:Uploading results into container
2025-10-28 11:07:25,681:INFO:Uploading model into container now
2025-10-28 11:07:25,682:INFO:_master_model_container: 13
2025-10-28 11:07:25,682:INFO:_display_container: 2
2025-10-28 11:07:25,682:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-28 11:07:25,682:INFO:create_model() successfully completed......................................
2025-10-28 11:07:25,789:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:25,789:INFO:Creating metrics dataframe
2025-10-28 11:07:25,794:INFO:Initializing Dummy Classifier
2025-10-28 11:07:25,795:INFO:Total runtime is 0.19668071667353315 minutes
2025-10-28 11:07:25,795:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:25,795:INFO:Initializing create_model()
2025-10-28 11:07:25,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:25,795:INFO:Checking exceptions
2025-10-28 11:07:25,796:INFO:Importing libraries
2025-10-28 11:07:25,796:INFO:Copying training dataset
2025-10-28 11:07:25,801:INFO:Defining folds
2025-10-28 11:07:25,801:INFO:Declaring metric variables
2025-10-28 11:07:25,801:INFO:Importing untrained model
2025-10-28 11:07:25,801:INFO:Dummy Classifier Imported successfully
2025-10-28 11:07:25,802:INFO:Starting cross validation
2025-10-28 11:07:25,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:25,861:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,861:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,861:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,866:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,868:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,868:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,870:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,873:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,874:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,875:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,888:INFO:Calculating mean and std
2025-10-28 11:07:25,890:INFO:Creating metrics dataframe
2025-10-28 11:07:25,894:INFO:Uploading results into container
2025-10-28 11:07:25,895:INFO:Uploading model into container now
2025-10-28 11:07:25,896:INFO:_master_model_container: 14
2025-10-28 11:07:25,896:INFO:_display_container: 2
2025-10-28 11:07:25,897:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-28 11:07:25,897:INFO:create_model() successfully completed......................................
2025-10-28 11:07:26,039:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:26,039:INFO:Creating metrics dataframe
2025-10-28 11:07:26,043:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 11:07:26,045:INFO:Initializing create_model()
2025-10-28 11:07:26,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:26,045:INFO:Checking exceptions
2025-10-28 11:07:26,046:INFO:Importing libraries
2025-10-28 11:07:26,046:INFO:Copying training dataset
2025-10-28 11:07:26,050:INFO:Defining folds
2025-10-28 11:07:26,050:INFO:Declaring metric variables
2025-10-28 11:07:26,050:INFO:Importing untrained model
2025-10-28 11:07:26,050:INFO:Declaring custom model
2025-10-28 11:07:26,052:INFO:Logistic Regression Imported successfully
2025-10-28 11:07:26,053:INFO:Cross validation set to False
2025-10-28 11:07:26,053:INFO:Fitting Model
2025-10-28 11:07:26,083:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:07:26,083:INFO:create_model() successfully completed......................................
2025-10-28 11:07:26,230:INFO:_master_model_container: 14
2025-10-28 11:07:26,230:INFO:_display_container: 2
2025-10-28 11:07:26,231:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:07:26,231:INFO:compare_models() successfully completed......................................
2025-10-28 11:07:26,236:INFO:Initializing plot_model()
2025-10-28 11:07:26,236:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-10-28 11:07:26,236:INFO:Checking exceptions
2025-10-28 11:07:26,236:INFO:Soft dependency imported: streamlit: 1.50.0
2025-10-28 11:07:26,238:INFO:Preloading libraries
2025-10-28 11:07:26,239:INFO:Copying training dataset
2025-10-28 11:07:26,239:INFO:Plot type: feature
2025-10-28 11:07:26,348:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

2025-10-28 11:07:26,348:INFO:Visual Rendered Successfully
2025-10-28 11:07:26,468:INFO:plot_model() successfully completed......................................
2025-10-28 11:09:40,481:INFO:PyCaret ClassificationExperiment
2025-10-28 11:09:40,482:INFO:Logging name: clf-default-name
2025-10-28 11:09:40,482:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 11:09:40,482:INFO:version 3.3.2
2025-10-28 11:09:40,482:INFO:Initializing setup()
2025-10-28 11:09:40,482:INFO:self.USI: eaf7
2025-10-28 11:09:40,482:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 11:09:40,482:INFO:Checking environment
2025-10-28 11:09:40,482:INFO:python_version: 3.11.14
2025-10-28 11:09:40,482:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 11:09:40,482:INFO:machine: AMD64
2025-10-28 11:09:40,482:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 11:09:40,484:INFO:Memory: svmem(total=16788250624, available=2777448448, percent=83.5, used=14010802176, free=2777448448)
2025-10-28 11:09:40,484:INFO:Physical Core: 12
2025-10-28 11:09:40,484:INFO:Logical Core: 16
2025-10-28 11:09:40,484:INFO:Checking libraries
2025-10-28 11:09:40,484:INFO:System:
2025-10-28 11:09:40,484:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 11:09:40,485:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 11:09:40,485:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 11:09:40,485:INFO:PyCaret required dependencies:
2025-10-28 11:09:40,485:INFO:                 pip: 25.2
2025-10-28 11:09:40,485:INFO:          setuptools: 80.9.0
2025-10-28 11:09:40,485:INFO:             pycaret: 3.3.2
2025-10-28 11:09:40,485:INFO:             IPython: 9.6.0
2025-10-28 11:09:40,485:INFO:          ipywidgets: 8.1.7
2025-10-28 11:09:40,486:INFO:                tqdm: 4.67.1
2025-10-28 11:09:40,486:INFO:               numpy: 1.26.4
2025-10-28 11:09:40,486:INFO:              pandas: 2.1.4
2025-10-28 11:09:40,486:INFO:              jinja2: 3.1.6
2025-10-28 11:09:40,486:INFO:               scipy: 1.11.4
2025-10-28 11:09:40,486:INFO:              joblib: 1.3.2
2025-10-28 11:09:40,486:INFO:             sklearn: 1.4.2
2025-10-28 11:09:40,488:INFO:                pyod: 2.0.5
2025-10-28 11:09:40,488:INFO:            imblearn: 0.14.0
2025-10-28 11:09:40,488:INFO:   category_encoders: 2.7.0
2025-10-28 11:09:40,488:INFO:            lightgbm: 4.6.0
2025-10-28 11:09:40,489:INFO:               numba: 0.62.1
2025-10-28 11:09:40,489:INFO:            requests: 2.32.5
2025-10-28 11:09:40,489:INFO:          matplotlib: 3.10.7
2025-10-28 11:09:40,489:INFO:          scikitplot: 0.3.7
2025-10-28 11:09:40,489:INFO:         yellowbrick: 1.5
2025-10-28 11:09:40,489:INFO:              plotly: 6.3.1
2025-10-28 11:09:40,489:INFO:    plotly-resampler: Not installed
2025-10-28 11:09:40,491:INFO:             kaleido: 0.2.1
2025-10-28 11:09:40,491:INFO:           schemdraw: 0.15
2025-10-28 11:09:40,491:INFO:         statsmodels: 0.14.5
2025-10-28 11:09:40,491:INFO:              sktime: 0.26.0
2025-10-28 11:09:40,492:INFO:               tbats: 1.1.3
2025-10-28 11:09:40,492:INFO:            pmdarima: 2.0.4
2025-10-28 11:09:40,492:INFO:              psutil: 7.1.1
2025-10-28 11:09:40,492:INFO:          markupsafe: 3.0.3
2025-10-28 11:09:40,492:INFO:             pickle5: Not installed
2025-10-28 11:09:40,492:INFO:         cloudpickle: 3.1.1
2025-10-28 11:09:40,492:INFO:         deprecation: 2.1.0
2025-10-28 11:09:40,492:INFO:              xxhash: 3.6.0
2025-10-28 11:09:40,493:INFO:           wurlitzer: 3.1.1
2025-10-28 11:09:40,493:INFO:PyCaret optional dependencies:
2025-10-28 11:09:40,493:INFO:                shap: Not installed
2025-10-28 11:09:40,493:INFO:           interpret: Not installed
2025-10-28 11:09:40,494:INFO:                umap: 0.5.9.post2
2025-10-28 11:09:40,494:INFO:     ydata_profiling: Not installed
2025-10-28 11:09:40,494:INFO:  explainerdashboard: Not installed
2025-10-28 11:09:40,494:INFO:             autoviz: Not installed
2025-10-28 11:09:40,494:INFO:           fairlearn: Not installed
2025-10-28 11:09:40,494:INFO:          deepchecks: Not installed
2025-10-28 11:09:40,494:INFO:             xgboost: Not installed
2025-10-28 11:09:40,494:INFO:            catboost: Not installed
2025-10-28 11:09:40,494:INFO:              kmodes: Not installed
2025-10-28 11:09:40,494:INFO:             mlxtend: Not installed
2025-10-28 11:09:40,494:INFO:       statsforecast: Not installed
2025-10-28 11:09:40,494:INFO:        tune_sklearn: Not installed
2025-10-28 11:09:40,494:INFO:                 ray: Not installed
2025-10-28 11:09:40,494:INFO:            hyperopt: Not installed
2025-10-28 11:09:40,494:INFO:              optuna: Not installed
2025-10-28 11:09:40,494:INFO:               skopt: Not installed
2025-10-28 11:09:40,494:INFO:              mlflow: Not installed
2025-10-28 11:09:40,494:INFO:              gradio: Not installed
2025-10-28 11:09:40,494:INFO:             fastapi: Not installed
2025-10-28 11:09:40,494:INFO:             uvicorn: Not installed
2025-10-28 11:09:40,494:INFO:              m2cgen: Not installed
2025-10-28 11:09:40,494:INFO:           evidently: Not installed
2025-10-28 11:09:40,494:INFO:               fugue: Not installed
2025-10-28 11:09:40,494:INFO:           streamlit: 1.50.0
2025-10-28 11:09:40,494:INFO:             prophet: Not installed
2025-10-28 11:09:40,494:INFO:None
2025-10-28 11:09:40,494:INFO:Set up data.
2025-10-28 11:09:40,497:INFO:Set up folding strategy.
2025-10-28 11:09:40,497:INFO:Set up train/test split.
2025-10-28 11:09:40,505:INFO:Set up index.
2025-10-28 11:09:40,506:INFO:Assigning column types.
2025-10-28 11:09:40,512:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 11:09:40,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,778:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 11:09:40,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,959:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,998:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 11:09:41,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,185:INFO:Preparing preprocessing pipeline...
2025-10-28 11:09:41,186:INFO:Set up simple imputation.
2025-10-28 11:09:41,187:INFO:Set up column name cleaning.
2025-10-28 11:09:41,211:INFO:Finished creating preprocessing pipeline.
2025-10-28 11:09:41,217:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-28 11:09:41,217:INFO:Creating final display dataframe.
2025-10-28 11:09:41,299:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              eaf7
2025-10-28 11:09:41,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,586:INFO:setup() successfully completed in 1.11s...............
2025-10-28 11:09:41,587:INFO:Initializing compare_models()
2025-10-28 11:09:41,587:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-28 11:09:41,587:INFO:Checking exceptions
2025-10-28 11:09:41,591:INFO:Preparing display monitor
2025-10-28 11:09:41,594:INFO:Initializing Logistic Regression
2025-10-28 11:09:41,594:INFO:Total runtime is 0.0 minutes
2025-10-28 11:09:41,594:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:41,596:INFO:Initializing create_model()
2025-10-28 11:09:41,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:41,596:INFO:Checking exceptions
2025-10-28 11:09:41,596:INFO:Importing libraries
2025-10-28 11:09:41,596:INFO:Copying training dataset
2025-10-28 11:09:41,598:INFO:Defining folds
2025-10-28 11:09:41,599:INFO:Declaring metric variables
2025-10-28 11:09:41,599:INFO:Importing untrained model
2025-10-28 11:09:41,600:INFO:Logistic Regression Imported successfully
2025-10-28 11:09:41,600:INFO:Starting cross validation
2025-10-28 11:09:41,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:41,670:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,670:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,671:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,675:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,675:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,681:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,685:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,695:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,696:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,720:INFO:Calculating mean and std
2025-10-28 11:09:41,721:INFO:Creating metrics dataframe
2025-10-28 11:09:41,725:INFO:Uploading results into container
2025-10-28 11:09:41,726:INFO:Uploading model into container now
2025-10-28 11:09:41,727:INFO:_master_model_container: 1
2025-10-28 11:09:41,727:INFO:_display_container: 2
2025-10-28 11:09:41,728:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:09:41,728:INFO:create_model() successfully completed......................................
2025-10-28 11:09:41,872:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:41,872:INFO:Creating metrics dataframe
2025-10-28 11:09:41,874:INFO:Initializing K Neighbors Classifier
2025-10-28 11:09:41,874:INFO:Total runtime is 0.004668609301249186 minutes
2025-10-28 11:09:41,874:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:41,875:INFO:Initializing create_model()
2025-10-28 11:09:41,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:41,875:INFO:Checking exceptions
2025-10-28 11:09:41,875:INFO:Importing libraries
2025-10-28 11:09:41,875:INFO:Copying training dataset
2025-10-28 11:09:41,878:INFO:Defining folds
2025-10-28 11:09:41,879:INFO:Declaring metric variables
2025-10-28 11:09:41,879:INFO:Importing untrained model
2025-10-28 11:09:41,879:INFO:K Neighbors Classifier Imported successfully
2025-10-28 11:09:41,880:INFO:Starting cross validation
2025-10-28 11:09:41,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,008:INFO:Calculating mean and std
2025-10-28 11:09:42,009:INFO:Creating metrics dataframe
2025-10-28 11:09:42,012:INFO:Uploading results into container
2025-10-28 11:09:42,013:INFO:Uploading model into container now
2025-10-28 11:09:42,013:INFO:_master_model_container: 2
2025-10-28 11:09:42,014:INFO:_display_container: 2
2025-10-28 11:09:42,014:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-28 11:09:42,014:INFO:create_model() successfully completed......................................
2025-10-28 11:09:42,144:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:42,145:INFO:Creating metrics dataframe
2025-10-28 11:09:42,153:INFO:Initializing Naive Bayes
2025-10-28 11:09:42,153:INFO:Total runtime is 0.009309331576029459 minutes
2025-10-28 11:09:42,154:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:42,154:INFO:Initializing create_model()
2025-10-28 11:09:42,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:42,155:INFO:Checking exceptions
2025-10-28 11:09:42,155:INFO:Importing libraries
2025-10-28 11:09:42,155:INFO:Copying training dataset
2025-10-28 11:09:42,163:INFO:Defining folds
2025-10-28 11:09:42,163:INFO:Declaring metric variables
2025-10-28 11:09:42,163:INFO:Importing untrained model
2025-10-28 11:09:42,164:INFO:Naive Bayes Imported successfully
2025-10-28 11:09:42,164:INFO:Starting cross validation
2025-10-28 11:09:42,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,295:INFO:Calculating mean and std
2025-10-28 11:09:42,297:INFO:Creating metrics dataframe
2025-10-28 11:09:42,302:INFO:Uploading results into container
2025-10-28 11:09:42,302:INFO:Uploading model into container now
2025-10-28 11:09:42,304:INFO:_master_model_container: 3
2025-10-28 11:09:42,304:INFO:_display_container: 2
2025-10-28 11:09:42,305:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-28 11:09:42,305:INFO:create_model() successfully completed......................................
2025-10-28 11:09:42,449:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:42,450:INFO:Creating metrics dataframe
2025-10-28 11:09:42,458:INFO:Initializing Decision Tree Classifier
2025-10-28 11:09:42,458:INFO:Total runtime is 0.014404563109079997 minutes
2025-10-28 11:09:42,459:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:42,459:INFO:Initializing create_model()
2025-10-28 11:09:42,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:42,459:INFO:Checking exceptions
2025-10-28 11:09:42,461:INFO:Importing libraries
2025-10-28 11:09:42,461:INFO:Copying training dataset
2025-10-28 11:09:42,467:INFO:Defining folds
2025-10-28 11:09:42,468:INFO:Declaring metric variables
2025-10-28 11:09:42,468:INFO:Importing untrained model
2025-10-28 11:09:42,468:INFO:Decision Tree Classifier Imported successfully
2025-10-28 11:09:42,469:INFO:Starting cross validation
2025-10-28 11:09:42,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,596:INFO:Calculating mean and std
2025-10-28 11:09:42,598:INFO:Creating metrics dataframe
2025-10-28 11:09:42,601:INFO:Uploading results into container
2025-10-28 11:09:42,602:INFO:Uploading model into container now
2025-10-28 11:09:42,604:INFO:_master_model_container: 4
2025-10-28 11:09:42,604:INFO:_display_container: 2
2025-10-28 11:09:42,605:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-28 11:09:42,605:INFO:create_model() successfully completed......................................
2025-10-28 11:09:42,756:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:42,756:INFO:Creating metrics dataframe
2025-10-28 11:09:42,761:INFO:Initializing SVM - Linear Kernel
2025-10-28 11:09:42,762:INFO:Total runtime is 0.019458580017089843 minutes
2025-10-28 11:09:42,762:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:42,763:INFO:Initializing create_model()
2025-10-28 11:09:42,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:42,763:INFO:Checking exceptions
2025-10-28 11:09:42,763:INFO:Importing libraries
2025-10-28 11:09:42,763:INFO:Copying training dataset
2025-10-28 11:09:42,768:INFO:Defining folds
2025-10-28 11:09:42,768:INFO:Declaring metric variables
2025-10-28 11:09:42,768:INFO:Importing untrained model
2025-10-28 11:09:42,769:INFO:SVM - Linear Kernel Imported successfully
2025-10-28 11:09:42,769:INFO:Starting cross validation
2025-10-28 11:09:42,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,864:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,864:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,867:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,867:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,868:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,870:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,871:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,871:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,873:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,877:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,879:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,881:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,884:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,887:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,888:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,902:INFO:Calculating mean and std
2025-10-28 11:09:42,903:INFO:Creating metrics dataframe
2025-10-28 11:09:42,905:INFO:Uploading results into container
2025-10-28 11:09:42,906:INFO:Uploading model into container now
2025-10-28 11:09:42,906:INFO:_master_model_container: 5
2025-10-28 11:09:42,906:INFO:_display_container: 2
2025-10-28 11:09:42,907:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-28 11:09:42,907:INFO:create_model() successfully completed......................................
2025-10-28 11:09:43,029:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:43,029:INFO:Creating metrics dataframe
2025-10-28 11:09:43,036:INFO:Initializing Ridge Classifier
2025-10-28 11:09:43,036:INFO:Total runtime is 0.02403590679168701 minutes
2025-10-28 11:09:43,037:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:43,037:INFO:Initializing create_model()
2025-10-28 11:09:43,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:43,038:INFO:Checking exceptions
2025-10-28 11:09:43,038:INFO:Importing libraries
2025-10-28 11:09:43,038:INFO:Copying training dataset
2025-10-28 11:09:43,046:INFO:Defining folds
2025-10-28 11:09:43,046:INFO:Declaring metric variables
2025-10-28 11:09:43,046:INFO:Importing untrained model
2025-10-28 11:09:43,046:INFO:Ridge Classifier Imported successfully
2025-10-28 11:09:43,047:INFO:Starting cross validation
2025-10-28 11:09:43,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:43,108:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,109:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,109:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,110:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,110:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,114:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,117:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,118:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,129:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,135:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,154:INFO:Calculating mean and std
2025-10-28 11:09:43,155:INFO:Creating metrics dataframe
2025-10-28 11:09:43,160:INFO:Uploading results into container
2025-10-28 11:09:43,161:INFO:Uploading model into container now
2025-10-28 11:09:43,162:INFO:_master_model_container: 6
2025-10-28 11:09:43,162:INFO:_display_container: 2
2025-10-28 11:09:43,162:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-28 11:09:43,162:INFO:create_model() successfully completed......................................
2025-10-28 11:09:43,306:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:43,306:INFO:Creating metrics dataframe
2025-10-28 11:09:43,309:INFO:Initializing Random Forest Classifier
2025-10-28 11:09:43,309:INFO:Total runtime is 0.028588700294494628 minutes
2025-10-28 11:09:43,310:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:43,310:INFO:Initializing create_model()
2025-10-28 11:09:43,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:43,311:INFO:Checking exceptions
2025-10-28 11:09:43,311:INFO:Importing libraries
2025-10-28 11:09:43,311:INFO:Copying training dataset
2025-10-28 11:09:43,321:INFO:Defining folds
2025-10-28 11:09:43,321:INFO:Declaring metric variables
2025-10-28 11:09:43,322:INFO:Importing untrained model
2025-10-28 11:09:43,322:INFO:Random Forest Classifier Imported successfully
2025-10-28 11:09:43,322:INFO:Starting cross validation
2025-10-28 11:09:43,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:43,683:INFO:Calculating mean and std
2025-10-28 11:09:43,684:INFO:Creating metrics dataframe
2025-10-28 11:09:43,686:INFO:Uploading results into container
2025-10-28 11:09:43,686:INFO:Uploading model into container now
2025-10-28 11:09:43,687:INFO:_master_model_container: 7
2025-10-28 11:09:43,687:INFO:_display_container: 2
2025-10-28 11:09:43,688:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-28 11:09:43,688:INFO:create_model() successfully completed......................................
2025-10-28 11:09:43,816:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:43,816:INFO:Creating metrics dataframe
2025-10-28 11:09:43,822:INFO:Initializing Quadratic Discriminant Analysis
2025-10-28 11:09:43,822:INFO:Total runtime is 0.0371234933535258 minutes
2025-10-28 11:09:43,823:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:43,824:INFO:Initializing create_model()
2025-10-28 11:09:43,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:43,825:INFO:Checking exceptions
2025-10-28 11:09:43,825:INFO:Importing libraries
2025-10-28 11:09:43,825:INFO:Copying training dataset
2025-10-28 11:09:43,831:INFO:Defining folds
2025-10-28 11:09:43,831:INFO:Declaring metric variables
2025-10-28 11:09:43,832:INFO:Importing untrained model
2025-10-28 11:09:43,832:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-28 11:09:43,832:INFO:Starting cross validation
2025-10-28 11:09:43,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:43,916:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,918:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,919:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,923:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,931:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,934:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,936:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,936:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,937:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,944:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,964:INFO:Calculating mean and std
2025-10-28 11:09:43,966:INFO:Creating metrics dataframe
2025-10-28 11:09:43,969:INFO:Uploading results into container
2025-10-28 11:09:43,970:INFO:Uploading model into container now
2025-10-28 11:09:43,970:INFO:_master_model_container: 8
2025-10-28 11:09:43,971:INFO:_display_container: 2
2025-10-28 11:09:43,971:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-28 11:09:43,971:INFO:create_model() successfully completed......................................
2025-10-28 11:09:44,090:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:44,090:INFO:Creating metrics dataframe
2025-10-28 11:09:44,094:INFO:Initializing Ada Boost Classifier
2025-10-28 11:09:44,094:INFO:Total runtime is 0.04166093667348226 minutes
2025-10-28 11:09:44,094:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:44,095:INFO:Initializing create_model()
2025-10-28 11:09:44,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:44,095:INFO:Checking exceptions
2025-10-28 11:09:44,095:INFO:Importing libraries
2025-10-28 11:09:44,095:INFO:Copying training dataset
2025-10-28 11:09:44,098:INFO:Defining folds
2025-10-28 11:09:44,098:INFO:Declaring metric variables
2025-10-28 11:09:44,099:INFO:Importing untrained model
2025-10-28 11:09:44,099:INFO:Ada Boost Classifier Imported successfully
2025-10-28 11:09:44,099:INFO:Starting cross validation
2025-10-28 11:09:44,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:44,122:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,127:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,129:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,134:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,136:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,139:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,142:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,145:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,147:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,148:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,304:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,311:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,313:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,314:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,315:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,322:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,322:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,324:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,325:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,330:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,351:INFO:Calculating mean and std
2025-10-28 11:09:44,352:INFO:Creating metrics dataframe
2025-10-28 11:09:44,354:INFO:Uploading results into container
2025-10-28 11:09:44,355:INFO:Uploading model into container now
2025-10-28 11:09:44,355:INFO:_master_model_container: 9
2025-10-28 11:09:44,356:INFO:_display_container: 2
2025-10-28 11:09:44,356:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-28 11:09:44,356:INFO:create_model() successfully completed......................................
2025-10-28 11:09:44,497:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:44,497:INFO:Creating metrics dataframe
2025-10-28 11:09:44,504:INFO:Initializing Gradient Boosting Classifier
2025-10-28 11:09:44,504:INFO:Total runtime is 0.04849430322647095 minutes
2025-10-28 11:09:44,505:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:44,505:INFO:Initializing create_model()
2025-10-28 11:09:44,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:44,505:INFO:Checking exceptions
2025-10-28 11:09:44,505:INFO:Importing libraries
2025-10-28 11:09:44,506:INFO:Copying training dataset
2025-10-28 11:09:44,512:INFO:Defining folds
2025-10-28 11:09:44,512:INFO:Declaring metric variables
2025-10-28 11:09:44,512:INFO:Importing untrained model
2025-10-28 11:09:44,512:INFO:Gradient Boosting Classifier Imported successfully
2025-10-28 11:09:44,514:INFO:Starting cross validation
2025-10-28 11:09:44,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:44,967:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,974:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,979:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,982:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,990:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,995:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,001:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,001:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,034:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,057:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,076:INFO:Calculating mean and std
2025-10-28 11:09:45,078:INFO:Creating metrics dataframe
2025-10-28 11:09:45,081:INFO:Uploading results into container
2025-10-28 11:09:45,082:INFO:Uploading model into container now
2025-10-28 11:09:45,082:INFO:_master_model_container: 10
2025-10-28 11:09:45,082:INFO:_display_container: 2
2025-10-28 11:09:45,084:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-28 11:09:45,084:INFO:create_model() successfully completed......................................
2025-10-28 11:09:45,237:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:45,237:INFO:Creating metrics dataframe
2025-10-28 11:09:45,242:INFO:Initializing Linear Discriminant Analysis
2025-10-28 11:09:45,242:INFO:Total runtime is 0.060796531041463216 minutes
2025-10-28 11:09:45,242:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:45,242:INFO:Initializing create_model()
2025-10-28 11:09:45,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:45,242:INFO:Checking exceptions
2025-10-28 11:09:45,242:INFO:Importing libraries
2025-10-28 11:09:45,242:INFO:Copying training dataset
2025-10-28 11:09:45,247:INFO:Defining folds
2025-10-28 11:09:45,247:INFO:Declaring metric variables
2025-10-28 11:09:45,247:INFO:Importing untrained model
2025-10-28 11:09:45,247:INFO:Linear Discriminant Analysis Imported successfully
2025-10-28 11:09:45,247:INFO:Starting cross validation
2025-10-28 11:09:45,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:45,300:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,300:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,301:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,302:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,303:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,304:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,306:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,307:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,310:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,310:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,334:INFO:Calculating mean and std
2025-10-28 11:09:45,336:INFO:Creating metrics dataframe
2025-10-28 11:09:45,340:INFO:Uploading results into container
2025-10-28 11:09:45,341:INFO:Uploading model into container now
2025-10-28 11:09:45,342:INFO:_master_model_container: 11
2025-10-28 11:09:45,342:INFO:_display_container: 2
2025-10-28 11:09:45,342:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-28 11:09:45,344:INFO:create_model() successfully completed......................................
2025-10-28 11:09:45,479:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:45,480:INFO:Creating metrics dataframe
2025-10-28 11:09:45,487:INFO:Initializing Extra Trees Classifier
2025-10-28 11:09:45,488:INFO:Total runtime is 0.06489071846008301 minutes
2025-10-28 11:09:45,488:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:45,488:INFO:Initializing create_model()
2025-10-28 11:09:45,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:45,489:INFO:Checking exceptions
2025-10-28 11:09:45,489:INFO:Importing libraries
2025-10-28 11:09:45,490:INFO:Copying training dataset
2025-10-28 11:09:45,495:INFO:Defining folds
2025-10-28 11:09:45,495:INFO:Declaring metric variables
2025-10-28 11:09:45,495:INFO:Importing untrained model
2025-10-28 11:09:45,496:INFO:Extra Trees Classifier Imported successfully
2025-10-28 11:09:45,496:INFO:Starting cross validation
2025-10-28 11:09:45,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:45,800:INFO:Calculating mean and std
2025-10-28 11:09:45,801:INFO:Creating metrics dataframe
2025-10-28 11:09:45,805:INFO:Uploading results into container
2025-10-28 11:09:45,805:INFO:Uploading model into container now
2025-10-28 11:09:45,806:INFO:_master_model_container: 12
2025-10-28 11:09:45,806:INFO:_display_container: 2
2025-10-28 11:09:45,807:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-28 11:09:45,807:INFO:create_model() successfully completed......................................
2025-10-28 11:09:45,938:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:45,938:INFO:Creating metrics dataframe
2025-10-28 11:09:45,943:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 11:09:45,943:INFO:Total runtime is 0.07247526248296103 minutes
2025-10-28 11:09:45,943:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:45,944:INFO:Initializing create_model()
2025-10-28 11:09:45,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:45,944:INFO:Checking exceptions
2025-10-28 11:09:45,944:INFO:Importing libraries
2025-10-28 11:09:45,944:INFO:Copying training dataset
2025-10-28 11:09:45,950:INFO:Defining folds
2025-10-28 11:09:45,950:INFO:Declaring metric variables
2025-10-28 11:09:45,950:INFO:Importing untrained model
2025-10-28 11:09:45,951:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 11:09:45,952:INFO:Starting cross validation
2025-10-28 11:09:45,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:46,979:INFO:Calculating mean and std
2025-10-28 11:09:46,979:INFO:Creating metrics dataframe
2025-10-28 11:09:46,981:INFO:Uploading results into container
2025-10-28 11:09:46,982:INFO:Uploading model into container now
2025-10-28 11:09:46,982:INFO:_master_model_container: 13
2025-10-28 11:09:46,982:INFO:_display_container: 2
2025-10-28 11:09:46,984:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-28 11:09:46,984:INFO:create_model() successfully completed......................................
2025-10-28 11:09:47,089:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:47,089:INFO:Creating metrics dataframe
2025-10-28 11:09:47,094:INFO:Initializing Dummy Classifier
2025-10-28 11:09:47,095:INFO:Total runtime is 0.09168450435002645 minutes
2025-10-28 11:09:47,095:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:47,095:INFO:Initializing create_model()
2025-10-28 11:09:47,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:47,095:INFO:Checking exceptions
2025-10-28 11:09:47,095:INFO:Importing libraries
2025-10-28 11:09:47,096:INFO:Copying training dataset
2025-10-28 11:09:47,104:INFO:Defining folds
2025-10-28 11:09:47,104:INFO:Declaring metric variables
2025-10-28 11:09:47,105:INFO:Importing untrained model
2025-10-28 11:09:47,105:INFO:Dummy Classifier Imported successfully
2025-10-28 11:09:47,105:INFO:Starting cross validation
2025-10-28 11:09:47,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:47,180:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,182:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,189:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,191:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,192:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,194:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,201:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,206:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,206:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,208:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,220:INFO:Calculating mean and std
2025-10-28 11:09:47,221:INFO:Creating metrics dataframe
2025-10-28 11:09:47,224:INFO:Uploading results into container
2025-10-28 11:09:47,225:INFO:Uploading model into container now
2025-10-28 11:09:47,225:INFO:_master_model_container: 14
2025-10-28 11:09:47,226:INFO:_display_container: 2
2025-10-28 11:09:47,226:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-28 11:09:47,226:INFO:create_model() successfully completed......................................
2025-10-28 11:09:47,361:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:47,361:INFO:Creating metrics dataframe
2025-10-28 11:09:47,368:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 11:09:47,372:INFO:Initializing create_model()
2025-10-28 11:09:47,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:47,372:INFO:Checking exceptions
2025-10-28 11:09:47,374:INFO:Importing libraries
2025-10-28 11:09:47,374:INFO:Copying training dataset
2025-10-28 11:09:47,379:INFO:Defining folds
2025-10-28 11:09:47,379:INFO:Declaring metric variables
2025-10-28 11:09:47,379:INFO:Importing untrained model
2025-10-28 11:09:47,379:INFO:Declaring custom model
2025-10-28 11:09:47,380:INFO:Logistic Regression Imported successfully
2025-10-28 11:09:47,382:INFO:Cross validation set to False
2025-10-28 11:09:47,382:INFO:Fitting Model
2025-10-28 11:09:47,422:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:09:47,422:INFO:create_model() successfully completed......................................
2025-10-28 11:09:47,561:INFO:_master_model_container: 14
2025-10-28 11:09:47,561:INFO:_display_container: 2
2025-10-28 11:09:47,562:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:09:47,562:INFO:compare_models() successfully completed......................................
2025-10-28 11:09:47,567:INFO:Initializing plot_model()
2025-10-28 11:09:47,567:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-10-28 11:09:47,567:INFO:Checking exceptions
2025-10-28 11:09:47,567:INFO:Soft dependency imported: streamlit: 1.50.0
2025-10-28 11:09:47,568:INFO:Preloading libraries
2025-10-28 11:09:47,569:INFO:Copying training dataset
2025-10-28 11:09:47,569:INFO:Plot type: feature
2025-10-28 11:09:47,666:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

2025-10-28 11:09:47,666:INFO:Visual Rendered Successfully
2025-10-28 11:09:47,834:INFO:plot_model() successfully completed......................................
2025-10-28 13:23:42,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:23:42,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:23:42,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:23:42,944:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:29:33,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:29:33,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:29:33,311:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:29:33,315:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 13:33:34,010:INFO:PyCaret RegressionExperiment
2025-10-28 13:33:34,010:INFO:Logging name: reg-default-name
2025-10-28 13:33:34,010:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 13:33:34,010:INFO:version 3.3.2
2025-10-28 13:33:34,010:INFO:Initializing setup()
2025-10-28 13:33:34,010:INFO:self.USI: ca24
2025-10-28 13:33:34,010:INFO:self._variable_keys: {'_ml_usecase', 'y_train', 'data', 'fold_generator', 'fold_shuffle_param', 'log_plots_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X', 'USI', 'gpu_param', 'transform_target_param', 'X_test', 'exp_id', 'html_param', '_available_plots', 'memory', 'idx', 'target_param', 'y_test', 'seed', 'exp_name_log', 'pipeline', 'logging_param', 'n_jobs_param', 'y', 'X_train'}
2025-10-28 13:33:34,010:INFO:Checking environment
2025-10-28 13:33:34,010:INFO:python_version: 3.11.14
2025-10-28 13:33:34,010:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 13:33:34,010:INFO:machine: AMD64
2025-10-28 13:33:34,010:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 13:33:34,010:INFO:Memory: svmem(total=16788250624, available=4016431104, percent=76.1, used=12771819520, free=4016431104)
2025-10-28 13:33:34,010:INFO:Physical Core: 12
2025-10-28 13:33:34,010:INFO:Logical Core: 16
2025-10-28 13:33:34,010:INFO:Checking libraries
2025-10-28 13:33:34,010:INFO:System:
2025-10-28 13:33:34,010:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 13:33:34,010:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 13:33:34,010:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 13:33:34,010:INFO:PyCaret required dependencies:
2025-10-28 13:33:34,020:INFO:                 pip: 25.2
2025-10-28 13:33:34,020:INFO:          setuptools: 80.9.0
2025-10-28 13:33:34,020:INFO:             pycaret: 3.3.2
2025-10-28 13:33:34,020:INFO:             IPython: 9.6.0
2025-10-28 13:33:34,020:INFO:          ipywidgets: 8.1.7
2025-10-28 13:33:34,020:INFO:                tqdm: 4.67.1
2025-10-28 13:33:34,020:INFO:               numpy: 1.26.4
2025-10-28 13:33:34,020:INFO:              pandas: 2.1.4
2025-10-28 13:33:34,020:INFO:              jinja2: 3.1.6
2025-10-28 13:33:34,020:INFO:               scipy: 1.11.4
2025-10-28 13:33:34,020:INFO:              joblib: 1.3.2
2025-10-28 13:33:34,020:INFO:             sklearn: 1.4.2
2025-10-28 13:33:34,020:INFO:                pyod: 2.0.5
2025-10-28 13:33:34,020:INFO:            imblearn: 0.14.0
2025-10-28 13:33:34,020:INFO:   category_encoders: 2.7.0
2025-10-28 13:33:34,020:INFO:            lightgbm: 4.6.0
2025-10-28 13:33:34,020:INFO:               numba: 0.62.1
2025-10-28 13:33:34,020:INFO:            requests: 2.32.5
2025-10-28 13:33:34,020:INFO:          matplotlib: 3.10.7
2025-10-28 13:33:34,020:INFO:          scikitplot: 0.3.7
2025-10-28 13:33:34,020:INFO:         yellowbrick: 1.5
2025-10-28 13:33:34,020:INFO:              plotly: 6.3.1
2025-10-28 13:33:34,020:INFO:    plotly-resampler: Not installed
2025-10-28 13:33:34,020:INFO:             kaleido: 0.2.1
2025-10-28 13:33:34,020:INFO:           schemdraw: 0.15
2025-10-28 13:33:34,020:INFO:         statsmodels: 0.14.5
2025-10-28 13:33:34,020:INFO:              sktime: 0.26.0
2025-10-28 13:33:34,020:INFO:               tbats: 1.1.3
2025-10-28 13:33:34,020:INFO:            pmdarima: 2.0.4
2025-10-28 13:33:34,020:INFO:              psutil: 7.1.1
2025-10-28 13:33:34,020:INFO:          markupsafe: 3.0.3
2025-10-28 13:33:34,020:INFO:             pickle5: Not installed
2025-10-28 13:33:34,020:INFO:         cloudpickle: 3.1.1
2025-10-28 13:33:34,020:INFO:         deprecation: 2.1.0
2025-10-28 13:33:34,020:INFO:              xxhash: 3.6.0
2025-10-28 13:33:34,020:INFO:           wurlitzer: 3.1.1
2025-10-28 13:33:34,020:INFO:PyCaret optional dependencies:
2025-10-28 13:33:34,030:INFO:                shap: Not installed
2025-10-28 13:33:34,030:INFO:           interpret: Not installed
2025-10-28 13:33:34,030:INFO:                umap: 0.5.9.post2
2025-10-28 13:33:34,030:INFO:     ydata_profiling: Not installed
2025-10-28 13:33:34,030:INFO:  explainerdashboard: Not installed
2025-10-28 13:33:34,030:INFO:             autoviz: Not installed
2025-10-28 13:33:34,030:INFO:           fairlearn: Not installed
2025-10-28 13:33:34,030:INFO:          deepchecks: Not installed
2025-10-28 13:33:34,030:INFO:             xgboost: Not installed
2025-10-28 13:33:34,030:INFO:            catboost: Not installed
2025-10-28 13:33:34,030:INFO:              kmodes: Not installed
2025-10-28 13:33:34,030:INFO:             mlxtend: Not installed
2025-10-28 13:33:34,030:INFO:       statsforecast: Not installed
2025-10-28 13:33:34,030:INFO:        tune_sklearn: Not installed
2025-10-28 13:33:34,030:INFO:                 ray: Not installed
2025-10-28 13:33:34,030:INFO:            hyperopt: Not installed
2025-10-28 13:33:34,030:INFO:              optuna: Not installed
2025-10-28 13:33:34,030:INFO:               skopt: Not installed
2025-10-28 13:33:34,030:INFO:              mlflow: Not installed
2025-10-28 13:33:34,030:INFO:              gradio: Not installed
2025-10-28 13:33:34,030:INFO:             fastapi: Not installed
2025-10-28 13:33:34,030:INFO:             uvicorn: Not installed
2025-10-28 13:33:34,030:INFO:              m2cgen: Not installed
2025-10-28 13:33:34,030:INFO:           evidently: Not installed
2025-10-28 13:33:34,030:INFO:               fugue: Not installed
2025-10-28 13:33:34,030:INFO:           streamlit: 1.50.0
2025-10-28 13:33:34,030:INFO:             prophet: Not installed
2025-10-28 13:33:34,030:INFO:None
2025-10-28 13:33:34,030:INFO:Set up data.
2025-10-28 13:33:34,040:INFO:Set up folding strategy.
2025-10-28 13:33:34,040:INFO:Set up train/test split.
2025-10-28 13:33:34,051:INFO:Set up index.
2025-10-28 13:33:34,056:INFO:Assigning column types.
2025-10-28 13:33:34,060:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 13:33:34,060:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,072:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,081:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,153:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,199:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,199:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,289:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,290:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,293:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,300:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,350:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,390:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,390:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 13:33:34,396:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,400:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,450:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,490:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,490:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,500:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,504:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,510:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,564:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,607:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,609:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,609:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 13:33:34,613:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,727:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,730:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,730:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,740:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,830:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,893:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:34,895:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,895:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:34,897:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 13:33:35,000:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:35,060:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:35,060:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,155:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:35,220:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:33:35,220:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,220:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,220:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 13:33:35,298:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:35,365:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,365:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,436:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:33:35,480:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,480:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,480:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 13:33:35,601:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,601:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,721:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,721:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:35,728:INFO:Preparing preprocessing pipeline...
2025-10-28 13:33:35,728:INFO:Set up simple imputation.
2025-10-28 13:33:35,765:INFO:Finished creating preprocessing pipeline.
2025-10-28 13:33:35,770:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['HouseAge', 'AveRooms',
                                             'AveBedrms', 'Population',
                                             'AveOccup', 'Latitude',
                                             'Longitude', 'MedHouseVal'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent')))])
2025-10-28 13:33:35,770:INFO:Creating final display dataframe.
2025-10-28 13:33:35,854:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            MedInc
2                   Target type        Regression
3           Original data shape        (20640, 9)
4        Transformed data shape        (20640, 9)
5   Transformed train set shape        (14447, 9)
6    Transformed test set shape         (6193, 9)
7              Numeric features                 8
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator             KFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  reg-default-name
18                          USI              ca24
2025-10-28 13:33:36,020:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:36,020:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:36,186:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:36,190:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:33:36,190:INFO:setup() successfully completed in 2.19s...............
2025-10-28 13:33:36,190:INFO:Initializing compare_models()
2025-10-28 13:33:36,190:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 13:33:36,190:INFO:Checking exceptions
2025-10-28 13:33:36,190:INFO:Preparing display monitor
2025-10-28 13:33:36,200:INFO:Initializing Linear Regression
2025-10-28 13:33:36,200:INFO:Total runtime is 0.0 minutes
2025-10-28 13:33:36,200:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:36,200:INFO:Initializing create_model()
2025-10-28 13:33:36,200:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:36,200:INFO:Checking exceptions
2025-10-28 13:33:36,200:INFO:Importing libraries
2025-10-28 13:33:36,200:INFO:Copying training dataset
2025-10-28 13:33:36,210:INFO:Defining folds
2025-10-28 13:33:36,210:INFO:Declaring metric variables
2025-10-28 13:33:36,210:INFO:Importing untrained model
2025-10-28 13:33:36,210:INFO:Linear Regression Imported successfully
2025-10-28 13:33:36,210:INFO:Starting cross validation
2025-10-28 13:33:36,230:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:40,188:INFO:Calculating mean and std
2025-10-28 13:33:40,190:INFO:Creating metrics dataframe
2025-10-28 13:33:40,194:INFO:Uploading results into container
2025-10-28 13:33:40,196:INFO:Uploading model into container now
2025-10-28 13:33:40,196:INFO:_master_model_container: 1
2025-10-28 13:33:40,196:INFO:_display_container: 2
2025-10-28 13:33:40,198:INFO:LinearRegression(n_jobs=-1)
2025-10-28 13:33:40,198:INFO:create_model() successfully completed......................................
2025-10-28 13:33:40,340:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:40,340:INFO:Creating metrics dataframe
2025-10-28 13:33:40,340:INFO:Initializing Lasso Regression
2025-10-28 13:33:40,340:INFO:Total runtime is 0.06899954875310262 minutes
2025-10-28 13:33:40,340:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:40,340:INFO:Initializing create_model()
2025-10-28 13:33:40,340:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:40,340:INFO:Checking exceptions
2025-10-28 13:33:40,340:INFO:Importing libraries
2025-10-28 13:33:40,340:INFO:Copying training dataset
2025-10-28 13:33:40,365:INFO:Defining folds
2025-10-28 13:33:40,365:INFO:Declaring metric variables
2025-10-28 13:33:40,365:INFO:Importing untrained model
2025-10-28 13:33:40,365:INFO:Lasso Regression Imported successfully
2025-10-28 13:33:40,365:INFO:Starting cross validation
2025-10-28 13:33:40,365:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:42,917:INFO:Calculating mean and std
2025-10-28 13:33:42,917:INFO:Creating metrics dataframe
2025-10-28 13:33:42,923:INFO:Uploading results into container
2025-10-28 13:33:42,923:INFO:Uploading model into container now
2025-10-28 13:33:42,923:INFO:_master_model_container: 2
2025-10-28 13:33:42,923:INFO:_display_container: 2
2025-10-28 13:33:42,925:INFO:Lasso(random_state=123)
2025-10-28 13:33:42,925:INFO:create_model() successfully completed......................................
2025-10-28 13:33:43,070:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:43,070:INFO:Creating metrics dataframe
2025-10-28 13:33:43,070:INFO:Initializing Ridge Regression
2025-10-28 13:33:43,070:INFO:Total runtime is 0.1145001212755839 minutes
2025-10-28 13:33:43,070:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:43,070:INFO:Initializing create_model()
2025-10-28 13:33:43,070:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:43,080:INFO:Checking exceptions
2025-10-28 13:33:43,080:INFO:Importing libraries
2025-10-28 13:33:43,080:INFO:Copying training dataset
2025-10-28 13:33:43,090:INFO:Defining folds
2025-10-28 13:33:43,090:INFO:Declaring metric variables
2025-10-28 13:33:43,098:INFO:Importing untrained model
2025-10-28 13:33:43,098:INFO:Ridge Regression Imported successfully
2025-10-28 13:33:43,098:INFO:Starting cross validation
2025-10-28 13:33:43,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:43,134:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=2.95944e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,140:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.30713e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,140:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.32291e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,145:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.33345e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,153:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.42935e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,158:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.28953e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,165:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.24778e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,170:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.27353e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,178:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.26922e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,180:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_ridge.py:204: LinAlgWarning: Ill-conditioned matrix (rcond=3.40276e-08): result may not be accurate.
  return linalg.solve(A, Xy, assume_a="pos", overwrite_a=True).T

2025-10-28 13:33:43,189:INFO:Calculating mean and std
2025-10-28 13:33:43,190:INFO:Creating metrics dataframe
2025-10-28 13:33:43,192:INFO:Uploading results into container
2025-10-28 13:33:43,192:INFO:Uploading model into container now
2025-10-28 13:33:43,192:INFO:_master_model_container: 3
2025-10-28 13:33:43,192:INFO:_display_container: 2
2025-10-28 13:33:43,192:INFO:Ridge(random_state=123)
2025-10-28 13:33:43,192:INFO:create_model() successfully completed......................................
2025-10-28 13:33:43,315:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:43,315:INFO:Creating metrics dataframe
2025-10-28 13:33:43,320:INFO:Initializing Elastic Net
2025-10-28 13:33:43,320:INFO:Total runtime is 0.11866493225097656 minutes
2025-10-28 13:33:43,320:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:43,320:INFO:Initializing create_model()
2025-10-28 13:33:43,320:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:43,320:INFO:Checking exceptions
2025-10-28 13:33:43,320:INFO:Importing libraries
2025-10-28 13:33:43,320:INFO:Copying training dataset
2025-10-28 13:33:43,336:INFO:Defining folds
2025-10-28 13:33:43,336:INFO:Declaring metric variables
2025-10-28 13:33:43,336:INFO:Importing untrained model
2025-10-28 13:33:43,336:INFO:Elastic Net Imported successfully
2025-10-28 13:33:43,336:INFO:Starting cross validation
2025-10-28 13:33:43,336:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:43,415:INFO:Calculating mean and std
2025-10-28 13:33:43,415:INFO:Creating metrics dataframe
2025-10-28 13:33:43,415:INFO:Uploading results into container
2025-10-28 13:33:43,420:INFO:Uploading model into container now
2025-10-28 13:33:43,420:INFO:_master_model_container: 4
2025-10-28 13:33:43,420:INFO:_display_container: 2
2025-10-28 13:33:43,420:INFO:ElasticNet(random_state=123)
2025-10-28 13:33:43,420:INFO:create_model() successfully completed......................................
2025-10-28 13:33:43,542:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:43,542:INFO:Creating metrics dataframe
2025-10-28 13:33:43,552:INFO:Initializing Least Angle Regression
2025-10-28 13:33:43,552:INFO:Total runtime is 0.12253210544586181 minutes
2025-10-28 13:33:43,552:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:43,554:INFO:Initializing create_model()
2025-10-28 13:33:43,554:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:43,554:INFO:Checking exceptions
2025-10-28 13:33:43,554:INFO:Importing libraries
2025-10-28 13:33:43,554:INFO:Copying training dataset
2025-10-28 13:33:43,574:INFO:Defining folds
2025-10-28 13:33:43,574:INFO:Declaring metric variables
2025-10-28 13:33:43,574:INFO:Importing untrained model
2025-10-28 13:33:43,574:INFO:Least Angle Regression Imported successfully
2025-10-28 13:33:43,574:INFO:Starting cross validation
2025-10-28 13:33:43,574:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:43,674:INFO:Calculating mean and std
2025-10-28 13:33:43,674:INFO:Creating metrics dataframe
2025-10-28 13:33:43,674:INFO:Uploading results into container
2025-10-28 13:33:43,674:INFO:Uploading model into container now
2025-10-28 13:33:43,674:INFO:_master_model_container: 5
2025-10-28 13:33:43,674:INFO:_display_container: 2
2025-10-28 13:33:43,674:INFO:Lars(random_state=123)
2025-10-28 13:33:43,674:INFO:create_model() successfully completed......................................
2025-10-28 13:33:43,772:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:43,772:INFO:Creating metrics dataframe
2025-10-28 13:33:43,772:INFO:Initializing Lasso Least Angle Regression
2025-10-28 13:33:43,772:INFO:Total runtime is 0.1262035051981608 minutes
2025-10-28 13:33:43,772:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:43,772:INFO:Initializing create_model()
2025-10-28 13:33:43,772:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:43,772:INFO:Checking exceptions
2025-10-28 13:33:43,772:INFO:Importing libraries
2025-10-28 13:33:43,772:INFO:Copying training dataset
2025-10-28 13:33:43,780:INFO:Defining folds
2025-10-28 13:33:43,780:INFO:Declaring metric variables
2025-10-28 13:33:43,780:INFO:Importing untrained model
2025-10-28 13:33:43,780:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 13:33:43,780:INFO:Starting cross validation
2025-10-28 13:33:43,790:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:43,888:INFO:Calculating mean and std
2025-10-28 13:33:43,888:INFO:Creating metrics dataframe
2025-10-28 13:33:43,891:INFO:Uploading results into container
2025-10-28 13:33:43,891:INFO:Uploading model into container now
2025-10-28 13:33:43,891:INFO:_master_model_container: 6
2025-10-28 13:33:43,891:INFO:_display_container: 2
2025-10-28 13:33:43,891:INFO:LassoLars(random_state=123)
2025-10-28 13:33:43,891:INFO:create_model() successfully completed......................................
2025-10-28 13:33:43,990:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:43,990:INFO:Creating metrics dataframe
2025-10-28 13:33:44,002:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 13:33:44,002:INFO:Total runtime is 0.13002667427062986 minutes
2025-10-28 13:33:44,002:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:44,002:INFO:Initializing create_model()
2025-10-28 13:33:44,002:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:44,002:INFO:Checking exceptions
2025-10-28 13:33:44,002:INFO:Importing libraries
2025-10-28 13:33:44,002:INFO:Copying training dataset
2025-10-28 13:33:44,010:INFO:Defining folds
2025-10-28 13:33:44,010:INFO:Declaring metric variables
2025-10-28 13:33:44,010:INFO:Importing untrained model
2025-10-28 13:33:44,010:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 13:33:44,010:INFO:Starting cross validation
2025-10-28 13:33:44,010:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:44,097:INFO:Calculating mean and std
2025-10-28 13:33:44,097:INFO:Creating metrics dataframe
2025-10-28 13:33:44,100:INFO:Uploading results into container
2025-10-28 13:33:44,100:INFO:Uploading model into container now
2025-10-28 13:33:44,100:INFO:_master_model_container: 7
2025-10-28 13:33:44,100:INFO:_display_container: 2
2025-10-28 13:33:44,100:INFO:OrthogonalMatchingPursuit()
2025-10-28 13:33:44,100:INFO:create_model() successfully completed......................................
2025-10-28 13:33:44,225:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:44,225:INFO:Creating metrics dataframe
2025-10-28 13:33:44,232:INFO:Initializing Bayesian Ridge
2025-10-28 13:33:44,232:INFO:Total runtime is 0.13386499484380085 minutes
2025-10-28 13:33:44,232:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:44,232:INFO:Initializing create_model()
2025-10-28 13:33:44,234:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:44,234:INFO:Checking exceptions
2025-10-28 13:33:44,234:INFO:Importing libraries
2025-10-28 13:33:44,234:INFO:Copying training dataset
2025-10-28 13:33:44,250:INFO:Defining folds
2025-10-28 13:33:44,250:INFO:Declaring metric variables
2025-10-28 13:33:44,250:INFO:Importing untrained model
2025-10-28 13:33:44,250:INFO:Bayesian Ridge Imported successfully
2025-10-28 13:33:44,254:INFO:Starting cross validation
2025-10-28 13:33:44,256:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:44,347:INFO:Calculating mean and std
2025-10-28 13:33:44,347:INFO:Creating metrics dataframe
2025-10-28 13:33:44,350:INFO:Uploading results into container
2025-10-28 13:33:44,350:INFO:Uploading model into container now
2025-10-28 13:33:44,350:INFO:_master_model_container: 8
2025-10-28 13:33:44,350:INFO:_display_container: 2
2025-10-28 13:33:44,350:INFO:BayesianRidge()
2025-10-28 13:33:44,350:INFO:create_model() successfully completed......................................
2025-10-28 13:33:44,470:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:44,470:INFO:Creating metrics dataframe
2025-10-28 13:33:44,470:INFO:Initializing Passive Aggressive Regressor
2025-10-28 13:33:44,470:INFO:Total runtime is 0.13783806562423706 minutes
2025-10-28 13:33:44,470:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:44,470:INFO:Initializing create_model()
2025-10-28 13:33:44,470:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:44,470:INFO:Checking exceptions
2025-10-28 13:33:44,470:INFO:Importing libraries
2025-10-28 13:33:44,470:INFO:Copying training dataset
2025-10-28 13:33:44,480:INFO:Defining folds
2025-10-28 13:33:44,480:INFO:Declaring metric variables
2025-10-28 13:33:44,480:INFO:Importing untrained model
2025-10-28 13:33:44,480:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 13:33:44,480:INFO:Starting cross validation
2025-10-28 13:33:44,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:44,601:INFO:Calculating mean and std
2025-10-28 13:33:44,601:INFO:Creating metrics dataframe
2025-10-28 13:33:44,604:INFO:Uploading results into container
2025-10-28 13:33:44,604:INFO:Uploading model into container now
2025-10-28 13:33:44,604:INFO:_master_model_container: 9
2025-10-28 13:33:44,604:INFO:_display_container: 2
2025-10-28 13:33:44,604:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-28 13:33:44,604:INFO:create_model() successfully completed......................................
2025-10-28 13:33:44,720:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:44,720:INFO:Creating metrics dataframe
2025-10-28 13:33:44,720:INFO:Initializing Huber Regressor
2025-10-28 13:33:44,720:INFO:Total runtime is 0.14200156132380168 minutes
2025-10-28 13:33:44,720:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:44,720:INFO:Initializing create_model()
2025-10-28 13:33:44,720:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:44,720:INFO:Checking exceptions
2025-10-28 13:33:44,720:INFO:Importing libraries
2025-10-28 13:33:44,720:INFO:Copying training dataset
2025-10-28 13:33:44,740:INFO:Defining folds
2025-10-28 13:33:44,740:INFO:Declaring metric variables
2025-10-28 13:33:44,740:INFO:Importing untrained model
2025-10-28 13:33:44,740:INFO:Huber Regressor Imported successfully
2025-10-28 13:33:44,740:INFO:Starting cross validation
2025-10-28 13:33:44,740:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:45,162:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,176:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,198:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,198:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,198:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,211:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,212:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,222:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,222:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,233:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 13:33:45,254:INFO:Calculating mean and std
2025-10-28 13:33:45,254:INFO:Creating metrics dataframe
2025-10-28 13:33:45,257:INFO:Uploading results into container
2025-10-28 13:33:45,260:INFO:Uploading model into container now
2025-10-28 13:33:45,260:INFO:_master_model_container: 10
2025-10-28 13:33:45,260:INFO:_display_container: 2
2025-10-28 13:33:45,260:INFO:HuberRegressor()
2025-10-28 13:33:45,260:INFO:create_model() successfully completed......................................
2025-10-28 13:33:45,366:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:45,366:INFO:Creating metrics dataframe
2025-10-28 13:33:45,371:INFO:Initializing K Neighbors Regressor
2025-10-28 13:33:45,371:INFO:Total runtime is 0.15283950567245483 minutes
2025-10-28 13:33:45,371:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:45,371:INFO:Initializing create_model()
2025-10-28 13:33:45,371:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:45,371:INFO:Checking exceptions
2025-10-28 13:33:45,371:INFO:Importing libraries
2025-10-28 13:33:45,371:INFO:Copying training dataset
2025-10-28 13:33:45,381:INFO:Defining folds
2025-10-28 13:33:45,381:INFO:Declaring metric variables
2025-10-28 13:33:45,381:INFO:Importing untrained model
2025-10-28 13:33:45,381:INFO:K Neighbors Regressor Imported successfully
2025-10-28 13:33:45,381:INFO:Starting cross validation
2025-10-28 13:33:45,381:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:45,542:INFO:Calculating mean and std
2025-10-28 13:33:45,542:INFO:Creating metrics dataframe
2025-10-28 13:33:45,542:INFO:Uploading results into container
2025-10-28 13:33:45,542:INFO:Uploading model into container now
2025-10-28 13:33:45,542:INFO:_master_model_container: 11
2025-10-28 13:33:45,542:INFO:_display_container: 2
2025-10-28 13:33:45,542:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 13:33:45,542:INFO:create_model() successfully completed......................................
2025-10-28 13:33:45,651:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:45,651:INFO:Creating metrics dataframe
2025-10-28 13:33:45,660:INFO:Initializing Decision Tree Regressor
2025-10-28 13:33:45,660:INFO:Total runtime is 0.15766661564509074 minutes
2025-10-28 13:33:45,660:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:45,660:INFO:Initializing create_model()
2025-10-28 13:33:45,660:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:45,660:INFO:Checking exceptions
2025-10-28 13:33:45,660:INFO:Importing libraries
2025-10-28 13:33:45,660:INFO:Copying training dataset
2025-10-28 13:33:45,670:INFO:Defining folds
2025-10-28 13:33:45,670:INFO:Declaring metric variables
2025-10-28 13:33:45,670:INFO:Importing untrained model
2025-10-28 13:33:45,670:INFO:Decision Tree Regressor Imported successfully
2025-10-28 13:33:45,670:INFO:Starting cross validation
2025-10-28 13:33:45,670:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:46,017:INFO:Calculating mean and std
2025-10-28 13:33:46,017:INFO:Creating metrics dataframe
2025-10-28 13:33:46,020:INFO:Uploading results into container
2025-10-28 13:33:46,020:INFO:Uploading model into container now
2025-10-28 13:33:46,020:INFO:_master_model_container: 12
2025-10-28 13:33:46,020:INFO:_display_container: 2
2025-10-28 13:33:46,020:INFO:DecisionTreeRegressor(random_state=123)
2025-10-28 13:33:46,020:INFO:create_model() successfully completed......................................
2025-10-28 13:33:46,130:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:46,130:INFO:Creating metrics dataframe
2025-10-28 13:33:46,130:INFO:Initializing Random Forest Regressor
2025-10-28 13:33:46,140:INFO:Total runtime is 0.16566596428553262 minutes
2025-10-28 13:33:46,140:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:46,140:INFO:Initializing create_model()
2025-10-28 13:33:46,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:46,140:INFO:Checking exceptions
2025-10-28 13:33:46,140:INFO:Importing libraries
2025-10-28 13:33:46,140:INFO:Copying training dataset
2025-10-28 13:33:46,150:INFO:Defining folds
2025-10-28 13:33:46,150:INFO:Declaring metric variables
2025-10-28 13:33:46,150:INFO:Importing untrained model
2025-10-28 13:33:46,150:INFO:Random Forest Regressor Imported successfully
2025-10-28 13:33:46,150:INFO:Starting cross validation
2025-10-28 13:33:46,158:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:33:57,006:INFO:Calculating mean and std
2025-10-28 13:33:57,007:INFO:Creating metrics dataframe
2025-10-28 13:33:57,010:INFO:Uploading results into container
2025-10-28 13:33:57,010:INFO:Uploading model into container now
2025-10-28 13:33:57,011:INFO:_master_model_container: 13
2025-10-28 13:33:57,011:INFO:_display_container: 2
2025-10-28 13:33:57,011:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:33:57,011:INFO:create_model() successfully completed......................................
2025-10-28 13:33:57,161:INFO:SubProcess create_model() end ==================================
2025-10-28 13:33:57,162:INFO:Creating metrics dataframe
2025-10-28 13:33:57,167:INFO:Initializing Extra Trees Regressor
2025-10-28 13:33:57,168:INFO:Total runtime is 0.3494648694992065 minutes
2025-10-28 13:33:57,168:INFO:SubProcess create_model() called ==================================
2025-10-28 13:33:57,169:INFO:Initializing create_model()
2025-10-28 13:33:57,169:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:33:57,169:INFO:Checking exceptions
2025-10-28 13:33:57,169:INFO:Importing libraries
2025-10-28 13:33:57,169:INFO:Copying training dataset
2025-10-28 13:33:57,185:INFO:Defining folds
2025-10-28 13:33:57,185:INFO:Declaring metric variables
2025-10-28 13:33:57,186:INFO:Importing untrained model
2025-10-28 13:33:57,187:INFO:Extra Trees Regressor Imported successfully
2025-10-28 13:33:57,187:INFO:Starting cross validation
2025-10-28 13:33:57,189:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:02,344:INFO:Calculating mean and std
2025-10-28 13:34:02,345:INFO:Creating metrics dataframe
2025-10-28 13:34:02,347:INFO:Uploading results into container
2025-10-28 13:34:02,348:INFO:Uploading model into container now
2025-10-28 13:34:02,348:INFO:_master_model_container: 14
2025-10-28 13:34:02,348:INFO:_display_container: 2
2025-10-28 13:34:02,349:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:02,349:INFO:create_model() successfully completed......................................
2025-10-28 13:34:02,480:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:02,480:INFO:Creating metrics dataframe
2025-10-28 13:34:02,486:INFO:Initializing AdaBoost Regressor
2025-10-28 13:34:02,486:INFO:Total runtime is 0.43810170888900757 minutes
2025-10-28 13:34:02,486:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:02,487:INFO:Initializing create_model()
2025-10-28 13:34:02,487:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:02,487:INFO:Checking exceptions
2025-10-28 13:34:02,487:INFO:Importing libraries
2025-10-28 13:34:02,487:INFO:Copying training dataset
2025-10-28 13:34:02,505:INFO:Defining folds
2025-10-28 13:34:02,505:INFO:Declaring metric variables
2025-10-28 13:34:02,506:INFO:Importing untrained model
2025-10-28 13:34:02,506:INFO:AdaBoost Regressor Imported successfully
2025-10-28 13:34:02,507:INFO:Starting cross validation
2025-10-28 13:34:02,508:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:04,338:INFO:Calculating mean and std
2025-10-28 13:34:04,341:INFO:Creating metrics dataframe
2025-10-28 13:34:04,348:INFO:Uploading results into container
2025-10-28 13:34:04,350:INFO:Uploading model into container now
2025-10-28 13:34:04,351:INFO:_master_model_container: 15
2025-10-28 13:34:04,351:INFO:_display_container: 2
2025-10-28 13:34:04,352:INFO:AdaBoostRegressor(random_state=123)
2025-10-28 13:34:04,352:INFO:create_model() successfully completed......................................
2025-10-28 13:34:04,488:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:04,488:INFO:Creating metrics dataframe
2025-10-28 13:34:04,492:INFO:Initializing Gradient Boosting Regressor
2025-10-28 13:34:04,492:INFO:Total runtime is 0.4715269366900126 minutes
2025-10-28 13:34:04,493:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:04,493:INFO:Initializing create_model()
2025-10-28 13:34:04,493:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:04,493:INFO:Checking exceptions
2025-10-28 13:34:04,494:INFO:Importing libraries
2025-10-28 13:34:04,494:INFO:Copying training dataset
2025-10-28 13:34:04,513:INFO:Defining folds
2025-10-28 13:34:04,513:INFO:Declaring metric variables
2025-10-28 13:34:04,513:INFO:Importing untrained model
2025-10-28 13:34:04,514:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 13:34:04,515:INFO:Starting cross validation
2025-10-28 13:34:04,515:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:10,812:INFO:Calculating mean and std
2025-10-28 13:34:10,814:INFO:Creating metrics dataframe
2025-10-28 13:34:10,816:INFO:Uploading results into container
2025-10-28 13:34:10,817:INFO:Uploading model into container now
2025-10-28 13:34:10,818:INFO:_master_model_container: 16
2025-10-28 13:34:10,818:INFO:_display_container: 2
2025-10-28 13:34:10,818:INFO:GradientBoostingRegressor(random_state=123)
2025-10-28 13:34:10,818:INFO:create_model() successfully completed......................................
2025-10-28 13:34:10,922:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:10,922:INFO:Creating metrics dataframe
2025-10-28 13:34:10,925:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 13:34:10,925:INFO:Total runtime is 0.578744379679362 minutes
2025-10-28 13:34:10,926:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:10,926:INFO:Initializing create_model()
2025-10-28 13:34:10,926:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:10,926:INFO:Checking exceptions
2025-10-28 13:34:10,926:INFO:Importing libraries
2025-10-28 13:34:10,926:INFO:Copying training dataset
2025-10-28 13:34:10,936:INFO:Defining folds
2025-10-28 13:34:10,936:INFO:Declaring metric variables
2025-10-28 13:34:10,936:INFO:Importing untrained model
2025-10-28 13:34:10,937:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 13:34:10,937:INFO:Starting cross validation
2025-10-28 13:34:10,937:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:12,827:INFO:Calculating mean and std
2025-10-28 13:34:12,829:INFO:Creating metrics dataframe
2025-10-28 13:34:12,832:INFO:Uploading results into container
2025-10-28 13:34:12,833:INFO:Uploading model into container now
2025-10-28 13:34:12,833:INFO:_master_model_container: 17
2025-10-28 13:34:12,833:INFO:_display_container: 2
2025-10-28 13:34:12,835:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:12,835:INFO:create_model() successfully completed......................................
2025-10-28 13:34:12,948:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:12,948:INFO:Creating metrics dataframe
2025-10-28 13:34:12,953:INFO:Initializing Dummy Regressor
2025-10-28 13:34:12,954:INFO:Total runtime is 0.6125491062800089 minutes
2025-10-28 13:34:12,954:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:12,954:INFO:Initializing create_model()
2025-10-28 13:34:12,954:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x000002948E1DC590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:12,955:INFO:Checking exceptions
2025-10-28 13:34:12,955:INFO:Importing libraries
2025-10-28 13:34:12,955:INFO:Copying training dataset
2025-10-28 13:34:12,970:INFO:Defining folds
2025-10-28 13:34:12,970:INFO:Declaring metric variables
2025-10-28 13:34:12,970:INFO:Importing untrained model
2025-10-28 13:34:12,970:INFO:Dummy Regressor Imported successfully
2025-10-28 13:34:12,971:INFO:Starting cross validation
2025-10-28 13:34:12,971:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:13,055:INFO:Calculating mean and std
2025-10-28 13:34:13,056:INFO:Creating metrics dataframe
2025-10-28 13:34:13,060:INFO:Uploading results into container
2025-10-28 13:34:13,061:INFO:Uploading model into container now
2025-10-28 13:34:13,062:INFO:_master_model_container: 18
2025-10-28 13:34:13,062:INFO:_display_container: 2
2025-10-28 13:34:13,062:INFO:DummyRegressor()
2025-10-28 13:34:13,062:INFO:create_model() successfully completed......................................
2025-10-28 13:34:13,167:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:13,167:INFO:Creating metrics dataframe
2025-10-28 13:34:13,175:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 13:34:13,180:INFO:Initializing create_model()
2025-10-28 13:34:13,180:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x000002948E12FCD0>, estimator=LGBMRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:13,180:INFO:Checking exceptions
2025-10-28 13:34:13,181:INFO:Importing libraries
2025-10-28 13:34:13,182:INFO:Copying training dataset
2025-10-28 13:34:13,193:INFO:Defining folds
2025-10-28 13:34:13,194:INFO:Declaring metric variables
2025-10-28 13:34:13,194:INFO:Importing untrained model
2025-10-28 13:34:13,194:INFO:Declaring custom model
2025-10-28 13:34:13,196:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 13:34:13,197:INFO:Cross validation set to False
2025-10-28 13:34:13,197:INFO:Fitting Model
2025-10-28 13:34:13,226:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000455 seconds.
2025-10-28 13:34:13,226:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-28 13:34:13,226:INFO:[LightGBM] [Info] Total Bins 1838
2025-10-28 13:34:13,227:INFO:[LightGBM] [Info] Number of data points in the train set: 14447, number of used features: 8
2025-10-28 13:34:13,227:INFO:[LightGBM] [Info] Start training from score 3.876481
2025-10-28 13:34:13,313:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:13,313:INFO:create_model() successfully completed......................................
2025-10-28 13:34:13,425:INFO:_master_model_container: 18
2025-10-28 13:34:13,426:INFO:_display_container: 2
2025-10-28 13:34:13,426:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:13,426:INFO:compare_models() successfully completed......................................
2025-10-28 13:34:49,236:INFO:PyCaret RegressionExperiment
2025-10-28 13:34:49,236:INFO:Logging name: reg-default-name
2025-10-28 13:34:49,236:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 13:34:49,236:INFO:version 3.3.2
2025-10-28 13:34:49,236:INFO:Initializing setup()
2025-10-28 13:34:49,236:INFO:self.USI: d153
2025-10-28 13:34:49,237:INFO:self._variable_keys: {'_ml_usecase', 'y_train', 'data', 'fold_generator', 'fold_shuffle_param', 'log_plots_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X', 'USI', 'gpu_param', 'transform_target_param', 'X_test', 'exp_id', 'html_param', '_available_plots', 'memory', 'idx', 'target_param', 'y_test', 'seed', 'exp_name_log', 'pipeline', 'logging_param', 'n_jobs_param', 'y', 'X_train'}
2025-10-28 13:34:49,237:INFO:Checking environment
2025-10-28 13:34:49,237:INFO:python_version: 3.11.14
2025-10-28 13:34:49,237:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 13:34:49,237:INFO:machine: AMD64
2025-10-28 13:34:49,237:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 13:34:49,237:INFO:Memory: svmem(total=16788250624, available=2602950656, percent=84.5, used=14185299968, free=2602950656)
2025-10-28 13:34:49,238:INFO:Physical Core: 12
2025-10-28 13:34:49,238:INFO:Logical Core: 16
2025-10-28 13:34:49,238:INFO:Checking libraries
2025-10-28 13:34:49,238:INFO:System:
2025-10-28 13:34:49,238:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 13:34:49,238:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 13:34:49,238:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 13:34:49,238:INFO:PyCaret required dependencies:
2025-10-28 13:34:49,238:INFO:                 pip: 25.2
2025-10-28 13:34:49,238:INFO:          setuptools: 80.9.0
2025-10-28 13:34:49,238:INFO:             pycaret: 3.3.2
2025-10-28 13:34:49,238:INFO:             IPython: 9.6.0
2025-10-28 13:34:49,238:INFO:          ipywidgets: 8.1.7
2025-10-28 13:34:49,238:INFO:                tqdm: 4.67.1
2025-10-28 13:34:49,238:INFO:               numpy: 1.26.4
2025-10-28 13:34:49,238:INFO:              pandas: 2.1.4
2025-10-28 13:34:49,238:INFO:              jinja2: 3.1.6
2025-10-28 13:34:49,238:INFO:               scipy: 1.11.4
2025-10-28 13:34:49,238:INFO:              joblib: 1.3.2
2025-10-28 13:34:49,238:INFO:             sklearn: 1.4.2
2025-10-28 13:34:49,238:INFO:                pyod: 2.0.5
2025-10-28 13:34:49,238:INFO:            imblearn: 0.14.0
2025-10-28 13:34:49,238:INFO:   category_encoders: 2.7.0
2025-10-28 13:34:49,238:INFO:            lightgbm: 4.6.0
2025-10-28 13:34:49,238:INFO:               numba: 0.62.1
2025-10-28 13:34:49,238:INFO:            requests: 2.32.5
2025-10-28 13:34:49,238:INFO:          matplotlib: 3.10.7
2025-10-28 13:34:49,238:INFO:          scikitplot: 0.3.7
2025-10-28 13:34:49,238:INFO:         yellowbrick: 1.5
2025-10-28 13:34:49,238:INFO:              plotly: 6.3.1
2025-10-28 13:34:49,238:INFO:    plotly-resampler: Not installed
2025-10-28 13:34:49,238:INFO:             kaleido: 0.2.1
2025-10-28 13:34:49,238:INFO:           schemdraw: 0.15
2025-10-28 13:34:49,238:INFO:         statsmodels: 0.14.5
2025-10-28 13:34:49,238:INFO:              sktime: 0.26.0
2025-10-28 13:34:49,238:INFO:               tbats: 1.1.3
2025-10-28 13:34:49,238:INFO:            pmdarima: 2.0.4
2025-10-28 13:34:49,238:INFO:              psutil: 7.1.1
2025-10-28 13:34:49,238:INFO:          markupsafe: 3.0.3
2025-10-28 13:34:49,238:INFO:             pickle5: Not installed
2025-10-28 13:34:49,238:INFO:         cloudpickle: 3.1.1
2025-10-28 13:34:49,238:INFO:         deprecation: 2.1.0
2025-10-28 13:34:49,238:INFO:              xxhash: 3.6.0
2025-10-28 13:34:49,238:INFO:           wurlitzer: 3.1.1
2025-10-28 13:34:49,238:INFO:PyCaret optional dependencies:
2025-10-28 13:34:49,239:INFO:                shap: Not installed
2025-10-28 13:34:49,239:INFO:           interpret: Not installed
2025-10-28 13:34:49,239:INFO:                umap: 0.5.9.post2
2025-10-28 13:34:49,239:INFO:     ydata_profiling: Not installed
2025-10-28 13:34:49,239:INFO:  explainerdashboard: Not installed
2025-10-28 13:34:49,239:INFO:             autoviz: Not installed
2025-10-28 13:34:49,239:INFO:           fairlearn: Not installed
2025-10-28 13:34:49,239:INFO:          deepchecks: Not installed
2025-10-28 13:34:49,239:INFO:             xgboost: Not installed
2025-10-28 13:34:49,239:INFO:            catboost: Not installed
2025-10-28 13:34:49,239:INFO:              kmodes: Not installed
2025-10-28 13:34:49,239:INFO:             mlxtend: Not installed
2025-10-28 13:34:49,239:INFO:       statsforecast: Not installed
2025-10-28 13:34:49,239:INFO:        tune_sklearn: Not installed
2025-10-28 13:34:49,239:INFO:                 ray: Not installed
2025-10-28 13:34:49,239:INFO:            hyperopt: Not installed
2025-10-28 13:34:49,239:INFO:              optuna: Not installed
2025-10-28 13:34:49,239:INFO:               skopt: Not installed
2025-10-28 13:34:49,239:INFO:              mlflow: Not installed
2025-10-28 13:34:49,239:INFO:              gradio: Not installed
2025-10-28 13:34:49,239:INFO:             fastapi: Not installed
2025-10-28 13:34:49,239:INFO:             uvicorn: Not installed
2025-10-28 13:34:49,239:INFO:              m2cgen: Not installed
2025-10-28 13:34:49,239:INFO:           evidently: Not installed
2025-10-28 13:34:49,239:INFO:               fugue: Not installed
2025-10-28 13:34:49,239:INFO:           streamlit: 1.50.0
2025-10-28 13:34:49,239:INFO:             prophet: Not installed
2025-10-28 13:34:49,239:INFO:None
2025-10-28 13:34:49,239:INFO:Set up data.
2025-10-28 13:34:49,243:INFO:Set up folding strategy.
2025-10-28 13:34:49,243:INFO:Set up train/test split.
2025-10-28 13:34:49,251:INFO:Set up index.
2025-10-28 13:34:49,251:INFO:Assigning column types.
2025-10-28 13:34:49,255:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 13:34:49,255:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,260:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,265:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,423:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,425:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,425:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,425:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,430:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,434:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,481:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,523:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,525:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,525:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,525:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 13:34:49,530:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,535:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,627:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,696:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,697:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,704:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,709:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,767:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,811:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,812:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,813:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,813:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 13:34:49,826:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,916:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,980:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:49,981:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,981:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:49,995:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,086:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,139:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,139:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 13:34:50,209:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,281:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,282:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,282:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,373:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,415:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,416:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 13:34:50,503:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,673:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:34:50,733:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,734:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,735:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 13:34:50,915:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:50,915:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,103:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,104:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,105:INFO:Preparing preprocessing pipeline...
2025-10-28 13:34:51,105:INFO:Set up simple imputation.
2025-10-28 13:34:51,106:INFO:Set up column name cleaning.
2025-10-28 13:34:51,141:INFO:Finished creating preprocessing pipeline.
2025-10-28 13:34:51,150:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)', 'target'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 13:34:51,150:INFO:Creating final display dataframe.
2025-10-28 13:34:51,248:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  sepal length (cm)
2                   Target type         Regression
3           Original data shape           (150, 5)
4        Transformed data shape           (150, 5)
5   Transformed train set shape           (105, 5)
6    Transformed test set shape            (45, 5)
7              Numeric features                  4
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12               Fold Generator              KFold
13                  Fold Number                 10
14                     CPU Jobs                 -1
15                      Use GPU              False
16               Log Experiment              False
17              Experiment Name   reg-default-name
18                          USI               d153
2025-10-28 13:34:51,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,506:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:34:51,507:INFO:setup() successfully completed in 2.27s...............
2025-10-28 13:34:51,507:INFO:Initializing compare_models()
2025-10-28 13:34:51,507:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 13:34:51,507:INFO:Checking exceptions
2025-10-28 13:34:51,509:INFO:Preparing display monitor
2025-10-28 13:34:51,511:INFO:Initializing Linear Regression
2025-10-28 13:34:51,512:INFO:Total runtime is 2.1437803904215496e-05 minutes
2025-10-28 13:34:51,512:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:51,512:INFO:Initializing create_model()
2025-10-28 13:34:51,512:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:51,512:INFO:Checking exceptions
2025-10-28 13:34:51,512:INFO:Importing libraries
2025-10-28 13:34:51,512:INFO:Copying training dataset
2025-10-28 13:34:51,515:INFO:Defining folds
2025-10-28 13:34:51,516:INFO:Declaring metric variables
2025-10-28 13:34:51,516:INFO:Importing untrained model
2025-10-28 13:34:51,516:INFO:Linear Regression Imported successfully
2025-10-28 13:34:51,516:INFO:Starting cross validation
2025-10-28 13:34:51,518:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:51,597:INFO:Calculating mean and std
2025-10-28 13:34:51,598:INFO:Creating metrics dataframe
2025-10-28 13:34:51,601:INFO:Uploading results into container
2025-10-28 13:34:51,602:INFO:Uploading model into container now
2025-10-28 13:34:51,603:INFO:_master_model_container: 1
2025-10-28 13:34:51,603:INFO:_display_container: 2
2025-10-28 13:34:51,603:INFO:LinearRegression(n_jobs=-1)
2025-10-28 13:34:51,603:INFO:create_model() successfully completed......................................
2025-10-28 13:34:51,722:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:51,722:INFO:Creating metrics dataframe
2025-10-28 13:34:51,723:INFO:Initializing Lasso Regression
2025-10-28 13:34:51,723:INFO:Total runtime is 0.003539931774139404 minutes
2025-10-28 13:34:51,723:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:51,725:INFO:Initializing create_model()
2025-10-28 13:34:51,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:51,725:INFO:Checking exceptions
2025-10-28 13:34:51,725:INFO:Importing libraries
2025-10-28 13:34:51,725:INFO:Copying training dataset
2025-10-28 13:34:51,727:INFO:Defining folds
2025-10-28 13:34:51,728:INFO:Declaring metric variables
2025-10-28 13:34:51,728:INFO:Importing untrained model
2025-10-28 13:34:51,728:INFO:Lasso Regression Imported successfully
2025-10-28 13:34:51,728:INFO:Starting cross validation
2025-10-28 13:34:51,729:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:51,803:INFO:Calculating mean and std
2025-10-28 13:34:51,804:INFO:Creating metrics dataframe
2025-10-28 13:34:51,805:INFO:Uploading results into container
2025-10-28 13:34:51,806:INFO:Uploading model into container now
2025-10-28 13:34:51,807:INFO:_master_model_container: 2
2025-10-28 13:34:51,807:INFO:_display_container: 2
2025-10-28 13:34:51,807:INFO:Lasso(random_state=123)
2025-10-28 13:34:51,807:INFO:create_model() successfully completed......................................
2025-10-28 13:34:51,931:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:51,931:INFO:Creating metrics dataframe
2025-10-28 13:34:51,937:INFO:Initializing Ridge Regression
2025-10-28 13:34:51,937:INFO:Total runtime is 0.007101603349049886 minutes
2025-10-28 13:34:51,937:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:51,937:INFO:Initializing create_model()
2025-10-28 13:34:51,937:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:51,938:INFO:Checking exceptions
2025-10-28 13:34:51,938:INFO:Importing libraries
2025-10-28 13:34:51,938:INFO:Copying training dataset
2025-10-28 13:34:51,943:INFO:Defining folds
2025-10-28 13:34:51,943:INFO:Declaring metric variables
2025-10-28 13:34:51,943:INFO:Importing untrained model
2025-10-28 13:34:51,943:INFO:Ridge Regression Imported successfully
2025-10-28 13:34:51,943:INFO:Starting cross validation
2025-10-28 13:34:51,945:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:52,080:INFO:Calculating mean and std
2025-10-28 13:34:52,081:INFO:Creating metrics dataframe
2025-10-28 13:34:52,085:INFO:Uploading results into container
2025-10-28 13:34:52,086:INFO:Uploading model into container now
2025-10-28 13:34:52,087:INFO:_master_model_container: 3
2025-10-28 13:34:52,087:INFO:_display_container: 2
2025-10-28 13:34:52,088:INFO:Ridge(random_state=123)
2025-10-28 13:34:52,088:INFO:create_model() successfully completed......................................
2025-10-28 13:34:52,223:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:52,223:INFO:Creating metrics dataframe
2025-10-28 13:34:52,227:INFO:Initializing Elastic Net
2025-10-28 13:34:52,227:INFO:Total runtime is 0.011936891078948974 minutes
2025-10-28 13:34:52,228:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:52,228:INFO:Initializing create_model()
2025-10-28 13:34:52,228:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:52,228:INFO:Checking exceptions
2025-10-28 13:34:52,228:INFO:Importing libraries
2025-10-28 13:34:52,228:INFO:Copying training dataset
2025-10-28 13:34:52,231:INFO:Defining folds
2025-10-28 13:34:52,231:INFO:Declaring metric variables
2025-10-28 13:34:52,232:INFO:Importing untrained model
2025-10-28 13:34:52,232:INFO:Elastic Net Imported successfully
2025-10-28 13:34:52,232:INFO:Starting cross validation
2025-10-28 13:34:52,233:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:52,336:INFO:Calculating mean and std
2025-10-28 13:34:52,339:INFO:Creating metrics dataframe
2025-10-28 13:34:52,343:INFO:Uploading results into container
2025-10-28 13:34:52,344:INFO:Uploading model into container now
2025-10-28 13:34:52,344:INFO:_master_model_container: 4
2025-10-28 13:34:52,344:INFO:_display_container: 2
2025-10-28 13:34:52,345:INFO:ElasticNet(random_state=123)
2025-10-28 13:34:52,345:INFO:create_model() successfully completed......................................
2025-10-28 13:34:52,472:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:52,473:INFO:Creating metrics dataframe
2025-10-28 13:34:52,476:INFO:Initializing Least Angle Regression
2025-10-28 13:34:52,476:INFO:Total runtime is 0.016081706682840983 minutes
2025-10-28 13:34:52,476:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:52,477:INFO:Initializing create_model()
2025-10-28 13:34:52,477:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:52,477:INFO:Checking exceptions
2025-10-28 13:34:52,477:INFO:Importing libraries
2025-10-28 13:34:52,477:INFO:Copying training dataset
2025-10-28 13:34:52,481:INFO:Defining folds
2025-10-28 13:34:52,482:INFO:Declaring metric variables
2025-10-28 13:34:52,483:INFO:Importing untrained model
2025-10-28 13:34:52,483:INFO:Least Angle Regression Imported successfully
2025-10-28 13:34:52,483:INFO:Starting cross validation
2025-10-28 13:34:52,485:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:52,597:INFO:Calculating mean and std
2025-10-28 13:34:52,599:INFO:Creating metrics dataframe
2025-10-28 13:34:52,604:INFO:Uploading results into container
2025-10-28 13:34:52,604:INFO:Uploading model into container now
2025-10-28 13:34:52,605:INFO:_master_model_container: 5
2025-10-28 13:34:52,605:INFO:_display_container: 2
2025-10-28 13:34:52,605:INFO:Lars(random_state=123)
2025-10-28 13:34:52,607:INFO:create_model() successfully completed......................................
2025-10-28 13:34:52,739:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:52,739:INFO:Creating metrics dataframe
2025-10-28 13:34:52,742:INFO:Initializing Lasso Least Angle Regression
2025-10-28 13:34:52,742:INFO:Total runtime is 0.02052459716796875 minutes
2025-10-28 13:34:52,742:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:52,742:INFO:Initializing create_model()
2025-10-28 13:34:52,742:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:52,742:INFO:Checking exceptions
2025-10-28 13:34:52,742:INFO:Importing libraries
2025-10-28 13:34:52,742:INFO:Copying training dataset
2025-10-28 13:34:52,746:INFO:Defining folds
2025-10-28 13:34:52,746:INFO:Declaring metric variables
2025-10-28 13:34:52,746:INFO:Importing untrained model
2025-10-28 13:34:52,747:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 13:34:52,747:INFO:Starting cross validation
2025-10-28 13:34:52,747:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:52,828:INFO:Calculating mean and std
2025-10-28 13:34:52,830:INFO:Creating metrics dataframe
2025-10-28 13:34:52,834:INFO:Uploading results into container
2025-10-28 13:34:52,835:INFO:Uploading model into container now
2025-10-28 13:34:52,837:INFO:_master_model_container: 6
2025-10-28 13:34:52,837:INFO:_display_container: 2
2025-10-28 13:34:52,837:INFO:LassoLars(random_state=123)
2025-10-28 13:34:52,837:INFO:create_model() successfully completed......................................
2025-10-28 13:34:52,966:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:52,966:INFO:Creating metrics dataframe
2025-10-28 13:34:52,970:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 13:34:52,970:INFO:Total runtime is 0.024314538637797038 minutes
2025-10-28 13:34:52,970:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:52,970:INFO:Initializing create_model()
2025-10-28 13:34:52,970:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:52,971:INFO:Checking exceptions
2025-10-28 13:34:52,971:INFO:Importing libraries
2025-10-28 13:34:52,971:INFO:Copying training dataset
2025-10-28 13:34:52,980:INFO:Defining folds
2025-10-28 13:34:52,980:INFO:Declaring metric variables
2025-10-28 13:34:52,980:INFO:Importing untrained model
2025-10-28 13:34:52,981:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 13:34:52,981:INFO:Starting cross validation
2025-10-28 13:34:52,982:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:53,099:INFO:Calculating mean and std
2025-10-28 13:34:53,102:INFO:Creating metrics dataframe
2025-10-28 13:34:53,105:INFO:Uploading results into container
2025-10-28 13:34:53,106:INFO:Uploading model into container now
2025-10-28 13:34:53,107:INFO:_master_model_container: 7
2025-10-28 13:34:53,107:INFO:_display_container: 2
2025-10-28 13:34:53,108:INFO:OrthogonalMatchingPursuit()
2025-10-28 13:34:53,108:INFO:create_model() successfully completed......................................
2025-10-28 13:34:53,241:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:53,242:INFO:Creating metrics dataframe
2025-10-28 13:34:53,245:INFO:Initializing Bayesian Ridge
2025-10-28 13:34:53,246:INFO:Total runtime is 0.02890334129333496 minutes
2025-10-28 13:34:53,246:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:53,246:INFO:Initializing create_model()
2025-10-28 13:34:53,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:53,246:INFO:Checking exceptions
2025-10-28 13:34:53,246:INFO:Importing libraries
2025-10-28 13:34:53,246:INFO:Copying training dataset
2025-10-28 13:34:53,252:INFO:Defining folds
2025-10-28 13:34:53,252:INFO:Declaring metric variables
2025-10-28 13:34:53,253:INFO:Importing untrained model
2025-10-28 13:34:53,253:INFO:Bayesian Ridge Imported successfully
2025-10-28 13:34:53,253:INFO:Starting cross validation
2025-10-28 13:34:53,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:53,350:INFO:Calculating mean and std
2025-10-28 13:34:53,351:INFO:Creating metrics dataframe
2025-10-28 13:34:53,357:INFO:Uploading results into container
2025-10-28 13:34:53,358:INFO:Uploading model into container now
2025-10-28 13:34:53,359:INFO:_master_model_container: 8
2025-10-28 13:34:53,359:INFO:_display_container: 2
2025-10-28 13:34:53,360:INFO:BayesianRidge()
2025-10-28 13:34:53,360:INFO:create_model() successfully completed......................................
2025-10-28 13:34:53,490:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:53,490:INFO:Creating metrics dataframe
2025-10-28 13:34:53,495:INFO:Initializing Passive Aggressive Regressor
2025-10-28 13:34:53,495:INFO:Total runtime is 0.033064659436543783 minutes
2025-10-28 13:34:53,495:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:53,495:INFO:Initializing create_model()
2025-10-28 13:34:53,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:53,495:INFO:Checking exceptions
2025-10-28 13:34:53,495:INFO:Importing libraries
2025-10-28 13:34:53,495:INFO:Copying training dataset
2025-10-28 13:34:53,500:INFO:Defining folds
2025-10-28 13:34:53,502:INFO:Declaring metric variables
2025-10-28 13:34:53,502:INFO:Importing untrained model
2025-10-28 13:34:53,502:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 13:34:53,502:INFO:Starting cross validation
2025-10-28 13:34:53,504:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:53,594:INFO:Calculating mean and std
2025-10-28 13:34:53,596:INFO:Creating metrics dataframe
2025-10-28 13:34:53,599:INFO:Uploading results into container
2025-10-28 13:34:53,600:INFO:Uploading model into container now
2025-10-28 13:34:53,601:INFO:_master_model_container: 9
2025-10-28 13:34:53,601:INFO:_display_container: 2
2025-10-28 13:34:53,602:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-28 13:34:53,602:INFO:create_model() successfully completed......................................
2025-10-28 13:34:53,719:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:53,719:INFO:Creating metrics dataframe
2025-10-28 13:34:53,723:INFO:Initializing Huber Regressor
2025-10-28 13:34:53,724:INFO:Total runtime is 0.0368811289469401 minutes
2025-10-28 13:34:53,724:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:53,725:INFO:Initializing create_model()
2025-10-28 13:34:53,725:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:53,725:INFO:Checking exceptions
2025-10-28 13:34:53,725:INFO:Importing libraries
2025-10-28 13:34:53,725:INFO:Copying training dataset
2025-10-28 13:34:53,730:INFO:Defining folds
2025-10-28 13:34:53,730:INFO:Declaring metric variables
2025-10-28 13:34:53,731:INFO:Importing untrained model
2025-10-28 13:34:53,731:INFO:Huber Regressor Imported successfully
2025-10-28 13:34:53,732:INFO:Starting cross validation
2025-10-28 13:34:53,733:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:53,841:INFO:Calculating mean and std
2025-10-28 13:34:53,843:INFO:Creating metrics dataframe
2025-10-28 13:34:53,847:INFO:Uploading results into container
2025-10-28 13:34:53,847:INFO:Uploading model into container now
2025-10-28 13:34:53,848:INFO:_master_model_container: 10
2025-10-28 13:34:53,848:INFO:_display_container: 2
2025-10-28 13:34:53,849:INFO:HuberRegressor()
2025-10-28 13:34:53,849:INFO:create_model() successfully completed......................................
2025-10-28 13:34:53,975:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:53,975:INFO:Creating metrics dataframe
2025-10-28 13:34:53,979:INFO:Initializing K Neighbors Regressor
2025-10-28 13:34:53,979:INFO:Total runtime is 0.04114150206247965 minutes
2025-10-28 13:34:53,980:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:53,980:INFO:Initializing create_model()
2025-10-28 13:34:53,981:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:53,981:INFO:Checking exceptions
2025-10-28 13:34:53,981:INFO:Importing libraries
2025-10-28 13:34:53,981:INFO:Copying training dataset
2025-10-28 13:34:53,990:INFO:Defining folds
2025-10-28 13:34:53,990:INFO:Declaring metric variables
2025-10-28 13:34:53,990:INFO:Importing untrained model
2025-10-28 13:34:53,990:INFO:K Neighbors Regressor Imported successfully
2025-10-28 13:34:53,990:INFO:Starting cross validation
2025-10-28 13:34:53,991:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:54,110:INFO:Calculating mean and std
2025-10-28 13:34:54,111:INFO:Creating metrics dataframe
2025-10-28 13:34:54,113:INFO:Uploading results into container
2025-10-28 13:34:54,115:INFO:Uploading model into container now
2025-10-28 13:34:54,116:INFO:_master_model_container: 11
2025-10-28 13:34:54,116:INFO:_display_container: 2
2025-10-28 13:34:54,116:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 13:34:54,116:INFO:create_model() successfully completed......................................
2025-10-28 13:34:54,244:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:54,244:INFO:Creating metrics dataframe
2025-10-28 13:34:54,249:INFO:Initializing Decision Tree Regressor
2025-10-28 13:34:54,249:INFO:Total runtime is 0.0456267237663269 minutes
2025-10-28 13:34:54,250:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:54,250:INFO:Initializing create_model()
2025-10-28 13:34:54,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:54,250:INFO:Checking exceptions
2025-10-28 13:34:54,251:INFO:Importing libraries
2025-10-28 13:34:54,251:INFO:Copying training dataset
2025-10-28 13:34:54,256:INFO:Defining folds
2025-10-28 13:34:54,256:INFO:Declaring metric variables
2025-10-28 13:34:54,256:INFO:Importing untrained model
2025-10-28 13:34:54,257:INFO:Decision Tree Regressor Imported successfully
2025-10-28 13:34:54,257:INFO:Starting cross validation
2025-10-28 13:34:54,257:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:54,338:INFO:Calculating mean and std
2025-10-28 13:34:54,339:INFO:Creating metrics dataframe
2025-10-28 13:34:54,343:INFO:Uploading results into container
2025-10-28 13:34:54,344:INFO:Uploading model into container now
2025-10-28 13:34:54,345:INFO:_master_model_container: 12
2025-10-28 13:34:54,345:INFO:_display_container: 2
2025-10-28 13:34:54,345:INFO:DecisionTreeRegressor(random_state=123)
2025-10-28 13:34:54,345:INFO:create_model() successfully completed......................................
2025-10-28 13:34:54,464:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:54,464:INFO:Creating metrics dataframe
2025-10-28 13:34:54,467:INFO:Initializing Random Forest Regressor
2025-10-28 13:34:54,467:INFO:Total runtime is 0.0492744485537211 minutes
2025-10-28 13:34:54,467:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:54,468:INFO:Initializing create_model()
2025-10-28 13:34:54,468:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:54,468:INFO:Checking exceptions
2025-10-28 13:34:54,468:INFO:Importing libraries
2025-10-28 13:34:54,468:INFO:Copying training dataset
2025-10-28 13:34:54,474:INFO:Defining folds
2025-10-28 13:34:54,474:INFO:Declaring metric variables
2025-10-28 13:34:54,474:INFO:Importing untrained model
2025-10-28 13:34:54,475:INFO:Random Forest Regressor Imported successfully
2025-10-28 13:34:54,475:INFO:Starting cross validation
2025-10-28 13:34:54,476:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:54,752:INFO:Calculating mean and std
2025-10-28 13:34:54,753:INFO:Creating metrics dataframe
2025-10-28 13:34:54,757:INFO:Uploading results into container
2025-10-28 13:34:54,758:INFO:Uploading model into container now
2025-10-28 13:34:54,758:INFO:_master_model_container: 13
2025-10-28 13:34:54,758:INFO:_display_container: 2
2025-10-28 13:34:54,759:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:54,759:INFO:create_model() successfully completed......................................
2025-10-28 13:34:54,873:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:54,874:INFO:Creating metrics dataframe
2025-10-28 13:34:54,879:INFO:Initializing Extra Trees Regressor
2025-10-28 13:34:54,879:INFO:Total runtime is 0.056126582622528065 minutes
2025-10-28 13:34:54,879:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:54,880:INFO:Initializing create_model()
2025-10-28 13:34:54,880:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:54,880:INFO:Checking exceptions
2025-10-28 13:34:54,880:INFO:Importing libraries
2025-10-28 13:34:54,880:INFO:Copying training dataset
2025-10-28 13:34:54,885:INFO:Defining folds
2025-10-28 13:34:54,885:INFO:Declaring metric variables
2025-10-28 13:34:54,885:INFO:Importing untrained model
2025-10-28 13:34:54,885:INFO:Extra Trees Regressor Imported successfully
2025-10-28 13:34:54,885:INFO:Starting cross validation
2025-10-28 13:34:54,886:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:55,115:INFO:Calculating mean and std
2025-10-28 13:34:55,116:INFO:Creating metrics dataframe
2025-10-28 13:34:55,118:INFO:Uploading results into container
2025-10-28 13:34:55,119:INFO:Uploading model into container now
2025-10-28 13:34:55,120:INFO:_master_model_container: 14
2025-10-28 13:34:55,120:INFO:_display_container: 2
2025-10-28 13:34:55,120:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:55,120:INFO:create_model() successfully completed......................................
2025-10-28 13:34:55,240:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:55,240:INFO:Creating metrics dataframe
2025-10-28 13:34:55,245:INFO:Initializing AdaBoost Regressor
2025-10-28 13:34:55,245:INFO:Total runtime is 0.062233563264211006 minutes
2025-10-28 13:34:55,245:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:55,246:INFO:Initializing create_model()
2025-10-28 13:34:55,246:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:55,246:INFO:Checking exceptions
2025-10-28 13:34:55,246:INFO:Importing libraries
2025-10-28 13:34:55,246:INFO:Copying training dataset
2025-10-28 13:34:55,249:INFO:Defining folds
2025-10-28 13:34:55,249:INFO:Declaring metric variables
2025-10-28 13:34:55,249:INFO:Importing untrained model
2025-10-28 13:34:55,250:INFO:AdaBoost Regressor Imported successfully
2025-10-28 13:34:55,250:INFO:Starting cross validation
2025-10-28 13:34:55,251:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:55,423:INFO:Calculating mean and std
2025-10-28 13:34:55,423:INFO:Creating metrics dataframe
2025-10-28 13:34:55,427:INFO:Uploading results into container
2025-10-28 13:34:55,427:INFO:Uploading model into container now
2025-10-28 13:34:55,428:INFO:_master_model_container: 15
2025-10-28 13:34:55,428:INFO:_display_container: 2
2025-10-28 13:34:55,428:INFO:AdaBoostRegressor(random_state=123)
2025-10-28 13:34:55,428:INFO:create_model() successfully completed......................................
2025-10-28 13:34:55,545:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:55,545:INFO:Creating metrics dataframe
2025-10-28 13:34:55,550:INFO:Initializing Gradient Boosting Regressor
2025-10-28 13:34:55,551:INFO:Total runtime is 0.06732606490453083 minutes
2025-10-28 13:34:55,551:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:55,551:INFO:Initializing create_model()
2025-10-28 13:34:55,552:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:55,552:INFO:Checking exceptions
2025-10-28 13:34:55,553:INFO:Importing libraries
2025-10-28 13:34:55,553:INFO:Copying training dataset
2025-10-28 13:34:55,559:INFO:Defining folds
2025-10-28 13:34:55,560:INFO:Declaring metric variables
2025-10-28 13:34:55,560:INFO:Importing untrained model
2025-10-28 13:34:55,561:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 13:34:55,561:INFO:Starting cross validation
2025-10-28 13:34:55,562:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:55,802:INFO:Calculating mean and std
2025-10-28 13:34:55,803:INFO:Creating metrics dataframe
2025-10-28 13:34:55,806:INFO:Uploading results into container
2025-10-28 13:34:55,807:INFO:Uploading model into container now
2025-10-28 13:34:55,807:INFO:_master_model_container: 16
2025-10-28 13:34:55,808:INFO:_display_container: 2
2025-10-28 13:34:55,808:INFO:GradientBoostingRegressor(random_state=123)
2025-10-28 13:34:55,808:INFO:create_model() successfully completed......................................
2025-10-28 13:34:55,943:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:55,943:INFO:Creating metrics dataframe
2025-10-28 13:34:55,948:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 13:34:55,948:INFO:Total runtime is 0.07395364840825397 minutes
2025-10-28 13:34:55,948:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:55,949:INFO:Initializing create_model()
2025-10-28 13:34:55,949:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:55,949:INFO:Checking exceptions
2025-10-28 13:34:55,949:INFO:Importing libraries
2025-10-28 13:34:55,949:INFO:Copying training dataset
2025-10-28 13:34:55,954:INFO:Defining folds
2025-10-28 13:34:55,954:INFO:Declaring metric variables
2025-10-28 13:34:55,954:INFO:Importing untrained model
2025-10-28 13:34:55,955:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 13:34:55,955:INFO:Starting cross validation
2025-10-28 13:34:55,957:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:56,332:INFO:Calculating mean and std
2025-10-28 13:34:56,333:INFO:Creating metrics dataframe
2025-10-28 13:34:56,335:INFO:Uploading results into container
2025-10-28 13:34:56,336:INFO:Uploading model into container now
2025-10-28 13:34:56,336:INFO:_master_model_container: 17
2025-10-28 13:34:56,336:INFO:_display_container: 2
2025-10-28 13:34:56,337:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:34:56,337:INFO:create_model() successfully completed......................................
2025-10-28 13:34:56,433:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:56,433:INFO:Creating metrics dataframe
2025-10-28 13:34:56,437:INFO:Initializing Dummy Regressor
2025-10-28 13:34:56,437:INFO:Total runtime is 0.08209623893102008 minutes
2025-10-28 13:34:56,437:INFO:SubProcess create_model() called ==================================
2025-10-28 13:34:56,437:INFO:Initializing create_model()
2025-10-28 13:34:56,437:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFD9B210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:56,437:INFO:Checking exceptions
2025-10-28 13:34:56,437:INFO:Importing libraries
2025-10-28 13:34:56,438:INFO:Copying training dataset
2025-10-28 13:34:56,442:INFO:Defining folds
2025-10-28 13:34:56,442:INFO:Declaring metric variables
2025-10-28 13:34:56,442:INFO:Importing untrained model
2025-10-28 13:34:56,443:INFO:Dummy Regressor Imported successfully
2025-10-28 13:34:56,443:INFO:Starting cross validation
2025-10-28 13:34:56,444:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:34:56,547:INFO:Calculating mean and std
2025-10-28 13:34:56,549:INFO:Creating metrics dataframe
2025-10-28 13:34:56,553:INFO:Uploading results into container
2025-10-28 13:34:56,554:INFO:Uploading model into container now
2025-10-28 13:34:56,555:INFO:_master_model_container: 18
2025-10-28 13:34:56,555:INFO:_display_container: 2
2025-10-28 13:34:56,555:INFO:DummyRegressor()
2025-10-28 13:34:56,555:INFO:create_model() successfully completed......................................
2025-10-28 13:34:56,678:INFO:SubProcess create_model() end ==================================
2025-10-28 13:34:56,678:INFO:Creating metrics dataframe
2025-10-28 13:34:56,687:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 13:34:56,690:INFO:Initializing create_model()
2025-10-28 13:34:56,690:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE8A1950>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:34:56,690:INFO:Checking exceptions
2025-10-28 13:34:56,692:INFO:Importing libraries
2025-10-28 13:34:56,693:INFO:Copying training dataset
2025-10-28 13:34:56,700:INFO:Defining folds
2025-10-28 13:34:56,700:INFO:Declaring metric variables
2025-10-28 13:34:56,700:INFO:Importing untrained model
2025-10-28 13:34:56,700:INFO:Declaring custom model
2025-10-28 13:34:56,701:INFO:Ridge Regression Imported successfully
2025-10-28 13:34:56,703:INFO:Cross validation set to False
2025-10-28 13:34:56,703:INFO:Fitting Model
2025-10-28 13:34:56,788:INFO:Ridge(random_state=123)
2025-10-28 13:34:56,788:INFO:create_model() successfully completed......................................
2025-10-28 13:34:56,945:INFO:_master_model_container: 18
2025-10-28 13:34:56,945:INFO:_display_container: 2
2025-10-28 13:34:56,945:INFO:Ridge(random_state=123)
2025-10-28 13:34:56,945:INFO:compare_models() successfully completed......................................
2025-10-28 13:40:13,512:INFO:PyCaret ClassificationExperiment
2025-10-28 13:40:13,512:INFO:Logging name: clf-default-name
2025-10-28 13:40:13,512:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 13:40:13,512:INFO:version 3.3.2
2025-10-28 13:40:13,512:INFO:Initializing setup()
2025-10-28 13:40:13,512:INFO:self.USI: c679
2025-10-28 13:40:13,512:INFO:self._variable_keys: {'_ml_usecase', 'y_train', 'data', 'fold_generator', 'fold_shuffle_param', 'is_multiclass', 'log_plots_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X', 'USI', 'gpu_param', 'X_test', 'exp_id', 'html_param', '_available_plots', 'memory', 'idx', 'target_param', 'y_test', 'seed', 'exp_name_log', 'pipeline', 'logging_param', 'n_jobs_param', 'y', 'X_train', 'fix_imbalance'}
2025-10-28 13:40:13,512:INFO:Checking environment
2025-10-28 13:40:13,512:INFO:python_version: 3.11.14
2025-10-28 13:40:13,512:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 13:40:13,512:INFO:machine: AMD64
2025-10-28 13:40:13,512:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 13:40:13,514:INFO:Memory: svmem(total=16788250624, available=4633706496, percent=72.4, used=12154544128, free=4633706496)
2025-10-28 13:40:13,514:INFO:Physical Core: 12
2025-10-28 13:40:13,514:INFO:Logical Core: 16
2025-10-28 13:40:13,514:INFO:Checking libraries
2025-10-28 13:40:13,514:INFO:System:
2025-10-28 13:40:13,514:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 13:40:13,514:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 13:40:13,514:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 13:40:13,514:INFO:PyCaret required dependencies:
2025-10-28 13:40:13,514:INFO:                 pip: 25.2
2025-10-28 13:40:13,514:INFO:          setuptools: 80.9.0
2025-10-28 13:40:13,514:INFO:             pycaret: 3.3.2
2025-10-28 13:40:13,514:INFO:             IPython: 9.6.0
2025-10-28 13:40:13,514:INFO:          ipywidgets: 8.1.7
2025-10-28 13:40:13,514:INFO:                tqdm: 4.67.1
2025-10-28 13:40:13,514:INFO:               numpy: 1.26.4
2025-10-28 13:40:13,514:INFO:              pandas: 2.1.4
2025-10-28 13:40:13,514:INFO:              jinja2: 3.1.6
2025-10-28 13:40:13,514:INFO:               scipy: 1.11.4
2025-10-28 13:40:13,514:INFO:              joblib: 1.3.2
2025-10-28 13:40:13,514:INFO:             sklearn: 1.4.2
2025-10-28 13:40:13,514:INFO:                pyod: 2.0.5
2025-10-28 13:40:13,514:INFO:            imblearn: 0.14.0
2025-10-28 13:40:13,514:INFO:   category_encoders: 2.7.0
2025-10-28 13:40:13,514:INFO:            lightgbm: 4.6.0
2025-10-28 13:40:13,514:INFO:               numba: 0.62.1
2025-10-28 13:40:13,515:INFO:            requests: 2.32.5
2025-10-28 13:40:13,515:INFO:          matplotlib: 3.10.7
2025-10-28 13:40:13,515:INFO:          scikitplot: 0.3.7
2025-10-28 13:40:13,515:INFO:         yellowbrick: 1.5
2025-10-28 13:40:13,515:INFO:              plotly: 6.3.1
2025-10-28 13:40:13,515:INFO:    plotly-resampler: Not installed
2025-10-28 13:40:13,515:INFO:             kaleido: 0.2.1
2025-10-28 13:40:13,515:INFO:           schemdraw: 0.15
2025-10-28 13:40:13,515:INFO:         statsmodels: 0.14.5
2025-10-28 13:40:13,515:INFO:              sktime: 0.26.0
2025-10-28 13:40:13,515:INFO:               tbats: 1.1.3
2025-10-28 13:40:13,515:INFO:            pmdarima: 2.0.4
2025-10-28 13:40:13,515:INFO:              psutil: 7.1.1
2025-10-28 13:40:13,515:INFO:          markupsafe: 3.0.3
2025-10-28 13:40:13,515:INFO:             pickle5: Not installed
2025-10-28 13:40:13,515:INFO:         cloudpickle: 3.1.1
2025-10-28 13:40:13,515:INFO:         deprecation: 2.1.0
2025-10-28 13:40:13,515:INFO:              xxhash: 3.6.0
2025-10-28 13:40:13,515:INFO:           wurlitzer: 3.1.1
2025-10-28 13:40:13,515:INFO:PyCaret optional dependencies:
2025-10-28 13:40:13,515:INFO:                shap: Not installed
2025-10-28 13:40:13,515:INFO:           interpret: Not installed
2025-10-28 13:40:13,515:INFO:                umap: 0.5.9.post2
2025-10-28 13:40:13,515:INFO:     ydata_profiling: Not installed
2025-10-28 13:40:13,515:INFO:  explainerdashboard: Not installed
2025-10-28 13:40:13,516:INFO:             autoviz: Not installed
2025-10-28 13:40:13,516:INFO:           fairlearn: Not installed
2025-10-28 13:40:13,516:INFO:          deepchecks: Not installed
2025-10-28 13:40:13,516:INFO:             xgboost: Not installed
2025-10-28 13:40:13,516:INFO:            catboost: Not installed
2025-10-28 13:40:13,516:INFO:              kmodes: Not installed
2025-10-28 13:40:13,516:INFO:             mlxtend: Not installed
2025-10-28 13:40:13,516:INFO:       statsforecast: Not installed
2025-10-28 13:40:13,516:INFO:        tune_sklearn: Not installed
2025-10-28 13:40:13,516:INFO:                 ray: Not installed
2025-10-28 13:40:13,516:INFO:            hyperopt: Not installed
2025-10-28 13:40:13,516:INFO:              optuna: Not installed
2025-10-28 13:40:13,516:INFO:               skopt: Not installed
2025-10-28 13:40:13,516:INFO:              mlflow: Not installed
2025-10-28 13:40:13,516:INFO:              gradio: Not installed
2025-10-28 13:40:13,516:INFO:             fastapi: Not installed
2025-10-28 13:40:13,516:INFO:             uvicorn: Not installed
2025-10-28 13:40:13,516:INFO:              m2cgen: Not installed
2025-10-28 13:40:13,516:INFO:           evidently: Not installed
2025-10-28 13:40:13,516:INFO:               fugue: Not installed
2025-10-28 13:40:13,516:INFO:           streamlit: 1.50.0
2025-10-28 13:40:13,517:INFO:             prophet: Not installed
2025-10-28 13:40:13,517:INFO:None
2025-10-28 13:40:13,517:INFO:Set up data.
2025-10-28 13:40:13,529:INFO:Set up folding strategy.
2025-10-28 13:40:13,530:INFO:Set up train/test split.
2025-10-28 13:40:29,051:INFO:PyCaret RegressionExperiment
2025-10-28 13:40:29,051:INFO:Logging name: reg-default-name
2025-10-28 13:40:29,051:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 13:40:29,051:INFO:version 3.3.2
2025-10-28 13:40:29,051:INFO:Initializing setup()
2025-10-28 13:40:29,051:INFO:self.USI: 47da
2025-10-28 13:40:29,051:INFO:self._variable_keys: {'_ml_usecase', 'y_train', 'data', 'fold_generator', 'fold_shuffle_param', 'log_plots_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X', 'USI', 'gpu_param', 'transform_target_param', 'X_test', 'exp_id', 'html_param', '_available_plots', 'memory', 'idx', 'target_param', 'y_test', 'seed', 'exp_name_log', 'pipeline', 'logging_param', 'n_jobs_param', 'y', 'X_train'}
2025-10-28 13:40:29,051:INFO:Checking environment
2025-10-28 13:40:29,051:INFO:python_version: 3.11.14
2025-10-28 13:40:29,051:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 13:40:29,051:INFO:machine: AMD64
2025-10-28 13:40:29,051:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 13:40:29,052:INFO:Memory: svmem(total=16788250624, available=4559503360, percent=72.8, used=12228747264, free=4559503360)
2025-10-28 13:40:29,052:INFO:Physical Core: 12
2025-10-28 13:40:29,052:INFO:Logical Core: 16
2025-10-28 13:40:29,052:INFO:Checking libraries
2025-10-28 13:40:29,052:INFO:System:
2025-10-28 13:40:29,052:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 13:40:29,052:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 13:40:29,052:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 13:40:29,052:INFO:PyCaret required dependencies:
2025-10-28 13:40:29,052:INFO:                 pip: 25.2
2025-10-28 13:40:29,052:INFO:          setuptools: 80.9.0
2025-10-28 13:40:29,052:INFO:             pycaret: 3.3.2
2025-10-28 13:40:29,052:INFO:             IPython: 9.6.0
2025-10-28 13:40:29,052:INFO:          ipywidgets: 8.1.7
2025-10-28 13:40:29,053:INFO:                tqdm: 4.67.1
2025-10-28 13:40:29,053:INFO:               numpy: 1.26.4
2025-10-28 13:40:29,053:INFO:              pandas: 2.1.4
2025-10-28 13:40:29,053:INFO:              jinja2: 3.1.6
2025-10-28 13:40:29,053:INFO:               scipy: 1.11.4
2025-10-28 13:40:29,053:INFO:              joblib: 1.3.2
2025-10-28 13:40:29,053:INFO:             sklearn: 1.4.2
2025-10-28 13:40:29,053:INFO:                pyod: 2.0.5
2025-10-28 13:40:29,053:INFO:            imblearn: 0.14.0
2025-10-28 13:40:29,053:INFO:   category_encoders: 2.7.0
2025-10-28 13:40:29,053:INFO:            lightgbm: 4.6.0
2025-10-28 13:40:29,054:INFO:               numba: 0.62.1
2025-10-28 13:40:29,054:INFO:            requests: 2.32.5
2025-10-28 13:40:29,054:INFO:          matplotlib: 3.10.7
2025-10-28 13:40:29,054:INFO:          scikitplot: 0.3.7
2025-10-28 13:40:29,054:INFO:         yellowbrick: 1.5
2025-10-28 13:40:29,055:INFO:              plotly: 6.3.1
2025-10-28 13:40:29,055:INFO:    plotly-resampler: Not installed
2025-10-28 13:40:29,055:INFO:             kaleido: 0.2.1
2025-10-28 13:40:29,055:INFO:           schemdraw: 0.15
2025-10-28 13:40:29,055:INFO:         statsmodels: 0.14.5
2025-10-28 13:40:29,055:INFO:              sktime: 0.26.0
2025-10-28 13:40:29,055:INFO:               tbats: 1.1.3
2025-10-28 13:40:29,055:INFO:            pmdarima: 2.0.4
2025-10-28 13:40:29,055:INFO:              psutil: 7.1.1
2025-10-28 13:40:29,055:INFO:          markupsafe: 3.0.3
2025-10-28 13:40:29,055:INFO:             pickle5: Not installed
2025-10-28 13:40:29,055:INFO:         cloudpickle: 3.1.1
2025-10-28 13:40:29,055:INFO:         deprecation: 2.1.0
2025-10-28 13:40:29,055:INFO:              xxhash: 3.6.0
2025-10-28 13:40:29,056:INFO:           wurlitzer: 3.1.1
2025-10-28 13:40:29,056:INFO:PyCaret optional dependencies:
2025-10-28 13:40:29,056:INFO:                shap: Not installed
2025-10-28 13:40:29,056:INFO:           interpret: Not installed
2025-10-28 13:40:29,056:INFO:                umap: 0.5.9.post2
2025-10-28 13:40:29,056:INFO:     ydata_profiling: Not installed
2025-10-28 13:40:29,056:INFO:  explainerdashboard: Not installed
2025-10-28 13:40:29,056:INFO:             autoviz: Not installed
2025-10-28 13:40:29,057:INFO:           fairlearn: Not installed
2025-10-28 13:40:29,057:INFO:          deepchecks: Not installed
2025-10-28 13:40:29,057:INFO:             xgboost: Not installed
2025-10-28 13:40:29,057:INFO:            catboost: Not installed
2025-10-28 13:40:29,057:INFO:              kmodes: Not installed
2025-10-28 13:40:29,057:INFO:             mlxtend: Not installed
2025-10-28 13:40:29,058:INFO:       statsforecast: Not installed
2025-10-28 13:40:29,058:INFO:        tune_sklearn: Not installed
2025-10-28 13:40:29,058:INFO:                 ray: Not installed
2025-10-28 13:40:29,059:INFO:            hyperopt: Not installed
2025-10-28 13:40:29,060:INFO:              optuna: Not installed
2025-10-28 13:40:29,060:INFO:               skopt: Not installed
2025-10-28 13:40:29,060:INFO:              mlflow: Not installed
2025-10-28 13:40:29,061:INFO:              gradio: Not installed
2025-10-28 13:40:29,061:INFO:             fastapi: Not installed
2025-10-28 13:40:29,061:INFO:             uvicorn: Not installed
2025-10-28 13:40:29,061:INFO:              m2cgen: Not installed
2025-10-28 13:40:29,062:INFO:           evidently: Not installed
2025-10-28 13:40:29,062:INFO:               fugue: Not installed
2025-10-28 13:40:29,062:INFO:           streamlit: 1.50.0
2025-10-28 13:40:29,062:INFO:             prophet: Not installed
2025-10-28 13:40:29,062:INFO:None
2025-10-28 13:40:29,062:INFO:Set up data.
2025-10-28 13:40:29,066:INFO:Set up folding strategy.
2025-10-28 13:40:29,066:INFO:Set up train/test split.
2025-10-28 13:40:29,070:INFO:Set up index.
2025-10-28 13:40:29,071:INFO:Assigning column types.
2025-10-28 13:40:29,075:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 13:40:29,075:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,081:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,100:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,207:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,255:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,256:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,257:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,257:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,262:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,266:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,334:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,389:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,391:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,391:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 13:40:29,404:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,409:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,538:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,540:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,540:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,545:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,550:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,694:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,697:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 13:40:29,711:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,794:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,873:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:29,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,875:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:29,886:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,002:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,059:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,062:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,062:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 13:40:30,192:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,239:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,240:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,240:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,302:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,359:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,360:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,360:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,361:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 13:40:30,492:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,573:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:40:30,746:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,747:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,747:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 13:40:30,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:30,867:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,000:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,001:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,002:INFO:Preparing preprocessing pipeline...
2025-10-28 13:40:31,002:INFO:Set up simple imputation.
2025-10-28 13:40:31,002:INFO:Set up column name cleaning.
2025-10-28 13:40:31,020:INFO:Finished creating preprocessing pipeline.
2025-10-28 13:40:31,023:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)', 'target'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 13:40:31,023:INFO:Creating final display dataframe.
2025-10-28 13:40:31,089:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  sepal length (cm)
2                   Target type         Regression
3           Original data shape           (150, 5)
4        Transformed data shape           (150, 5)
5   Transformed train set shape           (105, 5)
6    Transformed test set shape            (45, 5)
7              Numeric features                  4
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12               Fold Generator              KFold
13                  Fold Number                 10
14                     CPU Jobs                 -1
15                      Use GPU              False
16               Log Experiment              False
17              Experiment Name   reg-default-name
18                          USI               47da
2025-10-28 13:40:31,234:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,234:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,416:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,416:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:40:31,417:INFO:setup() successfully completed in 2.37s...............
2025-10-28 13:40:31,417:INFO:Initializing compare_models()
2025-10-28 13:40:31,417:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 13:40:31,417:INFO:Checking exceptions
2025-10-28 13:40:31,419:INFO:Preparing display monitor
2025-10-28 13:40:31,424:INFO:Initializing Linear Regression
2025-10-28 13:40:31,424:INFO:Total runtime is 0.0 minutes
2025-10-28 13:40:31,425:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:31,425:INFO:Initializing create_model()
2025-10-28 13:40:31,425:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:31,425:INFO:Checking exceptions
2025-10-28 13:40:31,425:INFO:Importing libraries
2025-10-28 13:40:31,425:INFO:Copying training dataset
2025-10-28 13:40:31,429:INFO:Defining folds
2025-10-28 13:40:31,429:INFO:Declaring metric variables
2025-10-28 13:40:31,429:INFO:Importing untrained model
2025-10-28 13:40:31,430:INFO:Linear Regression Imported successfully
2025-10-28 13:40:31,430:INFO:Starting cross validation
2025-10-28 13:40:31,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:36,070:INFO:Calculating mean and std
2025-10-28 13:40:36,077:INFO:Creating metrics dataframe
2025-10-28 13:40:36,080:INFO:Uploading results into container
2025-10-28 13:40:36,081:INFO:Uploading model into container now
2025-10-28 13:40:36,082:INFO:_master_model_container: 1
2025-10-28 13:40:36,082:INFO:_display_container: 2
2025-10-28 13:40:36,082:INFO:LinearRegression(n_jobs=-1)
2025-10-28 13:40:36,082:INFO:create_model() successfully completed......................................
2025-10-28 13:40:36,248:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:36,248:INFO:Creating metrics dataframe
2025-10-28 13:40:36,250:INFO:Initializing Lasso Regression
2025-10-28 13:40:36,250:INFO:Total runtime is 0.08044049739837647 minutes
2025-10-28 13:40:36,250:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:36,250:INFO:Initializing create_model()
2025-10-28 13:40:36,250:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:36,250:INFO:Checking exceptions
2025-10-28 13:40:36,250:INFO:Importing libraries
2025-10-28 13:40:36,250:INFO:Copying training dataset
2025-10-28 13:40:36,253:INFO:Defining folds
2025-10-28 13:40:36,253:INFO:Declaring metric variables
2025-10-28 13:40:36,253:INFO:Importing untrained model
2025-10-28 13:40:36,253:INFO:Lasso Regression Imported successfully
2025-10-28 13:40:36,253:INFO:Starting cross validation
2025-10-28 13:40:36,255:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:39,061:INFO:Calculating mean and std
2025-10-28 13:40:39,062:INFO:Creating metrics dataframe
2025-10-28 13:40:39,065:INFO:Uploading results into container
2025-10-28 13:40:39,067:INFO:Uploading model into container now
2025-10-28 13:40:39,067:INFO:_master_model_container: 2
2025-10-28 13:40:39,068:INFO:_display_container: 2
2025-10-28 13:40:39,068:INFO:Lasso(random_state=123)
2025-10-28 13:40:39,068:INFO:create_model() successfully completed......................................
2025-10-28 13:40:39,211:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:39,211:INFO:Creating metrics dataframe
2025-10-28 13:40:39,215:INFO:Initializing Ridge Regression
2025-10-28 13:40:39,215:INFO:Total runtime is 0.12986170053482055 minutes
2025-10-28 13:40:39,215:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:39,215:INFO:Initializing create_model()
2025-10-28 13:40:39,215:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:39,215:INFO:Checking exceptions
2025-10-28 13:40:39,215:INFO:Importing libraries
2025-10-28 13:40:39,215:INFO:Copying training dataset
2025-10-28 13:40:39,219:INFO:Defining folds
2025-10-28 13:40:39,219:INFO:Declaring metric variables
2025-10-28 13:40:39,219:INFO:Importing untrained model
2025-10-28 13:40:39,220:INFO:Ridge Regression Imported successfully
2025-10-28 13:40:39,220:INFO:Starting cross validation
2025-10-28 13:40:39,221:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:39,305:INFO:Calculating mean and std
2025-10-28 13:40:39,306:INFO:Creating metrics dataframe
2025-10-28 13:40:39,310:INFO:Uploading results into container
2025-10-28 13:40:39,311:INFO:Uploading model into container now
2025-10-28 13:40:39,312:INFO:_master_model_container: 3
2025-10-28 13:40:39,312:INFO:_display_container: 2
2025-10-28 13:40:39,312:INFO:Ridge(random_state=123)
2025-10-28 13:40:39,313:INFO:create_model() successfully completed......................................
2025-10-28 13:40:39,448:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:39,448:INFO:Creating metrics dataframe
2025-10-28 13:40:39,450:INFO:Initializing Elastic Net
2025-10-28 13:40:39,450:INFO:Total runtime is 0.13378164370854695 minutes
2025-10-28 13:40:39,450:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:39,451:INFO:Initializing create_model()
2025-10-28 13:40:39,451:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:39,451:INFO:Checking exceptions
2025-10-28 13:40:39,451:INFO:Importing libraries
2025-10-28 13:40:39,451:INFO:Copying training dataset
2025-10-28 13:40:39,457:INFO:Defining folds
2025-10-28 13:40:39,457:INFO:Declaring metric variables
2025-10-28 13:40:39,458:INFO:Importing untrained model
2025-10-28 13:40:39,458:INFO:Elastic Net Imported successfully
2025-10-28 13:40:39,458:INFO:Starting cross validation
2025-10-28 13:40:39,458:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:39,558:INFO:Calculating mean and std
2025-10-28 13:40:39,560:INFO:Creating metrics dataframe
2025-10-28 13:40:39,562:INFO:Uploading results into container
2025-10-28 13:40:39,562:INFO:Uploading model into container now
2025-10-28 13:40:39,563:INFO:_master_model_container: 4
2025-10-28 13:40:39,563:INFO:_display_container: 2
2025-10-28 13:40:39,563:INFO:ElasticNet(random_state=123)
2025-10-28 13:40:39,563:INFO:create_model() successfully completed......................................
2025-10-28 13:40:39,721:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:39,721:INFO:Creating metrics dataframe
2025-10-28 13:40:39,725:INFO:Initializing Least Angle Regression
2025-10-28 13:40:39,725:INFO:Total runtime is 0.13836123545964557 minutes
2025-10-28 13:40:39,726:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:39,726:INFO:Initializing create_model()
2025-10-28 13:40:39,726:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:39,726:INFO:Checking exceptions
2025-10-28 13:40:39,726:INFO:Importing libraries
2025-10-28 13:40:39,726:INFO:Copying training dataset
2025-10-28 13:40:39,732:INFO:Defining folds
2025-10-28 13:40:39,732:INFO:Declaring metric variables
2025-10-28 13:40:39,732:INFO:Importing untrained model
2025-10-28 13:40:39,732:INFO:Least Angle Regression Imported successfully
2025-10-28 13:40:39,732:INFO:Starting cross validation
2025-10-28 13:40:39,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:39,889:INFO:Calculating mean and std
2025-10-28 13:40:39,890:INFO:Creating metrics dataframe
2025-10-28 13:40:39,894:INFO:Uploading results into container
2025-10-28 13:40:39,895:INFO:Uploading model into container now
2025-10-28 13:40:39,895:INFO:_master_model_container: 5
2025-10-28 13:40:39,896:INFO:_display_container: 2
2025-10-28 13:40:39,896:INFO:Lars(random_state=123)
2025-10-28 13:40:39,896:INFO:create_model() successfully completed......................................
2025-10-28 13:40:40,010:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:40,010:INFO:Creating metrics dataframe
2025-10-28 13:40:40,016:INFO:Initializing Lasso Least Angle Regression
2025-10-28 13:40:40,016:INFO:Total runtime is 0.14320318301518756 minutes
2025-10-28 13:40:40,017:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:40,017:INFO:Initializing create_model()
2025-10-28 13:40:40,018:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:40,018:INFO:Checking exceptions
2025-10-28 13:40:40,018:INFO:Importing libraries
2025-10-28 13:40:40,018:INFO:Copying training dataset
2025-10-28 13:40:40,023:INFO:Defining folds
2025-10-28 13:40:40,024:INFO:Declaring metric variables
2025-10-28 13:40:40,024:INFO:Importing untrained model
2025-10-28 13:40:40,024:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 13:40:40,026:INFO:Starting cross validation
2025-10-28 13:40:40,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:40,110:INFO:Calculating mean and std
2025-10-28 13:40:40,111:INFO:Creating metrics dataframe
2025-10-28 13:40:40,114:INFO:Uploading results into container
2025-10-28 13:40:40,114:INFO:Uploading model into container now
2025-10-28 13:40:40,115:INFO:_master_model_container: 6
2025-10-28 13:40:40,115:INFO:_display_container: 2
2025-10-28 13:40:40,115:INFO:LassoLars(random_state=123)
2025-10-28 13:40:40,116:INFO:create_model() successfully completed......................................
2025-10-28 13:40:40,221:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:40,221:INFO:Creating metrics dataframe
2025-10-28 13:40:40,224:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 13:40:40,224:INFO:Total runtime is 0.14667418400446572 minutes
2025-10-28 13:40:40,224:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:40,224:INFO:Initializing create_model()
2025-10-28 13:40:40,224:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:40,224:INFO:Checking exceptions
2025-10-28 13:40:40,224:INFO:Importing libraries
2025-10-28 13:40:40,224:INFO:Copying training dataset
2025-10-28 13:40:40,227:INFO:Defining folds
2025-10-28 13:40:40,227:INFO:Declaring metric variables
2025-10-28 13:40:40,227:INFO:Importing untrained model
2025-10-28 13:40:40,227:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 13:40:40,228:INFO:Starting cross validation
2025-10-28 13:40:40,228:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:40,293:INFO:Calculating mean and std
2025-10-28 13:40:40,295:INFO:Creating metrics dataframe
2025-10-28 13:40:40,299:INFO:Uploading results into container
2025-10-28 13:40:40,301:INFO:Uploading model into container now
2025-10-28 13:40:40,301:INFO:_master_model_container: 7
2025-10-28 13:40:40,302:INFO:_display_container: 2
2025-10-28 13:40:40,302:INFO:OrthogonalMatchingPursuit()
2025-10-28 13:40:40,302:INFO:create_model() successfully completed......................................
2025-10-28 13:40:40,437:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:40,438:INFO:Creating metrics dataframe
2025-10-28 13:40:40,442:INFO:Initializing Bayesian Ridge
2025-10-28 13:40:40,442:INFO:Total runtime is 0.15030199289321897 minutes
2025-10-28 13:40:40,443:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:40,444:INFO:Initializing create_model()
2025-10-28 13:40:40,445:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:40,446:INFO:Checking exceptions
2025-10-28 13:40:40,446:INFO:Importing libraries
2025-10-28 13:40:40,446:INFO:Copying training dataset
2025-10-28 13:40:40,453:INFO:Defining folds
2025-10-28 13:40:40,454:INFO:Declaring metric variables
2025-10-28 13:40:40,454:INFO:Importing untrained model
2025-10-28 13:40:40,455:INFO:Bayesian Ridge Imported successfully
2025-10-28 13:40:40,455:INFO:Starting cross validation
2025-10-28 13:40:40,456:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:40,561:INFO:Calculating mean and std
2025-10-28 13:40:40,563:INFO:Creating metrics dataframe
2025-10-28 13:40:40,566:INFO:Uploading results into container
2025-10-28 13:40:40,567:INFO:Uploading model into container now
2025-10-28 13:40:40,567:INFO:_master_model_container: 8
2025-10-28 13:40:40,569:INFO:_display_container: 2
2025-10-28 13:40:40,569:INFO:BayesianRidge()
2025-10-28 13:40:40,569:INFO:create_model() successfully completed......................................
2025-10-28 13:40:40,676:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:40,677:INFO:Creating metrics dataframe
2025-10-28 13:40:40,681:INFO:Initializing Passive Aggressive Regressor
2025-10-28 13:40:40,681:INFO:Total runtime is 0.1542899409929911 minutes
2025-10-28 13:40:40,681:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:40,682:INFO:Initializing create_model()
2025-10-28 13:40:40,682:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:40,682:INFO:Checking exceptions
2025-10-28 13:40:40,682:INFO:Importing libraries
2025-10-28 13:40:40,682:INFO:Copying training dataset
2025-10-28 13:40:40,684:INFO:Defining folds
2025-10-28 13:40:40,684:INFO:Declaring metric variables
2025-10-28 13:40:40,684:INFO:Importing untrained model
2025-10-28 13:40:40,684:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 13:40:40,684:INFO:Starting cross validation
2025-10-28 13:40:40,685:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:40,780:INFO:Calculating mean and std
2025-10-28 13:40:40,781:INFO:Creating metrics dataframe
2025-10-28 13:40:40,786:INFO:Uploading results into container
2025-10-28 13:40:40,787:INFO:Uploading model into container now
2025-10-28 13:40:40,787:INFO:_master_model_container: 9
2025-10-28 13:40:40,787:INFO:_display_container: 2
2025-10-28 13:40:40,788:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-28 13:40:40,788:INFO:create_model() successfully completed......................................
2025-10-28 13:40:40,914:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:40,914:INFO:Creating metrics dataframe
2025-10-28 13:40:40,918:INFO:Initializing Huber Regressor
2025-10-28 13:40:40,918:INFO:Total runtime is 0.15823986132939652 minutes
2025-10-28 13:40:40,918:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:40,918:INFO:Initializing create_model()
2025-10-28 13:40:40,918:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:40,918:INFO:Checking exceptions
2025-10-28 13:40:40,918:INFO:Importing libraries
2025-10-28 13:40:40,918:INFO:Copying training dataset
2025-10-28 13:40:40,922:INFO:Defining folds
2025-10-28 13:40:40,922:INFO:Declaring metric variables
2025-10-28 13:40:40,924:INFO:Importing untrained model
2025-10-28 13:40:40,924:INFO:Huber Regressor Imported successfully
2025-10-28 13:40:40,925:INFO:Starting cross validation
2025-10-28 13:40:40,926:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:41,015:INFO:Calculating mean and std
2025-10-28 13:40:41,017:INFO:Creating metrics dataframe
2025-10-28 13:40:41,022:INFO:Uploading results into container
2025-10-28 13:40:41,022:INFO:Uploading model into container now
2025-10-28 13:40:41,023:INFO:_master_model_container: 10
2025-10-28 13:40:41,024:INFO:_display_container: 2
2025-10-28 13:40:41,024:INFO:HuberRegressor()
2025-10-28 13:40:41,024:INFO:create_model() successfully completed......................................
2025-10-28 13:40:41,135:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:41,135:INFO:Creating metrics dataframe
2025-10-28 13:40:41,139:INFO:Initializing K Neighbors Regressor
2025-10-28 13:40:41,139:INFO:Total runtime is 0.16191812356313065 minutes
2025-10-28 13:40:41,139:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:41,140:INFO:Initializing create_model()
2025-10-28 13:40:41,140:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:41,140:INFO:Checking exceptions
2025-10-28 13:40:41,140:INFO:Importing libraries
2025-10-28 13:40:41,140:INFO:Copying training dataset
2025-10-28 13:40:41,144:INFO:Defining folds
2025-10-28 13:40:41,144:INFO:Declaring metric variables
2025-10-28 13:40:41,144:INFO:Importing untrained model
2025-10-28 13:40:41,144:INFO:K Neighbors Regressor Imported successfully
2025-10-28 13:40:41,145:INFO:Starting cross validation
2025-10-28 13:40:41,145:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:41,263:INFO:Calculating mean and std
2025-10-28 13:40:41,265:INFO:Creating metrics dataframe
2025-10-28 13:40:41,269:INFO:Uploading results into container
2025-10-28 13:40:41,270:INFO:Uploading model into container now
2025-10-28 13:40:41,271:INFO:_master_model_container: 11
2025-10-28 13:40:41,271:INFO:_display_container: 2
2025-10-28 13:40:41,271:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 13:40:41,272:INFO:create_model() successfully completed......................................
2025-10-28 13:40:41,391:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:41,391:INFO:Creating metrics dataframe
2025-10-28 13:40:41,397:INFO:Initializing Decision Tree Regressor
2025-10-28 13:40:41,397:INFO:Total runtime is 0.16621913115183506 minutes
2025-10-28 13:40:41,398:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:41,398:INFO:Initializing create_model()
2025-10-28 13:40:41,398:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:41,398:INFO:Checking exceptions
2025-10-28 13:40:41,399:INFO:Importing libraries
2025-10-28 13:40:41,399:INFO:Copying training dataset
2025-10-28 13:40:41,402:INFO:Defining folds
2025-10-28 13:40:41,403:INFO:Declaring metric variables
2025-10-28 13:40:41,403:INFO:Importing untrained model
2025-10-28 13:40:41,404:INFO:Decision Tree Regressor Imported successfully
2025-10-28 13:40:41,404:INFO:Starting cross validation
2025-10-28 13:40:41,405:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:41,481:INFO:Calculating mean and std
2025-10-28 13:40:41,483:INFO:Creating metrics dataframe
2025-10-28 13:40:41,487:INFO:Uploading results into container
2025-10-28 13:40:41,488:INFO:Uploading model into container now
2025-10-28 13:40:41,489:INFO:_master_model_container: 12
2025-10-28 13:40:41,489:INFO:_display_container: 2
2025-10-28 13:40:41,490:INFO:DecisionTreeRegressor(random_state=123)
2025-10-28 13:40:41,490:INFO:create_model() successfully completed......................................
2025-10-28 13:40:41,615:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:41,615:INFO:Creating metrics dataframe
2025-10-28 13:40:41,618:INFO:Initializing Random Forest Regressor
2025-10-28 13:40:41,618:INFO:Total runtime is 0.16991215546925856 minutes
2025-10-28 13:40:41,618:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:41,618:INFO:Initializing create_model()
2025-10-28 13:40:41,618:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:41,618:INFO:Checking exceptions
2025-10-28 13:40:41,618:INFO:Importing libraries
2025-10-28 13:40:41,618:INFO:Copying training dataset
2025-10-28 13:40:41,621:INFO:Defining folds
2025-10-28 13:40:41,621:INFO:Declaring metric variables
2025-10-28 13:40:41,621:INFO:Importing untrained model
2025-10-28 13:40:41,621:INFO:Random Forest Regressor Imported successfully
2025-10-28 13:40:41,621:INFO:Starting cross validation
2025-10-28 13:40:41,622:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:41,888:INFO:Calculating mean and std
2025-10-28 13:40:41,889:INFO:Creating metrics dataframe
2025-10-28 13:40:41,892:INFO:Uploading results into container
2025-10-28 13:40:41,892:INFO:Uploading model into container now
2025-10-28 13:40:41,894:INFO:_master_model_container: 13
2025-10-28 13:40:41,894:INFO:_display_container: 2
2025-10-28 13:40:41,895:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:40:41,895:INFO:create_model() successfully completed......................................
2025-10-28 13:40:42,005:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:42,006:INFO:Creating metrics dataframe
2025-10-28 13:40:42,011:INFO:Initializing Extra Trees Regressor
2025-10-28 13:40:42,011:INFO:Total runtime is 0.17645456393559766 minutes
2025-10-28 13:40:42,011:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:42,012:INFO:Initializing create_model()
2025-10-28 13:40:42,012:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:42,012:INFO:Checking exceptions
2025-10-28 13:40:42,012:INFO:Importing libraries
2025-10-28 13:40:42,012:INFO:Copying training dataset
2025-10-28 13:40:42,016:INFO:Defining folds
2025-10-28 13:40:42,016:INFO:Declaring metric variables
2025-10-28 13:40:42,016:INFO:Importing untrained model
2025-10-28 13:40:42,017:INFO:Extra Trees Regressor Imported successfully
2025-10-28 13:40:42,017:INFO:Starting cross validation
2025-10-28 13:40:42,018:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:42,256:INFO:Calculating mean and std
2025-10-28 13:40:42,258:INFO:Creating metrics dataframe
2025-10-28 13:40:42,262:INFO:Uploading results into container
2025-10-28 13:40:42,263:INFO:Uploading model into container now
2025-10-28 13:40:42,264:INFO:_master_model_container: 14
2025-10-28 13:40:42,264:INFO:_display_container: 2
2025-10-28 13:40:42,264:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:40:42,264:INFO:create_model() successfully completed......................................
2025-10-28 13:40:42,385:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:42,385:INFO:Creating metrics dataframe
2025-10-28 13:40:42,388:INFO:Initializing AdaBoost Regressor
2025-10-28 13:40:42,388:INFO:Total runtime is 0.18273474375406892 minutes
2025-10-28 13:40:42,388:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:42,389:INFO:Initializing create_model()
2025-10-28 13:40:42,389:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:42,389:INFO:Checking exceptions
2025-10-28 13:40:42,389:INFO:Importing libraries
2025-10-28 13:40:42,389:INFO:Copying training dataset
2025-10-28 13:40:42,392:INFO:Defining folds
2025-10-28 13:40:42,392:INFO:Declaring metric variables
2025-10-28 13:40:42,392:INFO:Importing untrained model
2025-10-28 13:40:42,392:INFO:AdaBoost Regressor Imported successfully
2025-10-28 13:40:42,392:INFO:Starting cross validation
2025-10-28 13:40:42,392:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:42,586:INFO:Calculating mean and std
2025-10-28 13:40:42,587:INFO:Creating metrics dataframe
2025-10-28 13:40:42,589:INFO:Uploading results into container
2025-10-28 13:40:42,590:INFO:Uploading model into container now
2025-10-28 13:40:42,590:INFO:_master_model_container: 15
2025-10-28 13:40:42,591:INFO:_display_container: 2
2025-10-28 13:40:42,591:INFO:AdaBoostRegressor(random_state=123)
2025-10-28 13:40:42,591:INFO:create_model() successfully completed......................................
2025-10-28 13:40:42,725:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:42,726:INFO:Creating metrics dataframe
2025-10-28 13:40:42,731:INFO:Initializing Gradient Boosting Regressor
2025-10-28 13:40:42,732:INFO:Total runtime is 0.1884757677714029 minutes
2025-10-28 13:40:42,733:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:42,734:INFO:Initializing create_model()
2025-10-28 13:40:42,734:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:42,735:INFO:Checking exceptions
2025-10-28 13:40:42,735:INFO:Importing libraries
2025-10-28 13:40:42,735:INFO:Copying training dataset
2025-10-28 13:40:42,739:INFO:Defining folds
2025-10-28 13:40:42,739:INFO:Declaring metric variables
2025-10-28 13:40:42,739:INFO:Importing untrained model
2025-10-28 13:40:42,739:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 13:40:42,740:INFO:Starting cross validation
2025-10-28 13:40:42,741:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:42,913:INFO:Calculating mean and std
2025-10-28 13:40:42,914:INFO:Creating metrics dataframe
2025-10-28 13:40:42,916:INFO:Uploading results into container
2025-10-28 13:40:42,917:INFO:Uploading model into container now
2025-10-28 13:40:42,918:INFO:_master_model_container: 16
2025-10-28 13:40:42,918:INFO:_display_container: 2
2025-10-28 13:40:42,919:INFO:GradientBoostingRegressor(random_state=123)
2025-10-28 13:40:42,919:INFO:create_model() successfully completed......................................
2025-10-28 13:40:43,039:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:43,039:INFO:Creating metrics dataframe
2025-10-28 13:40:43,043:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 13:40:43,044:INFO:Total runtime is 0.19367479085922232 minutes
2025-10-28 13:40:43,044:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:43,044:INFO:Initializing create_model()
2025-10-28 13:40:43,044:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:43,044:INFO:Checking exceptions
2025-10-28 13:40:43,044:INFO:Importing libraries
2025-10-28 13:40:43,044:INFO:Copying training dataset
2025-10-28 13:40:43,047:INFO:Defining folds
2025-10-28 13:40:43,047:INFO:Declaring metric variables
2025-10-28 13:40:43,047:INFO:Importing untrained model
2025-10-28 13:40:43,048:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 13:40:43,048:INFO:Starting cross validation
2025-10-28 13:40:43,048:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:43,566:INFO:Calculating mean and std
2025-10-28 13:40:43,568:INFO:Creating metrics dataframe
2025-10-28 13:40:43,570:INFO:Uploading results into container
2025-10-28 13:40:43,571:INFO:Uploading model into container now
2025-10-28 13:40:43,571:INFO:_master_model_container: 17
2025-10-28 13:40:43,571:INFO:_display_container: 2
2025-10-28 13:40:43,572:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:40:43,572:INFO:create_model() successfully completed......................................
2025-10-28 13:40:43,677:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:43,678:INFO:Creating metrics dataframe
2025-10-28 13:40:43,682:INFO:Initializing Dummy Regressor
2025-10-28 13:40:43,682:INFO:Total runtime is 0.20431327025095614 minutes
2025-10-28 13:40:43,683:INFO:SubProcess create_model() called ==================================
2025-10-28 13:40:43,684:INFO:Initializing create_model()
2025-10-28 13:40:43,684:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CFFDF090>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:43,684:INFO:Checking exceptions
2025-10-28 13:40:43,684:INFO:Importing libraries
2025-10-28 13:40:43,684:INFO:Copying training dataset
2025-10-28 13:40:43,688:INFO:Defining folds
2025-10-28 13:40:43,688:INFO:Declaring metric variables
2025-10-28 13:40:43,688:INFO:Importing untrained model
2025-10-28 13:40:43,688:INFO:Dummy Regressor Imported successfully
2025-10-28 13:40:43,688:INFO:Starting cross validation
2025-10-28 13:40:43,689:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:40:43,757:INFO:Calculating mean and std
2025-10-28 13:40:43,758:INFO:Creating metrics dataframe
2025-10-28 13:40:43,761:INFO:Uploading results into container
2025-10-28 13:40:43,762:INFO:Uploading model into container now
2025-10-28 13:40:43,763:INFO:_master_model_container: 18
2025-10-28 13:40:43,763:INFO:_display_container: 2
2025-10-28 13:40:43,763:INFO:DummyRegressor()
2025-10-28 13:40:43,763:INFO:create_model() successfully completed......................................
2025-10-28 13:40:43,879:INFO:SubProcess create_model() end ==================================
2025-10-28 13:40:43,879:INFO:Creating metrics dataframe
2025-10-28 13:40:43,885:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 13:40:43,887:INFO:Initializing create_model()
2025-10-28 13:40:43,888:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CFE66790>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:40:43,888:INFO:Checking exceptions
2025-10-28 13:40:43,889:INFO:Importing libraries
2025-10-28 13:40:43,889:INFO:Copying training dataset
2025-10-28 13:40:43,892:INFO:Defining folds
2025-10-28 13:40:43,893:INFO:Declaring metric variables
2025-10-28 13:40:43,893:INFO:Importing untrained model
2025-10-28 13:40:43,893:INFO:Declaring custom model
2025-10-28 13:40:43,895:INFO:Ridge Regression Imported successfully
2025-10-28 13:40:43,896:INFO:Cross validation set to False
2025-10-28 13:40:43,896:INFO:Fitting Model
2025-10-28 13:40:43,915:INFO:Ridge(random_state=123)
2025-10-28 13:40:43,915:INFO:create_model() successfully completed......................................
2025-10-28 13:40:44,061:INFO:_master_model_container: 18
2025-10-28 13:40:44,061:INFO:_display_container: 2
2025-10-28 13:40:44,062:INFO:Ridge(random_state=123)
2025-10-28 13:40:44,062:INFO:compare_models() successfully completed......................................
2025-10-28 13:43:47,957:INFO:PyCaret RegressionExperiment
2025-10-28 13:43:47,957:INFO:Logging name: reg-default-name
2025-10-28 13:43:47,957:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 13:43:47,958:INFO:version 3.3.2
2025-10-28 13:43:47,958:INFO:Initializing setup()
2025-10-28 13:43:47,958:INFO:self.USI: 752e
2025-10-28 13:43:47,958:INFO:self._variable_keys: {'_ml_usecase', 'y_train', 'data', 'fold_generator', 'fold_shuffle_param', 'log_plots_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X', 'USI', 'gpu_param', 'transform_target_param', 'X_test', 'exp_id', 'html_param', '_available_plots', 'memory', 'idx', 'target_param', 'y_test', 'seed', 'exp_name_log', 'pipeline', 'logging_param', 'n_jobs_param', 'y', 'X_train'}
2025-10-28 13:43:47,958:INFO:Checking environment
2025-10-28 13:43:47,958:INFO:python_version: 3.11.14
2025-10-28 13:43:47,958:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 13:43:47,958:INFO:machine: AMD64
2025-10-28 13:43:47,958:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 13:43:47,958:INFO:Memory: svmem(total=16788250624, available=2123640832, percent=87.4, used=14664609792, free=2123640832)
2025-10-28 13:43:47,958:INFO:Physical Core: 12
2025-10-28 13:43:47,959:INFO:Logical Core: 16
2025-10-28 13:43:47,959:INFO:Checking libraries
2025-10-28 13:43:47,959:INFO:System:
2025-10-28 13:43:47,959:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 13:43:47,959:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 13:43:47,959:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 13:43:47,959:INFO:PyCaret required dependencies:
2025-10-28 13:43:47,959:INFO:                 pip: 25.2
2025-10-28 13:43:47,959:INFO:          setuptools: 80.9.0
2025-10-28 13:43:47,959:INFO:             pycaret: 3.3.2
2025-10-28 13:43:47,959:INFO:             IPython: 9.6.0
2025-10-28 13:43:47,960:INFO:          ipywidgets: 8.1.7
2025-10-28 13:43:47,960:INFO:                tqdm: 4.67.1
2025-10-28 13:43:47,960:INFO:               numpy: 1.26.4
2025-10-28 13:43:47,960:INFO:              pandas: 2.1.4
2025-10-28 13:43:47,960:INFO:              jinja2: 3.1.6
2025-10-28 13:43:47,960:INFO:               scipy: 1.11.4
2025-10-28 13:43:47,960:INFO:              joblib: 1.3.2
2025-10-28 13:43:47,960:INFO:             sklearn: 1.4.2
2025-10-28 13:43:47,960:INFO:                pyod: 2.0.5
2025-10-28 13:43:47,961:INFO:            imblearn: 0.14.0
2025-10-28 13:43:47,961:INFO:   category_encoders: 2.7.0
2025-10-28 13:43:47,961:INFO:            lightgbm: 4.6.0
2025-10-28 13:43:47,961:INFO:               numba: 0.62.1
2025-10-28 13:43:47,961:INFO:            requests: 2.32.5
2025-10-28 13:43:47,961:INFO:          matplotlib: 3.10.7
2025-10-28 13:43:47,961:INFO:          scikitplot: 0.3.7
2025-10-28 13:43:47,961:INFO:         yellowbrick: 1.5
2025-10-28 13:43:47,961:INFO:              plotly: 6.3.1
2025-10-28 13:43:47,961:INFO:    plotly-resampler: Not installed
2025-10-28 13:43:47,961:INFO:             kaleido: 0.2.1
2025-10-28 13:43:47,961:INFO:           schemdraw: 0.15
2025-10-28 13:43:47,961:INFO:         statsmodels: 0.14.5
2025-10-28 13:43:47,961:INFO:              sktime: 0.26.0
2025-10-28 13:43:47,961:INFO:               tbats: 1.1.3
2025-10-28 13:43:47,961:INFO:            pmdarima: 2.0.4
2025-10-28 13:43:47,962:INFO:              psutil: 7.1.1
2025-10-28 13:43:47,962:INFO:          markupsafe: 3.0.3
2025-10-28 13:43:47,962:INFO:             pickle5: Not installed
2025-10-28 13:43:47,962:INFO:         cloudpickle: 3.1.1
2025-10-28 13:43:47,962:INFO:         deprecation: 2.1.0
2025-10-28 13:43:47,962:INFO:              xxhash: 3.6.0
2025-10-28 13:43:47,963:INFO:           wurlitzer: 3.1.1
2025-10-28 13:43:47,963:INFO:PyCaret optional dependencies:
2025-10-28 13:43:47,963:INFO:                shap: Not installed
2025-10-28 13:43:47,963:INFO:           interpret: Not installed
2025-10-28 13:43:47,963:INFO:                umap: 0.5.9.post2
2025-10-28 13:43:47,963:INFO:     ydata_profiling: Not installed
2025-10-28 13:43:47,963:INFO:  explainerdashboard: Not installed
2025-10-28 13:43:47,964:INFO:             autoviz: Not installed
2025-10-28 13:43:47,964:INFO:           fairlearn: Not installed
2025-10-28 13:43:47,964:INFO:          deepchecks: Not installed
2025-10-28 13:43:47,964:INFO:             xgboost: Not installed
2025-10-28 13:43:47,964:INFO:            catboost: Not installed
2025-10-28 13:43:47,964:INFO:              kmodes: Not installed
2025-10-28 13:43:47,964:INFO:             mlxtend: Not installed
2025-10-28 13:43:47,964:INFO:       statsforecast: Not installed
2025-10-28 13:43:47,964:INFO:        tune_sklearn: Not installed
2025-10-28 13:43:47,964:INFO:                 ray: Not installed
2025-10-28 13:43:47,964:INFO:            hyperopt: Not installed
2025-10-28 13:43:47,965:INFO:              optuna: Not installed
2025-10-28 13:43:47,965:INFO:               skopt: Not installed
2025-10-28 13:43:47,965:INFO:              mlflow: Not installed
2025-10-28 13:43:47,965:INFO:              gradio: Not installed
2025-10-28 13:43:47,965:INFO:             fastapi: Not installed
2025-10-28 13:43:47,965:INFO:             uvicorn: Not installed
2025-10-28 13:43:47,965:INFO:              m2cgen: Not installed
2025-10-28 13:43:47,965:INFO:           evidently: Not installed
2025-10-28 13:43:47,965:INFO:               fugue: Not installed
2025-10-28 13:43:47,966:INFO:           streamlit: 1.50.0
2025-10-28 13:43:47,966:INFO:             prophet: Not installed
2025-10-28 13:43:47,966:INFO:None
2025-10-28 13:43:47,966:INFO:Set up data.
2025-10-28 13:43:47,968:INFO:Set up folding strategy.
2025-10-28 13:43:47,969:INFO:Set up train/test split.
2025-10-28 13:43:47,971:INFO:Set up index.
2025-10-28 13:43:47,971:INFO:Assigning column types.
2025-10-28 13:43:47,975:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 13:43:47,975:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:43:47,978:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:43:47,981:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,018:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,045:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,046:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,046:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,047:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,050:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,052:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,118:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,119:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,119:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,119:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 13:43:48,122:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,125:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,188:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,192:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,194:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,228:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,253:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,253:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,255:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,255:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 13:43:48,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,294:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,319:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,326:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,385:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,386:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,386:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,387:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 13:43:48,426:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,452:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,454:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,454:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,495:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,522:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,523:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,523:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,523:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 13:43:48,561:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,590:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,590:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,630:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 13:43:48,658:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,658:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,658:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 13:43:48,727:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,727:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,797:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,797:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,798:INFO:Preparing preprocessing pipeline...
2025-10-28 13:43:48,798:INFO:Set up simple imputation.
2025-10-28 13:43:48,798:INFO:Set up column name cleaning.
2025-10-28 13:43:48,814:INFO:Finished creating preprocessing pipeline.
2025-10-28 13:43:48,817:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)', 'target'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=[],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 13:43:48,817:INFO:Creating final display dataframe.
2025-10-28 13:43:48,864:INFO:Setup _display_container:                     Description              Value
0                    Session id                123
1                        Target  sepal length (cm)
2                   Target type         Regression
3           Original data shape           (150, 5)
4        Transformed data shape           (150, 5)
5   Transformed train set shape           (105, 5)
6    Transformed test set shape            (45, 5)
7              Numeric features                  4
8                    Preprocess               True
9               Imputation type             simple
10           Numeric imputation               mean
11       Categorical imputation               mode
12               Fold Generator              KFold
13                  Fold Number                 10
14                     CPU Jobs                 -1
15                      Use GPU              False
16               Log Experiment              False
17              Experiment Name   reg-default-name
18                          USI               752e
2025-10-28 13:43:48,931:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,931:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,999:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:43:48,999:INFO:setup() successfully completed in 1.04s...............
2025-10-28 13:43:48,999:INFO:Initializing compare_models()
2025-10-28 13:43:48,999:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 13:43:48,999:INFO:Checking exceptions
2025-10-28 13:43:49,000:INFO:Preparing display monitor
2025-10-28 13:43:49,003:INFO:Initializing Linear Regression
2025-10-28 13:43:49,003:INFO:Total runtime is 0.0 minutes
2025-10-28 13:43:49,003:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,003:INFO:Initializing create_model()
2025-10-28 13:43:49,004:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,004:INFO:Checking exceptions
2025-10-28 13:43:49,004:INFO:Importing libraries
2025-10-28 13:43:49,004:INFO:Copying training dataset
2025-10-28 13:43:49,006:INFO:Defining folds
2025-10-28 13:43:49,006:INFO:Declaring metric variables
2025-10-28 13:43:49,007:INFO:Importing untrained model
2025-10-28 13:43:49,007:INFO:Linear Regression Imported successfully
2025-10-28 13:43:49,007:INFO:Starting cross validation
2025-10-28 13:43:49,007:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,059:INFO:Calculating mean and std
2025-10-28 13:43:49,060:INFO:Creating metrics dataframe
2025-10-28 13:43:49,061:INFO:Uploading results into container
2025-10-28 13:43:49,061:INFO:Uploading model into container now
2025-10-28 13:43:49,061:INFO:_master_model_container: 1
2025-10-28 13:43:49,061:INFO:_display_container: 2
2025-10-28 13:43:49,061:INFO:LinearRegression(n_jobs=-1)
2025-10-28 13:43:49,061:INFO:create_model() successfully completed......................................
2025-10-28 13:43:49,150:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:49,151:INFO:Creating metrics dataframe
2025-10-28 13:43:49,152:INFO:Initializing Lasso Regression
2025-10-28 13:43:49,152:INFO:Total runtime is 0.0024913628896077473 minutes
2025-10-28 13:43:49,153:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,153:INFO:Initializing create_model()
2025-10-28 13:43:49,153:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,153:INFO:Checking exceptions
2025-10-28 13:43:49,153:INFO:Importing libraries
2025-10-28 13:43:49,153:INFO:Copying training dataset
2025-10-28 13:43:49,157:INFO:Defining folds
2025-10-28 13:43:49,158:INFO:Declaring metric variables
2025-10-28 13:43:49,158:INFO:Importing untrained model
2025-10-28 13:43:49,158:INFO:Lasso Regression Imported successfully
2025-10-28 13:43:49,158:INFO:Starting cross validation
2025-10-28 13:43:49,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,214:INFO:Calculating mean and std
2025-10-28 13:43:49,216:INFO:Creating metrics dataframe
2025-10-28 13:43:49,217:INFO:Uploading results into container
2025-10-28 13:43:49,217:INFO:Uploading model into container now
2025-10-28 13:43:49,217:INFO:_master_model_container: 2
2025-10-28 13:43:49,217:INFO:_display_container: 2
2025-10-28 13:43:49,217:INFO:Lasso(random_state=123)
2025-10-28 13:43:49,217:INFO:create_model() successfully completed......................................
2025-10-28 13:43:49,297:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:49,297:INFO:Creating metrics dataframe
2025-10-28 13:43:49,299:INFO:Initializing Ridge Regression
2025-10-28 13:43:49,299:INFO:Total runtime is 0.004934271176656087 minutes
2025-10-28 13:43:49,299:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,299:INFO:Initializing create_model()
2025-10-28 13:43:49,300:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,300:INFO:Checking exceptions
2025-10-28 13:43:49,300:INFO:Importing libraries
2025-10-28 13:43:49,300:INFO:Copying training dataset
2025-10-28 13:43:49,301:INFO:Defining folds
2025-10-28 13:43:49,301:INFO:Declaring metric variables
2025-10-28 13:43:49,301:INFO:Importing untrained model
2025-10-28 13:43:49,301:INFO:Ridge Regression Imported successfully
2025-10-28 13:43:49,302:INFO:Starting cross validation
2025-10-28 13:43:49,303:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,357:INFO:Calculating mean and std
2025-10-28 13:43:49,357:INFO:Creating metrics dataframe
2025-10-28 13:43:49,358:INFO:Uploading results into container
2025-10-28 13:43:49,359:INFO:Uploading model into container now
2025-10-28 13:43:49,359:INFO:_master_model_container: 3
2025-10-28 13:43:49,359:INFO:_display_container: 2
2025-10-28 13:43:49,359:INFO:Ridge(random_state=123)
2025-10-28 13:43:49,359:INFO:create_model() successfully completed......................................
2025-10-28 13:43:49,441:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:49,441:INFO:Creating metrics dataframe
2025-10-28 13:43:49,443:INFO:Initializing Elastic Net
2025-10-28 13:43:49,443:INFO:Total runtime is 0.007333048184712728 minutes
2025-10-28 13:43:49,443:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,443:INFO:Initializing create_model()
2025-10-28 13:43:49,443:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,443:INFO:Checking exceptions
2025-10-28 13:43:49,443:INFO:Importing libraries
2025-10-28 13:43:49,443:INFO:Copying training dataset
2025-10-28 13:43:49,445:INFO:Defining folds
2025-10-28 13:43:49,445:INFO:Declaring metric variables
2025-10-28 13:43:49,445:INFO:Importing untrained model
2025-10-28 13:43:49,445:INFO:Elastic Net Imported successfully
2025-10-28 13:43:49,446:INFO:Starting cross validation
2025-10-28 13:43:49,446:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,499:INFO:Calculating mean and std
2025-10-28 13:43:49,499:INFO:Creating metrics dataframe
2025-10-28 13:43:49,500:INFO:Uploading results into container
2025-10-28 13:43:49,501:INFO:Uploading model into container now
2025-10-28 13:43:49,501:INFO:_master_model_container: 4
2025-10-28 13:43:49,501:INFO:_display_container: 2
2025-10-28 13:43:49,501:INFO:ElasticNet(random_state=123)
2025-10-28 13:43:49,501:INFO:create_model() successfully completed......................................
2025-10-28 13:43:49,587:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:49,587:INFO:Creating metrics dataframe
2025-10-28 13:43:49,591:INFO:Initializing Least Angle Regression
2025-10-28 13:43:49,591:INFO:Total runtime is 0.009810022513071696 minutes
2025-10-28 13:43:49,592:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,592:INFO:Initializing create_model()
2025-10-28 13:43:49,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,592:INFO:Checking exceptions
2025-10-28 13:43:49,592:INFO:Importing libraries
2025-10-28 13:43:49,592:INFO:Copying training dataset
2025-10-28 13:43:49,596:INFO:Defining folds
2025-10-28 13:43:49,596:INFO:Declaring metric variables
2025-10-28 13:43:49,596:INFO:Importing untrained model
2025-10-28 13:43:49,596:INFO:Least Angle Regression Imported successfully
2025-10-28 13:43:49,597:INFO:Starting cross validation
2025-10-28 13:43:49,597:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,647:INFO:Calculating mean and std
2025-10-28 13:43:49,647:INFO:Creating metrics dataframe
2025-10-28 13:43:49,649:INFO:Uploading results into container
2025-10-28 13:43:49,649:INFO:Uploading model into container now
2025-10-28 13:43:49,650:INFO:_master_model_container: 5
2025-10-28 13:43:49,650:INFO:_display_container: 2
2025-10-28 13:43:49,650:INFO:Lars(random_state=123)
2025-10-28 13:43:49,650:INFO:create_model() successfully completed......................................
2025-10-28 13:43:49,733:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:49,733:INFO:Creating metrics dataframe
2025-10-28 13:43:49,734:INFO:Initializing Lasso Least Angle Regression
2025-10-28 13:43:49,734:INFO:Total runtime is 0.012186841169993082 minutes
2025-10-28 13:43:49,735:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,735:INFO:Initializing create_model()
2025-10-28 13:43:49,735:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,735:INFO:Checking exceptions
2025-10-28 13:43:49,735:INFO:Importing libraries
2025-10-28 13:43:49,735:INFO:Copying training dataset
2025-10-28 13:43:49,737:INFO:Defining folds
2025-10-28 13:43:49,737:INFO:Declaring metric variables
2025-10-28 13:43:49,737:INFO:Importing untrained model
2025-10-28 13:43:49,737:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 13:43:49,738:INFO:Starting cross validation
2025-10-28 13:43:49,739:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,786:INFO:Calculating mean and std
2025-10-28 13:43:49,786:INFO:Creating metrics dataframe
2025-10-28 13:43:49,787:INFO:Uploading results into container
2025-10-28 13:43:49,788:INFO:Uploading model into container now
2025-10-28 13:43:49,788:INFO:_master_model_container: 6
2025-10-28 13:43:49,788:INFO:_display_container: 2
2025-10-28 13:43:49,789:INFO:LassoLars(random_state=123)
2025-10-28 13:43:49,789:INFO:create_model() successfully completed......................................
2025-10-28 13:43:49,867:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:49,867:INFO:Creating metrics dataframe
2025-10-28 13:43:49,868:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 13:43:49,869:INFO:Total runtime is 0.014439841111501057 minutes
2025-10-28 13:43:49,869:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:49,869:INFO:Initializing create_model()
2025-10-28 13:43:49,869:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:49,869:INFO:Checking exceptions
2025-10-28 13:43:49,869:INFO:Importing libraries
2025-10-28 13:43:49,869:INFO:Copying training dataset
2025-10-28 13:43:49,871:INFO:Defining folds
2025-10-28 13:43:49,871:INFO:Declaring metric variables
2025-10-28 13:43:49,871:INFO:Importing untrained model
2025-10-28 13:43:49,872:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 13:43:49,872:INFO:Starting cross validation
2025-10-28 13:43:49,872:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:49,916:INFO:Calculating mean and std
2025-10-28 13:43:49,916:INFO:Creating metrics dataframe
2025-10-28 13:43:49,917:INFO:Uploading results into container
2025-10-28 13:43:49,918:INFO:Uploading model into container now
2025-10-28 13:43:49,918:INFO:_master_model_container: 7
2025-10-28 13:43:49,918:INFO:_display_container: 2
2025-10-28 13:43:49,918:INFO:OrthogonalMatchingPursuit()
2025-10-28 13:43:49,918:INFO:create_model() successfully completed......................................
2025-10-28 13:43:50,008:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:50,008:INFO:Creating metrics dataframe
2025-10-28 13:43:50,010:INFO:Initializing Bayesian Ridge
2025-10-28 13:43:50,010:INFO:Total runtime is 0.016780940691630046 minutes
2025-10-28 13:43:50,011:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:50,011:INFO:Initializing create_model()
2025-10-28 13:43:50,011:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:50,011:INFO:Checking exceptions
2025-10-28 13:43:50,012:INFO:Importing libraries
2025-10-28 13:43:50,012:INFO:Copying training dataset
2025-10-28 13:43:50,014:INFO:Defining folds
2025-10-28 13:43:50,014:INFO:Declaring metric variables
2025-10-28 13:43:50,014:INFO:Importing untrained model
2025-10-28 13:43:50,015:INFO:Bayesian Ridge Imported successfully
2025-10-28 13:43:50,015:INFO:Starting cross validation
2025-10-28 13:43:50,015:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:50,068:INFO:Calculating mean and std
2025-10-28 13:43:50,068:INFO:Creating metrics dataframe
2025-10-28 13:43:50,069:INFO:Uploading results into container
2025-10-28 13:43:50,070:INFO:Uploading model into container now
2025-10-28 13:43:50,070:INFO:_master_model_container: 8
2025-10-28 13:43:50,070:INFO:_display_container: 2
2025-10-28 13:43:50,070:INFO:BayesianRidge()
2025-10-28 13:43:50,070:INFO:create_model() successfully completed......................................
2025-10-28 13:43:50,153:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:50,153:INFO:Creating metrics dataframe
2025-10-28 13:43:50,155:INFO:Initializing Passive Aggressive Regressor
2025-10-28 13:43:50,155:INFO:Total runtime is 0.019197960694630943 minutes
2025-10-28 13:43:50,155:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:50,155:INFO:Initializing create_model()
2025-10-28 13:43:50,155:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:50,155:INFO:Checking exceptions
2025-10-28 13:43:50,155:INFO:Importing libraries
2025-10-28 13:43:50,155:INFO:Copying training dataset
2025-10-28 13:43:50,157:INFO:Defining folds
2025-10-28 13:43:50,157:INFO:Declaring metric variables
2025-10-28 13:43:50,157:INFO:Importing untrained model
2025-10-28 13:43:50,157:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 13:43:50,159:INFO:Starting cross validation
2025-10-28 13:43:50,159:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:50,203:INFO:Calculating mean and std
2025-10-28 13:43:50,203:INFO:Creating metrics dataframe
2025-10-28 13:43:50,205:INFO:Uploading results into container
2025-10-28 13:43:50,205:INFO:Uploading model into container now
2025-10-28 13:43:50,206:INFO:_master_model_container: 9
2025-10-28 13:43:50,206:INFO:_display_container: 2
2025-10-28 13:43:50,206:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-28 13:43:50,206:INFO:create_model() successfully completed......................................
2025-10-28 13:43:50,280:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:50,281:INFO:Creating metrics dataframe
2025-10-28 13:43:50,282:INFO:Initializing Huber Regressor
2025-10-28 13:43:50,282:INFO:Total runtime is 0.02132421334584554 minutes
2025-10-28 13:43:50,282:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:50,282:INFO:Initializing create_model()
2025-10-28 13:43:50,282:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:50,282:INFO:Checking exceptions
2025-10-28 13:43:50,282:INFO:Importing libraries
2025-10-28 13:43:50,282:INFO:Copying training dataset
2025-10-28 13:43:50,285:INFO:Defining folds
2025-10-28 13:43:50,285:INFO:Declaring metric variables
2025-10-28 13:43:50,285:INFO:Importing untrained model
2025-10-28 13:43:50,285:INFO:Huber Regressor Imported successfully
2025-10-28 13:43:50,285:INFO:Starting cross validation
2025-10-28 13:43:50,286:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:50,336:INFO:Calculating mean and std
2025-10-28 13:43:50,336:INFO:Creating metrics dataframe
2025-10-28 13:43:50,338:INFO:Uploading results into container
2025-10-28 13:43:50,339:INFO:Uploading model into container now
2025-10-28 13:43:50,339:INFO:_master_model_container: 10
2025-10-28 13:43:50,340:INFO:_display_container: 2
2025-10-28 13:43:50,340:INFO:HuberRegressor()
2025-10-28 13:43:50,340:INFO:create_model() successfully completed......................................
2025-10-28 13:43:50,424:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:50,424:INFO:Creating metrics dataframe
2025-10-28 13:43:50,426:INFO:Initializing K Neighbors Regressor
2025-10-28 13:43:50,427:INFO:Total runtime is 0.023733270168304444 minutes
2025-10-28 13:43:50,427:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:50,427:INFO:Initializing create_model()
2025-10-28 13:43:50,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:50,427:INFO:Checking exceptions
2025-10-28 13:43:50,427:INFO:Importing libraries
2025-10-28 13:43:50,427:INFO:Copying training dataset
2025-10-28 13:43:50,430:INFO:Defining folds
2025-10-28 13:43:50,430:INFO:Declaring metric variables
2025-10-28 13:43:50,430:INFO:Importing untrained model
2025-10-28 13:43:50,430:INFO:K Neighbors Regressor Imported successfully
2025-10-28 13:43:50,431:INFO:Starting cross validation
2025-10-28 13:43:50,431:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:50,504:INFO:Calculating mean and std
2025-10-28 13:43:50,504:INFO:Creating metrics dataframe
2025-10-28 13:43:50,506:INFO:Uploading results into container
2025-10-28 13:43:50,506:INFO:Uploading model into container now
2025-10-28 13:43:50,507:INFO:_master_model_container: 11
2025-10-28 13:43:50,507:INFO:_display_container: 2
2025-10-28 13:43:50,507:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 13:43:50,507:INFO:create_model() successfully completed......................................
2025-10-28 13:43:50,586:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:50,587:INFO:Creating metrics dataframe
2025-10-28 13:43:50,592:INFO:Initializing Decision Tree Regressor
2025-10-28 13:43:50,592:INFO:Total runtime is 0.02648069461186727 minutes
2025-10-28 13:43:50,592:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:50,592:INFO:Initializing create_model()
2025-10-28 13:43:50,592:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:50,592:INFO:Checking exceptions
2025-10-28 13:43:50,592:INFO:Importing libraries
2025-10-28 13:43:50,592:INFO:Copying training dataset
2025-10-28 13:43:50,594:INFO:Defining folds
2025-10-28 13:43:50,594:INFO:Declaring metric variables
2025-10-28 13:43:50,594:INFO:Importing untrained model
2025-10-28 13:43:50,595:INFO:Decision Tree Regressor Imported successfully
2025-10-28 13:43:50,595:INFO:Starting cross validation
2025-10-28 13:43:50,595:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:50,646:INFO:Calculating mean and std
2025-10-28 13:43:50,646:INFO:Creating metrics dataframe
2025-10-28 13:43:50,647:INFO:Uploading results into container
2025-10-28 13:43:50,648:INFO:Uploading model into container now
2025-10-28 13:43:50,648:INFO:_master_model_container: 12
2025-10-28 13:43:50,648:INFO:_display_container: 2
2025-10-28 13:43:50,648:INFO:DecisionTreeRegressor(random_state=123)
2025-10-28 13:43:50,648:INFO:create_model() successfully completed......................................
2025-10-28 13:43:50,728:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:50,728:INFO:Creating metrics dataframe
2025-10-28 13:43:50,730:INFO:Initializing Random Forest Regressor
2025-10-28 13:43:50,730:INFO:Total runtime is 0.028782228628794353 minutes
2025-10-28 13:43:50,730:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:50,731:INFO:Initializing create_model()
2025-10-28 13:43:50,731:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:50,731:INFO:Checking exceptions
2025-10-28 13:43:50,731:INFO:Importing libraries
2025-10-28 13:43:50,731:INFO:Copying training dataset
2025-10-28 13:43:50,733:INFO:Defining folds
2025-10-28 13:43:50,733:INFO:Declaring metric variables
2025-10-28 13:43:50,733:INFO:Importing untrained model
2025-10-28 13:43:50,733:INFO:Random Forest Regressor Imported successfully
2025-10-28 13:43:50,733:INFO:Starting cross validation
2025-10-28 13:43:50,734:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:50,940:INFO:Calculating mean and std
2025-10-28 13:43:50,940:INFO:Creating metrics dataframe
2025-10-28 13:43:50,941:INFO:Uploading results into container
2025-10-28 13:43:50,941:INFO:Uploading model into container now
2025-10-28 13:43:50,942:INFO:_master_model_container: 13
2025-10-28 13:43:50,942:INFO:_display_container: 2
2025-10-28 13:43:50,942:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:43:50,942:INFO:create_model() successfully completed......................................
2025-10-28 13:43:51,021:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:51,021:INFO:Creating metrics dataframe
2025-10-28 13:43:51,024:INFO:Initializing Extra Trees Regressor
2025-10-28 13:43:51,024:INFO:Total runtime is 0.03368768294652303 minutes
2025-10-28 13:43:51,024:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:51,024:INFO:Initializing create_model()
2025-10-28 13:43:51,024:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:51,024:INFO:Checking exceptions
2025-10-28 13:43:51,024:INFO:Importing libraries
2025-10-28 13:43:51,024:INFO:Copying training dataset
2025-10-28 13:43:51,026:INFO:Defining folds
2025-10-28 13:43:51,026:INFO:Declaring metric variables
2025-10-28 13:43:51,026:INFO:Importing untrained model
2025-10-28 13:43:51,026:INFO:Extra Trees Regressor Imported successfully
2025-10-28 13:43:51,027:INFO:Starting cross validation
2025-10-28 13:43:51,027:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:51,200:INFO:Calculating mean and std
2025-10-28 13:43:51,201:INFO:Creating metrics dataframe
2025-10-28 13:43:51,202:INFO:Uploading results into container
2025-10-28 13:43:51,203:INFO:Uploading model into container now
2025-10-28 13:43:51,203:INFO:_master_model_container: 14
2025-10-28 13:43:51,203:INFO:_display_container: 2
2025-10-28 13:43:51,203:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:43:51,203:INFO:create_model() successfully completed......................................
2025-10-28 13:43:51,286:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:51,286:INFO:Creating metrics dataframe
2025-10-28 13:43:51,289:INFO:Initializing AdaBoost Regressor
2025-10-28 13:43:51,289:INFO:Total runtime is 0.03810691038767497 minutes
2025-10-28 13:43:51,289:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:51,290:INFO:Initializing create_model()
2025-10-28 13:43:51,290:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:51,290:INFO:Checking exceptions
2025-10-28 13:43:51,290:INFO:Importing libraries
2025-10-28 13:43:51,290:INFO:Copying training dataset
2025-10-28 13:43:51,292:INFO:Defining folds
2025-10-28 13:43:51,292:INFO:Declaring metric variables
2025-10-28 13:43:51,293:INFO:Importing untrained model
2025-10-28 13:43:51,293:INFO:AdaBoost Regressor Imported successfully
2025-10-28 13:43:51,293:INFO:Starting cross validation
2025-10-28 13:43:51,294:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:51,405:INFO:Calculating mean and std
2025-10-28 13:43:51,406:INFO:Creating metrics dataframe
2025-10-28 13:43:51,407:INFO:Uploading results into container
2025-10-28 13:43:51,408:INFO:Uploading model into container now
2025-10-28 13:43:51,408:INFO:_master_model_container: 15
2025-10-28 13:43:51,408:INFO:_display_container: 2
2025-10-28 13:43:51,408:INFO:AdaBoostRegressor(random_state=123)
2025-10-28 13:43:51,408:INFO:create_model() successfully completed......................................
2025-10-28 13:43:51,493:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:51,493:INFO:Creating metrics dataframe
2025-10-28 13:43:51,495:INFO:Initializing Gradient Boosting Regressor
2025-10-28 13:43:51,495:INFO:Total runtime is 0.041539756457010905 minutes
2025-10-28 13:43:51,495:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:51,495:INFO:Initializing create_model()
2025-10-28 13:43:51,495:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:51,495:INFO:Checking exceptions
2025-10-28 13:43:51,495:INFO:Importing libraries
2025-10-28 13:43:51,495:INFO:Copying training dataset
2025-10-28 13:43:51,497:INFO:Defining folds
2025-10-28 13:43:51,497:INFO:Declaring metric variables
2025-10-28 13:43:51,497:INFO:Importing untrained model
2025-10-28 13:43:51,498:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 13:43:51,498:INFO:Starting cross validation
2025-10-28 13:43:51,498:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:51,595:INFO:Calculating mean and std
2025-10-28 13:43:51,595:INFO:Creating metrics dataframe
2025-10-28 13:43:51,596:INFO:Uploading results into container
2025-10-28 13:43:51,597:INFO:Uploading model into container now
2025-10-28 13:43:51,597:INFO:_master_model_container: 16
2025-10-28 13:43:51,597:INFO:_display_container: 2
2025-10-28 13:43:51,597:INFO:GradientBoostingRegressor(random_state=123)
2025-10-28 13:43:51,597:INFO:create_model() successfully completed......................................
2025-10-28 13:43:51,678:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:51,678:INFO:Creating metrics dataframe
2025-10-28 13:43:51,680:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 13:43:51,680:INFO:Total runtime is 0.04462018410364787 minutes
2025-10-28 13:43:51,680:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:51,680:INFO:Initializing create_model()
2025-10-28 13:43:51,680:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:51,680:INFO:Checking exceptions
2025-10-28 13:43:51,680:INFO:Importing libraries
2025-10-28 13:43:51,680:INFO:Copying training dataset
2025-10-28 13:43:51,681:INFO:Defining folds
2025-10-28 13:43:51,681:INFO:Declaring metric variables
2025-10-28 13:43:51,683:INFO:Importing untrained model
2025-10-28 13:43:51,683:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 13:43:51,683:INFO:Starting cross validation
2025-10-28 13:43:51,684:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:51,991:INFO:Calculating mean and std
2025-10-28 13:43:51,991:INFO:Creating metrics dataframe
2025-10-28 13:43:51,994:INFO:Uploading results into container
2025-10-28 13:43:51,995:INFO:Uploading model into container now
2025-10-28 13:43:51,995:INFO:_master_model_container: 17
2025-10-28 13:43:51,995:INFO:_display_container: 2
2025-10-28 13:43:51,995:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 13:43:51,995:INFO:create_model() successfully completed......................................
2025-10-28 13:43:52,092:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:52,092:INFO:Creating metrics dataframe
2025-10-28 13:43:52,095:INFO:Initializing Dummy Regressor
2025-10-28 13:43:52,095:INFO:Total runtime is 0.05154019594192505 minutes
2025-10-28 13:43:52,095:INFO:SubProcess create_model() called ==================================
2025-10-28 13:43:52,095:INFO:Initializing create_model()
2025-10-28 13:43:52,095:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294CECB7590>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:52,096:INFO:Checking exceptions
2025-10-28 13:43:52,096:INFO:Importing libraries
2025-10-28 13:43:52,096:INFO:Copying training dataset
2025-10-28 13:43:52,098:INFO:Defining folds
2025-10-28 13:43:52,098:INFO:Declaring metric variables
2025-10-28 13:43:52,099:INFO:Importing untrained model
2025-10-28 13:43:52,099:INFO:Dummy Regressor Imported successfully
2025-10-28 13:43:52,099:INFO:Starting cross validation
2025-10-28 13:43:52,100:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:43:52,145:INFO:Calculating mean and std
2025-10-28 13:43:52,145:INFO:Creating metrics dataframe
2025-10-28 13:43:52,146:INFO:Uploading results into container
2025-10-28 13:43:52,146:INFO:Uploading model into container now
2025-10-28 13:43:52,146:INFO:_master_model_container: 18
2025-10-28 13:43:52,146:INFO:_display_container: 2
2025-10-28 13:43:52,147:INFO:DummyRegressor()
2025-10-28 13:43:52,147:INFO:create_model() successfully completed......................................
2025-10-28 13:43:52,226:INFO:SubProcess create_model() end ==================================
2025-10-28 13:43:52,226:INFO:Creating metrics dataframe
2025-10-28 13:43:52,229:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 13:43:52,230:INFO:Initializing create_model()
2025-10-28 13:43:52,230:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000294CE9B28D0>, estimator=Ridge(random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:43:52,230:INFO:Checking exceptions
2025-10-28 13:43:52,230:INFO:Importing libraries
2025-10-28 13:43:52,230:INFO:Copying training dataset
2025-10-28 13:43:52,232:INFO:Defining folds
2025-10-28 13:43:52,232:INFO:Declaring metric variables
2025-10-28 13:43:52,232:INFO:Importing untrained model
2025-10-28 13:43:52,232:INFO:Declaring custom model
2025-10-28 13:43:52,233:INFO:Ridge Regression Imported successfully
2025-10-28 13:43:52,233:INFO:Cross validation set to False
2025-10-28 13:43:52,233:INFO:Fitting Model
2025-10-28 13:43:52,239:INFO:Ridge(random_state=123)
2025-10-28 13:43:52,239:INFO:create_model() successfully completed......................................
2025-10-28 13:43:52,332:INFO:_master_model_container: 18
2025-10-28 13:43:52,332:INFO:_display_container: 2
2025-10-28 13:43:52,332:INFO:Ridge(random_state=123)
2025-10-28 13:43:52,332:INFO:compare_models() successfully completed......................................
2025-10-28 13:44:56,401:INFO:PyCaret ClassificationExperiment
2025-10-28 13:44:56,401:INFO:Logging name: clf-default-name
2025-10-28 13:44:56,401:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 13:44:56,401:INFO:version 3.3.2
2025-10-28 13:44:56,401:INFO:Initializing setup()
2025-10-28 13:44:56,401:INFO:self.USI: 28c1
2025-10-28 13:44:56,401:INFO:self._variable_keys: {'_ml_usecase', 'y_train', 'data', 'fold_generator', 'fold_shuffle_param', 'is_multiclass', 'log_plots_param', 'gpu_n_jobs_param', 'fold_groups_param', 'X', 'USI', 'gpu_param', 'X_test', 'exp_id', 'html_param', '_available_plots', 'memory', 'idx', 'target_param', 'y_test', 'seed', 'exp_name_log', 'pipeline', 'logging_param', 'n_jobs_param', 'y', 'X_train', 'fix_imbalance'}
2025-10-28 13:44:56,401:INFO:Checking environment
2025-10-28 13:44:56,401:INFO:python_version: 3.11.14
2025-10-28 13:44:56,401:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 13:44:56,401:INFO:machine: AMD64
2025-10-28 13:44:56,401:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 13:44:56,402:INFO:Memory: svmem(total=16788250624, available=2133913600, percent=87.3, used=14654337024, free=2133913600)
2025-10-28 13:44:56,402:INFO:Physical Core: 12
2025-10-28 13:44:56,402:INFO:Logical Core: 16
2025-10-28 13:44:56,402:INFO:Checking libraries
2025-10-28 13:44:56,402:INFO:System:
2025-10-28 13:44:56,402:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 13:44:56,402:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 13:44:56,402:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 13:44:56,403:INFO:PyCaret required dependencies:
2025-10-28 13:44:56,403:INFO:                 pip: 25.2
2025-10-28 13:44:56,403:INFO:          setuptools: 80.9.0
2025-10-28 13:44:56,403:INFO:             pycaret: 3.3.2
2025-10-28 13:44:56,403:INFO:             IPython: 9.6.0
2025-10-28 13:44:56,404:INFO:          ipywidgets: 8.1.7
2025-10-28 13:44:56,404:INFO:                tqdm: 4.67.1
2025-10-28 13:44:56,404:INFO:               numpy: 1.26.4
2025-10-28 13:44:56,404:INFO:              pandas: 2.1.4
2025-10-28 13:44:56,404:INFO:              jinja2: 3.1.6
2025-10-28 13:44:56,404:INFO:               scipy: 1.11.4
2025-10-28 13:44:56,404:INFO:              joblib: 1.3.2
2025-10-28 13:44:56,404:INFO:             sklearn: 1.4.2
2025-10-28 13:44:56,405:INFO:                pyod: 2.0.5
2025-10-28 13:44:56,405:INFO:            imblearn: 0.14.0
2025-10-28 13:44:56,405:INFO:   category_encoders: 2.7.0
2025-10-28 13:44:56,405:INFO:            lightgbm: 4.6.0
2025-10-28 13:44:56,405:INFO:               numba: 0.62.1
2025-10-28 13:44:56,405:INFO:            requests: 2.32.5
2025-10-28 13:44:56,405:INFO:          matplotlib: 3.10.7
2025-10-28 13:44:56,405:INFO:          scikitplot: 0.3.7
2025-10-28 13:44:56,405:INFO:         yellowbrick: 1.5
2025-10-28 13:44:56,405:INFO:              plotly: 6.3.1
2025-10-28 13:44:56,405:INFO:    plotly-resampler: Not installed
2025-10-28 13:44:56,405:INFO:             kaleido: 0.2.1
2025-10-28 13:44:56,405:INFO:           schemdraw: 0.15
2025-10-28 13:44:56,405:INFO:         statsmodels: 0.14.5
2025-10-28 13:44:56,405:INFO:              sktime: 0.26.0
2025-10-28 13:44:56,405:INFO:               tbats: 1.1.3
2025-10-28 13:44:56,406:INFO:            pmdarima: 2.0.4
2025-10-28 13:44:56,406:INFO:              psutil: 7.1.1
2025-10-28 13:44:56,406:INFO:          markupsafe: 3.0.3
2025-10-28 13:44:56,406:INFO:             pickle5: Not installed
2025-10-28 13:44:56,406:INFO:         cloudpickle: 3.1.1
2025-10-28 13:44:56,407:INFO:         deprecation: 2.1.0
2025-10-28 13:44:56,407:INFO:              xxhash: 3.6.0
2025-10-28 13:44:56,407:INFO:           wurlitzer: 3.1.1
2025-10-28 13:44:56,407:INFO:PyCaret optional dependencies:
2025-10-28 13:44:56,407:INFO:                shap: Not installed
2025-10-28 13:44:56,407:INFO:           interpret: Not installed
2025-10-28 13:44:56,407:INFO:                umap: 0.5.9.post2
2025-10-28 13:44:56,407:INFO:     ydata_profiling: Not installed
2025-10-28 13:44:56,407:INFO:  explainerdashboard: Not installed
2025-10-28 13:44:56,407:INFO:             autoviz: Not installed
2025-10-28 13:44:56,408:INFO:           fairlearn: Not installed
2025-10-28 13:44:56,408:INFO:          deepchecks: Not installed
2025-10-28 13:44:56,408:INFO:             xgboost: Not installed
2025-10-28 13:44:56,409:INFO:            catboost: Not installed
2025-10-28 13:44:56,409:INFO:              kmodes: Not installed
2025-10-28 13:44:56,409:INFO:             mlxtend: Not installed
2025-10-28 13:44:56,409:INFO:       statsforecast: Not installed
2025-10-28 13:44:56,410:INFO:        tune_sklearn: Not installed
2025-10-28 13:44:56,410:INFO:                 ray: Not installed
2025-10-28 13:44:56,410:INFO:            hyperopt: Not installed
2025-10-28 13:44:56,410:INFO:              optuna: Not installed
2025-10-28 13:44:56,410:INFO:               skopt: Not installed
2025-10-28 13:44:56,410:INFO:              mlflow: Not installed
2025-10-28 13:44:56,410:INFO:              gradio: Not installed
2025-10-28 13:44:56,410:INFO:             fastapi: Not installed
2025-10-28 13:44:56,410:INFO:             uvicorn: Not installed
2025-10-28 13:44:56,410:INFO:              m2cgen: Not installed
2025-10-28 13:44:56,410:INFO:           evidently: Not installed
2025-10-28 13:44:56,410:INFO:               fugue: Not installed
2025-10-28 13:44:56,410:INFO:           streamlit: 1.50.0
2025-10-28 13:44:56,410:INFO:             prophet: Not installed
2025-10-28 13:44:56,410:INFO:None
2025-10-28 13:44:56,410:INFO:Set up data.
2025-10-28 13:44:56,412:INFO:Set up folding strategy.
2025-10-28 13:44:56,412:INFO:Set up train/test split.
2025-10-28 13:44:56,419:INFO:Set up index.
2025-10-28 13:44:56,419:INFO:Assigning column types.
2025-10-28 13:44:56,421:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 13:44:56,448:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:44:56,452:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 13:44:56,472:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,472:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,500:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 13:44:56,500:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 13:44:56,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,517:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 13:44:56,544:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 13:44:56,561:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,561:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,588:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 13:44:56,605:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,605:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,605:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 13:44:56,651:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,651:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,694:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,694:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,695:INFO:Preparing preprocessing pipeline...
2025-10-28 13:44:56,701:INFO:Set up simple imputation.
2025-10-28 13:44:56,701:INFO:Set up column name cleaning.
2025-10-28 13:44:56,715:INFO:Finished creating preprocessing pipeline.
2025-10-28 13:44:56,717:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-28 13:44:56,718:INFO:Creating final display dataframe.
2025-10-28 13:44:56,759:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              28c1
2025-10-28 13:44:56,802:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,848:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 13:44:56,849:INFO:setup() successfully completed in 0.45s...............
2025-10-28 13:44:56,849:INFO:Initializing compare_models()
2025-10-28 13:44:56,849:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-28 13:44:56,849:INFO:Checking exceptions
2025-10-28 13:44:56,855:INFO:Preparing display monitor
2025-10-28 13:44:56,857:INFO:Initializing Logistic Regression
2025-10-28 13:44:56,857:INFO:Total runtime is 0.0 minutes
2025-10-28 13:44:56,857:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:56,857:INFO:Initializing create_model()
2025-10-28 13:44:56,857:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:56,857:INFO:Checking exceptions
2025-10-28 13:44:56,857:INFO:Importing libraries
2025-10-28 13:44:56,857:INFO:Copying training dataset
2025-10-28 13:44:56,859:INFO:Defining folds
2025-10-28 13:44:56,859:INFO:Declaring metric variables
2025-10-28 13:44:56,859:INFO:Importing untrained model
2025-10-28 13:44:56,859:INFO:Logistic Regression Imported successfully
2025-10-28 13:44:56,859:INFO:Starting cross validation
2025-10-28 13:44:56,860:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:56,908:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,908:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,908:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,909:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,909:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,910:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,910:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,911:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,912:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,919:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:56,932:INFO:Calculating mean and std
2025-10-28 13:44:56,932:INFO:Creating metrics dataframe
2025-10-28 13:44:56,933:INFO:Uploading results into container
2025-10-28 13:44:56,933:INFO:Uploading model into container now
2025-10-28 13:44:56,934:INFO:_master_model_container: 1
2025-10-28 13:44:56,934:INFO:_display_container: 2
2025-10-28 13:44:56,934:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 13:44:56,934:INFO:create_model() successfully completed......................................
2025-10-28 13:44:57,008:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:57,008:INFO:Creating metrics dataframe
2025-10-28 13:44:57,010:INFO:Initializing K Neighbors Classifier
2025-10-28 13:44:57,010:INFO:Total runtime is 0.002559916178385417 minutes
2025-10-28 13:44:57,010:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:57,010:INFO:Initializing create_model()
2025-10-28 13:44:57,010:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:57,010:INFO:Checking exceptions
2025-10-28 13:44:57,010:INFO:Importing libraries
2025-10-28 13:44:57,010:INFO:Copying training dataset
2025-10-28 13:44:57,013:INFO:Defining folds
2025-10-28 13:44:57,013:INFO:Declaring metric variables
2025-10-28 13:44:57,013:INFO:Importing untrained model
2025-10-28 13:44:57,013:INFO:K Neighbors Classifier Imported successfully
2025-10-28 13:44:57,014:INFO:Starting cross validation
2025-10-28 13:44:57,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:57,104:INFO:Calculating mean and std
2025-10-28 13:44:57,104:INFO:Creating metrics dataframe
2025-10-28 13:44:57,105:INFO:Uploading results into container
2025-10-28 13:44:57,106:INFO:Uploading model into container now
2025-10-28 13:44:57,106:INFO:_master_model_container: 2
2025-10-28 13:44:57,106:INFO:_display_container: 2
2025-10-28 13:44:57,106:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-28 13:44:57,106:INFO:create_model() successfully completed......................................
2025-10-28 13:44:57,191:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:57,191:INFO:Creating metrics dataframe
2025-10-28 13:44:57,193:INFO:Initializing Naive Bayes
2025-10-28 13:44:57,193:INFO:Total runtime is 0.0056093176205952965 minutes
2025-10-28 13:44:57,194:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:57,194:INFO:Initializing create_model()
2025-10-28 13:44:57,194:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:57,194:INFO:Checking exceptions
2025-10-28 13:44:57,194:INFO:Importing libraries
2025-10-28 13:44:57,194:INFO:Copying training dataset
2025-10-28 13:44:57,197:INFO:Defining folds
2025-10-28 13:44:57,197:INFO:Declaring metric variables
2025-10-28 13:44:57,197:INFO:Importing untrained model
2025-10-28 13:44:57,198:INFO:Naive Bayes Imported successfully
2025-10-28 13:44:57,199:INFO:Starting cross validation
2025-10-28 13:44:57,200:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:57,250:INFO:Calculating mean and std
2025-10-28 13:44:57,250:INFO:Creating metrics dataframe
2025-10-28 13:44:57,251:INFO:Uploading results into container
2025-10-28 13:44:57,252:INFO:Uploading model into container now
2025-10-28 13:44:57,252:INFO:_master_model_container: 3
2025-10-28 13:44:57,252:INFO:_display_container: 2
2025-10-28 13:44:57,252:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-28 13:44:57,252:INFO:create_model() successfully completed......................................
2025-10-28 13:44:57,329:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:57,329:INFO:Creating metrics dataframe
2025-10-28 13:44:57,331:INFO:Initializing Decision Tree Classifier
2025-10-28 13:44:57,332:INFO:Total runtime is 0.007923535505930583 minutes
2025-10-28 13:44:57,332:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:57,332:INFO:Initializing create_model()
2025-10-28 13:44:57,332:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:57,332:INFO:Checking exceptions
2025-10-28 13:44:57,332:INFO:Importing libraries
2025-10-28 13:44:57,332:INFO:Copying training dataset
2025-10-28 13:44:57,334:INFO:Defining folds
2025-10-28 13:44:57,334:INFO:Declaring metric variables
2025-10-28 13:44:57,334:INFO:Importing untrained model
2025-10-28 13:44:57,334:INFO:Decision Tree Classifier Imported successfully
2025-10-28 13:44:57,335:INFO:Starting cross validation
2025-10-28 13:44:57,336:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:57,383:INFO:Calculating mean and std
2025-10-28 13:44:57,383:INFO:Creating metrics dataframe
2025-10-28 13:44:57,384:INFO:Uploading results into container
2025-10-28 13:44:57,384:INFO:Uploading model into container now
2025-10-28 13:44:57,385:INFO:_master_model_container: 4
2025-10-28 13:44:57,385:INFO:_display_container: 2
2025-10-28 13:44:57,385:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-28 13:44:57,385:INFO:create_model() successfully completed......................................
2025-10-28 13:44:57,463:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:57,463:INFO:Creating metrics dataframe
2025-10-28 13:44:57,465:INFO:Initializing SVM - Linear Kernel
2025-10-28 13:44:57,466:INFO:Total runtime is 0.010153365135192872 minutes
2025-10-28 13:44:57,466:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:57,466:INFO:Initializing create_model()
2025-10-28 13:44:57,466:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:57,466:INFO:Checking exceptions
2025-10-28 13:44:57,466:INFO:Importing libraries
2025-10-28 13:44:57,466:INFO:Copying training dataset
2025-10-28 13:44:57,467:INFO:Defining folds
2025-10-28 13:44:57,468:INFO:Declaring metric variables
2025-10-28 13:44:57,468:INFO:Importing untrained model
2025-10-28 13:44:57,468:INFO:SVM - Linear Kernel Imported successfully
2025-10-28 13:44:57,468:INFO:Starting cross validation
2025-10-28 13:44:57,469:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:57,517:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,520:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,521:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,522:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,522:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,523:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,524:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,525:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,525:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,526:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,528:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:44:57,529:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:44:57,530:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:44:57,532:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:44:57,532:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:44:57,539:INFO:Calculating mean and std
2025-10-28 13:44:57,539:INFO:Creating metrics dataframe
2025-10-28 13:44:57,540:INFO:Uploading results into container
2025-10-28 13:44:57,541:INFO:Uploading model into container now
2025-10-28 13:44:57,541:INFO:_master_model_container: 5
2025-10-28 13:44:57,541:INFO:_display_container: 2
2025-10-28 13:44:57,541:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-28 13:44:57,541:INFO:create_model() successfully completed......................................
2025-10-28 13:44:57,620:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:57,621:INFO:Creating metrics dataframe
2025-10-28 13:44:57,623:INFO:Initializing Ridge Classifier
2025-10-28 13:44:57,623:INFO:Total runtime is 0.012777002652486167 minutes
2025-10-28 13:44:57,623:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:57,623:INFO:Initializing create_model()
2025-10-28 13:44:57,623:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:57,624:INFO:Checking exceptions
2025-10-28 13:44:57,624:INFO:Importing libraries
2025-10-28 13:44:57,624:INFO:Copying training dataset
2025-10-28 13:44:57,626:INFO:Defining folds
2025-10-28 13:44:57,626:INFO:Declaring metric variables
2025-10-28 13:44:57,626:INFO:Importing untrained model
2025-10-28 13:44:57,627:INFO:Ridge Classifier Imported successfully
2025-10-28 13:44:57,627:INFO:Starting cross validation
2025-10-28 13:44:57,628:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:57,656:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,656:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,658:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,659:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,660:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,663:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,664:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,666:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,668:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,668:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:57,687:INFO:Calculating mean and std
2025-10-28 13:44:57,687:INFO:Creating metrics dataframe
2025-10-28 13:44:57,688:INFO:Uploading results into container
2025-10-28 13:44:57,689:INFO:Uploading model into container now
2025-10-28 13:44:57,689:INFO:_master_model_container: 6
2025-10-28 13:44:57,689:INFO:_display_container: 2
2025-10-28 13:44:57,689:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-28 13:44:57,689:INFO:create_model() successfully completed......................................
2025-10-28 13:44:57,772:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:57,772:INFO:Creating metrics dataframe
2025-10-28 13:44:57,774:INFO:Initializing Random Forest Classifier
2025-10-28 13:44:57,774:INFO:Total runtime is 0.015298147996266685 minutes
2025-10-28 13:44:57,774:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:57,774:INFO:Initializing create_model()
2025-10-28 13:44:57,774:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:57,774:INFO:Checking exceptions
2025-10-28 13:44:57,774:INFO:Importing libraries
2025-10-28 13:44:57,774:INFO:Copying training dataset
2025-10-28 13:44:57,776:INFO:Defining folds
2025-10-28 13:44:57,776:INFO:Declaring metric variables
2025-10-28 13:44:57,776:INFO:Importing untrained model
2025-10-28 13:44:57,777:INFO:Random Forest Classifier Imported successfully
2025-10-28 13:44:57,777:INFO:Starting cross validation
2025-10-28 13:44:57,777:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:58,043:INFO:Calculating mean and std
2025-10-28 13:44:58,043:INFO:Creating metrics dataframe
2025-10-28 13:44:58,045:INFO:Uploading results into container
2025-10-28 13:44:58,045:INFO:Uploading model into container now
2025-10-28 13:44:58,045:INFO:_master_model_container: 7
2025-10-28 13:44:58,045:INFO:_display_container: 2
2025-10-28 13:44:58,045:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-28 13:44:58,046:INFO:create_model() successfully completed......................................
2025-10-28 13:44:58,128:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:58,128:INFO:Creating metrics dataframe
2025-10-28 13:44:58,130:INFO:Initializing Quadratic Discriminant Analysis
2025-10-28 13:44:58,130:INFO:Total runtime is 0.0212168296178182 minutes
2025-10-28 13:44:58,130:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:58,131:INFO:Initializing create_model()
2025-10-28 13:44:58,131:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:58,131:INFO:Checking exceptions
2025-10-28 13:44:58,131:INFO:Importing libraries
2025-10-28 13:44:58,131:INFO:Copying training dataset
2025-10-28 13:44:58,132:INFO:Defining folds
2025-10-28 13:44:58,132:INFO:Declaring metric variables
2025-10-28 13:44:58,132:INFO:Importing untrained model
2025-10-28 13:44:58,132:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-28 13:44:58,133:INFO:Starting cross validation
2025-10-28 13:44:58,133:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:58,180:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,182:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,183:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,184:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,184:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,185:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,187:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,197:INFO:Calculating mean and std
2025-10-28 13:44:58,197:INFO:Creating metrics dataframe
2025-10-28 13:44:58,199:INFO:Uploading results into container
2025-10-28 13:44:58,200:INFO:Uploading model into container now
2025-10-28 13:44:58,200:INFO:_master_model_container: 8
2025-10-28 13:44:58,200:INFO:_display_container: 2
2025-10-28 13:44:58,200:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-28 13:44:58,200:INFO:create_model() successfully completed......................................
2025-10-28 13:44:58,282:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:58,282:INFO:Creating metrics dataframe
2025-10-28 13:44:58,284:INFO:Initializing Ada Boost Classifier
2025-10-28 13:44:58,284:INFO:Total runtime is 0.023792572816212974 minutes
2025-10-28 13:44:58,284:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:58,285:INFO:Initializing create_model()
2025-10-28 13:44:58,285:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:58,285:INFO:Checking exceptions
2025-10-28 13:44:58,285:INFO:Importing libraries
2025-10-28 13:44:58,285:INFO:Copying training dataset
2025-10-28 13:44:58,287:INFO:Defining folds
2025-10-28 13:44:58,287:INFO:Declaring metric variables
2025-10-28 13:44:58,287:INFO:Importing untrained model
2025-10-28 13:44:58,287:INFO:Ada Boost Classifier Imported successfully
2025-10-28 13:44:58,287:INFO:Starting cross validation
2025-10-28 13:44:58,288:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:58,304:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,305:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,306:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,307:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,309:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,311:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,312:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,313:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,314:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,316:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 13:44:58,359:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,367:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,383:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,384:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,386:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,390:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,392:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,395:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,401:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,404:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,410:INFO:Calculating mean and std
2025-10-28 13:44:58,410:INFO:Creating metrics dataframe
2025-10-28 13:44:58,412:INFO:Uploading results into container
2025-10-28 13:44:58,412:INFO:Uploading model into container now
2025-10-28 13:44:58,412:INFO:_master_model_container: 9
2025-10-28 13:44:58,412:INFO:_display_container: 2
2025-10-28 13:44:58,412:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-28 13:44:58,412:INFO:create_model() successfully completed......................................
2025-10-28 13:44:58,501:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:58,502:INFO:Creating metrics dataframe
2025-10-28 13:44:58,504:INFO:Initializing Gradient Boosting Classifier
2025-10-28 13:44:58,504:INFO:Total runtime is 0.027464564641316733 minutes
2025-10-28 13:44:58,504:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:58,505:INFO:Initializing create_model()
2025-10-28 13:44:58,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:58,505:INFO:Checking exceptions
2025-10-28 13:44:58,505:INFO:Importing libraries
2025-10-28 13:44:58,505:INFO:Copying training dataset
2025-10-28 13:44:58,507:INFO:Defining folds
2025-10-28 13:44:58,508:INFO:Declaring metric variables
2025-10-28 13:44:58,508:INFO:Importing untrained model
2025-10-28 13:44:58,508:INFO:Gradient Boosting Classifier Imported successfully
2025-10-28 13:44:58,508:INFO:Starting cross validation
2025-10-28 13:44:58,509:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:58,717:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,750:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,760:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,762:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,762:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,770:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,777:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,787:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,788:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,803:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,811:INFO:Calculating mean and std
2025-10-28 13:44:58,811:INFO:Creating metrics dataframe
2025-10-28 13:44:58,812:INFO:Uploading results into container
2025-10-28 13:44:58,812:INFO:Uploading model into container now
2025-10-28 13:44:58,813:INFO:_master_model_container: 10
2025-10-28 13:44:58,813:INFO:_display_container: 2
2025-10-28 13:44:58,813:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-28 13:44:58,813:INFO:create_model() successfully completed......................................
2025-10-28 13:44:58,899:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:58,899:INFO:Creating metrics dataframe
2025-10-28 13:44:58,901:INFO:Initializing Linear Discriminant Analysis
2025-10-28 13:44:58,901:INFO:Total runtime is 0.03406954209009806 minutes
2025-10-28 13:44:58,901:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:58,901:INFO:Initializing create_model()
2025-10-28 13:44:58,901:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:58,901:INFO:Checking exceptions
2025-10-28 13:44:58,901:INFO:Importing libraries
2025-10-28 13:44:58,901:INFO:Copying training dataset
2025-10-28 13:44:58,904:INFO:Defining folds
2025-10-28 13:44:58,904:INFO:Declaring metric variables
2025-10-28 13:44:58,904:INFO:Importing untrained model
2025-10-28 13:44:58,905:INFO:Linear Discriminant Analysis Imported successfully
2025-10-28 13:44:58,905:INFO:Starting cross validation
2025-10-28 13:44:58,905:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:58,928:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,929:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,930:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,932:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,934:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,938:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,938:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,941:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,941:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,942:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 13:44:58,954:INFO:Calculating mean and std
2025-10-28 13:44:58,954:INFO:Creating metrics dataframe
2025-10-28 13:44:58,956:INFO:Uploading results into container
2025-10-28 13:44:58,956:INFO:Uploading model into container now
2025-10-28 13:44:58,956:INFO:_master_model_container: 11
2025-10-28 13:44:58,956:INFO:_display_container: 2
2025-10-28 13:44:58,956:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-28 13:44:58,956:INFO:create_model() successfully completed......................................
2025-10-28 13:44:59,029:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:59,029:INFO:Creating metrics dataframe
2025-10-28 13:44:59,031:INFO:Initializing Extra Trees Classifier
2025-10-28 13:44:59,032:INFO:Total runtime is 0.03625601132710775 minutes
2025-10-28 13:44:59,032:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:59,032:INFO:Initializing create_model()
2025-10-28 13:44:59,032:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:59,032:INFO:Checking exceptions
2025-10-28 13:44:59,032:INFO:Importing libraries
2025-10-28 13:44:59,032:INFO:Copying training dataset
2025-10-28 13:44:59,033:INFO:Defining folds
2025-10-28 13:44:59,033:INFO:Declaring metric variables
2025-10-28 13:44:59,034:INFO:Importing untrained model
2025-10-28 13:44:59,034:INFO:Extra Trees Classifier Imported successfully
2025-10-28 13:44:59,034:INFO:Starting cross validation
2025-10-28 13:44:59,034:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:44:59,256:INFO:Calculating mean and std
2025-10-28 13:44:59,257:INFO:Creating metrics dataframe
2025-10-28 13:44:59,258:INFO:Uploading results into container
2025-10-28 13:44:59,258:INFO:Uploading model into container now
2025-10-28 13:44:59,259:INFO:_master_model_container: 12
2025-10-28 13:44:59,259:INFO:_display_container: 2
2025-10-28 13:44:59,259:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-28 13:44:59,259:INFO:create_model() successfully completed......................................
2025-10-28 13:44:59,334:INFO:SubProcess create_model() end ==================================
2025-10-28 13:44:59,334:INFO:Creating metrics dataframe
2025-10-28 13:44:59,336:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 13:44:59,336:INFO:Total runtime is 0.04131609996159871 minutes
2025-10-28 13:44:59,336:INFO:SubProcess create_model() called ==================================
2025-10-28 13:44:59,336:INFO:Initializing create_model()
2025-10-28 13:44:59,337:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:44:59,337:INFO:Checking exceptions
2025-10-28 13:44:59,337:INFO:Importing libraries
2025-10-28 13:44:59,337:INFO:Copying training dataset
2025-10-28 13:44:59,339:INFO:Defining folds
2025-10-28 13:44:59,339:INFO:Declaring metric variables
2025-10-28 13:44:59,339:INFO:Importing untrained model
2025-10-28 13:44:59,340:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 13:44:59,340:INFO:Starting cross validation
2025-10-28 13:44:59,341:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:45:00,094:INFO:Calculating mean and std
2025-10-28 13:45:00,095:INFO:Creating metrics dataframe
2025-10-28 13:45:00,096:INFO:Uploading results into container
2025-10-28 13:45:00,097:INFO:Uploading model into container now
2025-10-28 13:45:00,097:INFO:_master_model_container: 13
2025-10-28 13:45:00,097:INFO:_display_container: 2
2025-10-28 13:45:00,098:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-28 13:45:00,098:INFO:create_model() successfully completed......................................
2025-10-28 13:45:00,192:INFO:SubProcess create_model() end ==================================
2025-10-28 13:45:00,192:INFO:Creating metrics dataframe
2025-10-28 13:45:00,194:INFO:Initializing Dummy Classifier
2025-10-28 13:45:00,195:INFO:Total runtime is 0.05564041932423909 minutes
2025-10-28 13:45:00,195:INFO:SubProcess create_model() called ==================================
2025-10-28 13:45:00,195:INFO:Initializing create_model()
2025-10-28 13:45:00,195:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000294D0323610>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:45:00,195:INFO:Checking exceptions
2025-10-28 13:45:00,195:INFO:Importing libraries
2025-10-28 13:45:00,195:INFO:Copying training dataset
2025-10-28 13:45:00,197:INFO:Defining folds
2025-10-28 13:45:00,198:INFO:Declaring metric variables
2025-10-28 13:45:00,198:INFO:Importing untrained model
2025-10-28 13:45:00,198:INFO:Dummy Classifier Imported successfully
2025-10-28 13:45:00,198:INFO:Starting cross validation
2025-10-28 13:45:00,199:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 13:45:00,220:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,223:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,223:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,228:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,230:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,231:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,231:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,232:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,234:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,236:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 13:45:00,246:INFO:Calculating mean and std
2025-10-28 13:45:00,246:INFO:Creating metrics dataframe
2025-10-28 13:45:00,248:INFO:Uploading results into container
2025-10-28 13:45:00,249:INFO:Uploading model into container now
2025-10-28 13:45:00,249:INFO:_master_model_container: 14
2025-10-28 13:45:00,249:INFO:_display_container: 2
2025-10-28 13:45:00,249:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-28 13:45:00,249:INFO:create_model() successfully completed......................................
2025-10-28 13:45:00,327:INFO:SubProcess create_model() end ==================================
2025-10-28 13:45:00,327:INFO:Creating metrics dataframe
2025-10-28 13:45:00,329:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 13:45:00,331:INFO:Initializing create_model()
2025-10-28 13:45:00,331:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000294CE8D0E10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 13:45:00,331:INFO:Checking exceptions
2025-10-28 13:45:00,332:INFO:Importing libraries
2025-10-28 13:45:00,333:INFO:Copying training dataset
2025-10-28 13:45:00,334:INFO:Defining folds
2025-10-28 13:45:00,334:INFO:Declaring metric variables
2025-10-28 13:45:00,334:INFO:Importing untrained model
2025-10-28 13:45:00,334:INFO:Declaring custom model
2025-10-28 13:45:00,335:INFO:Logistic Regression Imported successfully
2025-10-28 13:45:00,335:INFO:Cross validation set to False
2025-10-28 13:45:00,335:INFO:Fitting Model
2025-10-28 13:45:00,352:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 13:45:00,352:INFO:create_model() successfully completed......................................
2025-10-28 13:45:00,443:INFO:_master_model_container: 14
2025-10-28 13:45:00,443:INFO:_display_container: 2
2025-10-28 13:45:00,444:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 13:45:00,444:INFO:compare_models() successfully completed......................................
