2025-10-28 10:12:03,141:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:12:03,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:12:03,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:12:03,143:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-28 10:14:49,220:INFO:PyCaret ClassificationExperiment
2025-10-28 10:14:49,222:INFO:Logging name: clf-default-name
2025-10-28 10:14:49,222:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:14:49,222:INFO:version 3.3.2
2025-10-28 10:14:49,222:INFO:Initializing setup()
2025-10-28 10:14:49,222:INFO:self.USI: 01c8
2025-10-28 10:14:49,222:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:14:49,226:INFO:Checking environment
2025-10-28 10:14:49,227:INFO:python_version: 3.11.14
2025-10-28 10:14:49,227:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:14:49,227:INFO:machine: AMD64
2025-10-28 10:14:49,268:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:14:49,269:INFO:Memory: svmem(total=16788250624, available=5147144192, percent=69.3, used=11641106432, free=5147144192)
2025-10-28 10:14:49,269:INFO:Physical Core: 12
2025-10-28 10:14:49,269:INFO:Logical Core: 16
2025-10-28 10:14:49,269:INFO:Checking libraries
2025-10-28 10:14:49,269:INFO:System:
2025-10-28 10:14:49,269:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:14:49,269:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:14:49,269:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:14:49,269:INFO:PyCaret required dependencies:
2025-10-28 10:14:49,272:INFO:                 pip: 25.2
2025-10-28 10:14:49,272:INFO:          setuptools: 80.9.0
2025-10-28 10:14:49,273:INFO:             pycaret: 3.3.2
2025-10-28 10:14:49,273:INFO:             IPython: 9.6.0
2025-10-28 10:14:49,273:INFO:          ipywidgets: 8.1.7
2025-10-28 10:14:49,273:INFO:                tqdm: 4.67.1
2025-10-28 10:14:49,273:INFO:               numpy: 1.26.4
2025-10-28 10:14:49,273:INFO:              pandas: 2.1.4
2025-10-28 10:14:49,273:INFO:              jinja2: 3.1.6
2025-10-28 10:14:49,273:INFO:               scipy: 1.11.4
2025-10-28 10:14:49,273:INFO:              joblib: 1.3.2
2025-10-28 10:14:49,273:INFO:             sklearn: 1.4.2
2025-10-28 10:14:49,273:INFO:                pyod: 2.0.5
2025-10-28 10:14:49,273:INFO:            imblearn: 0.14.0
2025-10-28 10:14:49,273:INFO:   category_encoders: 2.7.0
2025-10-28 10:14:49,273:INFO:            lightgbm: 4.6.0
2025-10-28 10:14:49,273:INFO:               numba: 0.62.1
2025-10-28 10:14:49,273:INFO:            requests: 2.32.5
2025-10-28 10:14:49,273:INFO:          matplotlib: 3.10.7
2025-10-28 10:14:49,273:INFO:          scikitplot: 0.3.7
2025-10-28 10:14:49,274:INFO:         yellowbrick: 1.5
2025-10-28 10:14:49,274:INFO:              plotly: 6.3.1
2025-10-28 10:14:49,274:INFO:    plotly-resampler: Not installed
2025-10-28 10:14:49,274:INFO:             kaleido: 0.2.1
2025-10-28 10:14:49,274:INFO:           schemdraw: 0.15
2025-10-28 10:14:49,274:INFO:         statsmodels: 0.14.5
2025-10-28 10:14:49,274:INFO:              sktime: 0.26.0
2025-10-28 10:14:49,274:INFO:               tbats: 1.1.3
2025-10-28 10:14:49,274:INFO:            pmdarima: 2.0.4
2025-10-28 10:14:49,274:INFO:              psutil: 7.1.1
2025-10-28 10:14:49,274:INFO:          markupsafe: 3.0.3
2025-10-28 10:14:49,275:INFO:             pickle5: Not installed
2025-10-28 10:14:49,275:INFO:         cloudpickle: 3.1.1
2025-10-28 10:14:49,275:INFO:         deprecation: 2.1.0
2025-10-28 10:14:49,275:INFO:              xxhash: 3.6.0
2025-10-28 10:14:49,275:INFO:           wurlitzer: 3.1.1
2025-10-28 10:14:49,275:INFO:PyCaret optional dependencies:
2025-10-28 10:14:49,297:INFO:                shap: Not installed
2025-10-28 10:14:49,298:INFO:           interpret: Not installed
2025-10-28 10:14:49,298:INFO:                umap: 0.5.9.post2
2025-10-28 10:14:49,298:INFO:     ydata_profiling: Not installed
2025-10-28 10:14:49,298:INFO:  explainerdashboard: Not installed
2025-10-28 10:14:49,298:INFO:             autoviz: Not installed
2025-10-28 10:14:49,298:INFO:           fairlearn: Not installed
2025-10-28 10:14:49,298:INFO:          deepchecks: Not installed
2025-10-28 10:14:49,298:INFO:             xgboost: Not installed
2025-10-28 10:14:49,298:INFO:            catboost: Not installed
2025-10-28 10:14:49,298:INFO:              kmodes: Not installed
2025-10-28 10:14:49,298:INFO:             mlxtend: Not installed
2025-10-28 10:14:49,298:INFO:       statsforecast: Not installed
2025-10-28 10:14:49,298:INFO:        tune_sklearn: Not installed
2025-10-28 10:14:49,298:INFO:                 ray: Not installed
2025-10-28 10:14:49,298:INFO:            hyperopt: Not installed
2025-10-28 10:14:49,298:INFO:              optuna: Not installed
2025-10-28 10:14:49,298:INFO:               skopt: Not installed
2025-10-28 10:14:49,298:INFO:              mlflow: Not installed
2025-10-28 10:14:49,298:INFO:              gradio: Not installed
2025-10-28 10:14:49,298:INFO:             fastapi: Not installed
2025-10-28 10:14:49,298:INFO:             uvicorn: Not installed
2025-10-28 10:14:49,300:INFO:              m2cgen: Not installed
2025-10-28 10:14:49,300:INFO:           evidently: Not installed
2025-10-28 10:14:49,300:INFO:               fugue: Not installed
2025-10-28 10:14:49,300:INFO:           streamlit: 1.50.0
2025-10-28 10:14:49,300:INFO:             prophet: Not installed
2025-10-28 10:14:49,300:INFO:None
2025-10-28 10:14:49,300:INFO:Set up data.
2025-10-28 10:14:49,307:INFO:Set up folding strategy.
2025-10-28 10:14:49,307:INFO:Set up train/test split.
2025-10-28 10:14:49,320:INFO:Set up index.
2025-10-28 10:14:49,320:INFO:Assigning column types.
2025-10-28 10:14:49,325:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:14:49,403:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,410:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,484:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,638:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,718:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,719:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,774:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,777:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,777:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:14:49,856:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:49,903:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,903:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:49,978:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:14:50,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,015:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:14:50,109:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,110:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,217:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,218:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,221:INFO:Preparing preprocessing pipeline...
2025-10-28 10:14:50,222:INFO:Set up label encoding.
2025-10-28 10:14:50,222:INFO:Set up simple imputation.
2025-10-28 10:14:50,319:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:14:50,328:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:14:50,328:INFO:Creating final display dataframe.
2025-10-28 10:14:50,476:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               01c8
2025-10-28 10:14:50,574:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,666:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,666:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:14:50,668:INFO:setup() successfully completed in 1.47s...............
2025-10-28 10:15:01,000:INFO:PyCaret ClassificationExperiment
2025-10-28 10:15:01,001:INFO:Logging name: clf-default-name
2025-10-28 10:15:01,001:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:15:01,001:INFO:version 3.3.2
2025-10-28 10:15:01,001:INFO:Initializing setup()
2025-10-28 10:15:01,001:INFO:self.USI: f1e3
2025-10-28 10:15:01,001:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:15:01,001:INFO:Checking environment
2025-10-28 10:15:01,001:INFO:python_version: 3.11.14
2025-10-28 10:15:01,001:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:15:01,001:INFO:machine: AMD64
2025-10-28 10:15:01,001:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:15:01,001:INFO:Memory: svmem(total=16788250624, available=5319151616, percent=68.3, used=11469099008, free=5319151616)
2025-10-28 10:15:01,001:INFO:Physical Core: 12
2025-10-28 10:15:01,001:INFO:Logical Core: 16
2025-10-28 10:15:01,001:INFO:Checking libraries
2025-10-28 10:15:01,002:INFO:System:
2025-10-28 10:15:01,002:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:15:01,002:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:15:01,002:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:15:01,002:INFO:PyCaret required dependencies:
2025-10-28 10:15:01,002:INFO:                 pip: 25.2
2025-10-28 10:15:01,002:INFO:          setuptools: 80.9.0
2025-10-28 10:15:01,002:INFO:             pycaret: 3.3.2
2025-10-28 10:15:01,002:INFO:             IPython: 9.6.0
2025-10-28 10:15:01,002:INFO:          ipywidgets: 8.1.7
2025-10-28 10:15:01,002:INFO:                tqdm: 4.67.1
2025-10-28 10:15:01,002:INFO:               numpy: 1.26.4
2025-10-28 10:15:01,002:INFO:              pandas: 2.1.4
2025-10-28 10:15:01,002:INFO:              jinja2: 3.1.6
2025-10-28 10:15:01,002:INFO:               scipy: 1.11.4
2025-10-28 10:15:01,002:INFO:              joblib: 1.3.2
2025-10-28 10:15:01,002:INFO:             sklearn: 1.4.2
2025-10-28 10:15:01,002:INFO:                pyod: 2.0.5
2025-10-28 10:15:01,002:INFO:            imblearn: 0.14.0
2025-10-28 10:15:01,002:INFO:   category_encoders: 2.7.0
2025-10-28 10:15:01,002:INFO:            lightgbm: 4.6.0
2025-10-28 10:15:01,002:INFO:               numba: 0.62.1
2025-10-28 10:15:01,002:INFO:            requests: 2.32.5
2025-10-28 10:15:01,002:INFO:          matplotlib: 3.10.7
2025-10-28 10:15:01,002:INFO:          scikitplot: 0.3.7
2025-10-28 10:15:01,002:INFO:         yellowbrick: 1.5
2025-10-28 10:15:01,002:INFO:              plotly: 6.3.1
2025-10-28 10:15:01,002:INFO:    plotly-resampler: Not installed
2025-10-28 10:15:01,002:INFO:             kaleido: 0.2.1
2025-10-28 10:15:01,003:INFO:           schemdraw: 0.15
2025-10-28 10:15:01,003:INFO:         statsmodels: 0.14.5
2025-10-28 10:15:01,003:INFO:              sktime: 0.26.0
2025-10-28 10:15:01,003:INFO:               tbats: 1.1.3
2025-10-28 10:15:01,003:INFO:            pmdarima: 2.0.4
2025-10-28 10:15:01,003:INFO:              psutil: 7.1.1
2025-10-28 10:15:01,003:INFO:          markupsafe: 3.0.3
2025-10-28 10:15:01,003:INFO:             pickle5: Not installed
2025-10-28 10:15:01,003:INFO:         cloudpickle: 3.1.1
2025-10-28 10:15:01,003:INFO:         deprecation: 2.1.0
2025-10-28 10:15:01,003:INFO:              xxhash: 3.6.0
2025-10-28 10:15:01,003:INFO:           wurlitzer: 3.1.1
2025-10-28 10:15:01,003:INFO:PyCaret optional dependencies:
2025-10-28 10:15:01,003:INFO:                shap: Not installed
2025-10-28 10:15:01,003:INFO:           interpret: Not installed
2025-10-28 10:15:01,003:INFO:                umap: 0.5.9.post2
2025-10-28 10:15:01,003:INFO:     ydata_profiling: Not installed
2025-10-28 10:15:01,003:INFO:  explainerdashboard: Not installed
2025-10-28 10:15:01,003:INFO:             autoviz: Not installed
2025-10-28 10:15:01,003:INFO:           fairlearn: Not installed
2025-10-28 10:15:01,003:INFO:          deepchecks: Not installed
2025-10-28 10:15:01,003:INFO:             xgboost: Not installed
2025-10-28 10:15:01,003:INFO:            catboost: Not installed
2025-10-28 10:15:01,003:INFO:              kmodes: Not installed
2025-10-28 10:15:01,003:INFO:             mlxtend: Not installed
2025-10-28 10:15:01,003:INFO:       statsforecast: Not installed
2025-10-28 10:15:01,003:INFO:        tune_sklearn: Not installed
2025-10-28 10:15:01,003:INFO:                 ray: Not installed
2025-10-28 10:15:01,003:INFO:            hyperopt: Not installed
2025-10-28 10:15:01,004:INFO:              optuna: Not installed
2025-10-28 10:15:01,004:INFO:               skopt: Not installed
2025-10-28 10:15:01,004:INFO:              mlflow: Not installed
2025-10-28 10:15:01,004:INFO:              gradio: Not installed
2025-10-28 10:15:01,004:INFO:             fastapi: Not installed
2025-10-28 10:15:01,004:INFO:             uvicorn: Not installed
2025-10-28 10:15:01,004:INFO:              m2cgen: Not installed
2025-10-28 10:15:01,004:INFO:           evidently: Not installed
2025-10-28 10:15:01,004:INFO:               fugue: Not installed
2025-10-28 10:15:01,004:INFO:           streamlit: 1.50.0
2025-10-28 10:15:01,004:INFO:             prophet: Not installed
2025-10-28 10:15:01,004:INFO:None
2025-10-28 10:15:01,004:INFO:Set up data.
2025-10-28 10:15:01,007:INFO:Set up folding strategy.
2025-10-28 10:15:01,007:INFO:Set up train/test split.
2025-10-28 10:15:01,011:INFO:Set up index.
2025-10-28 10:15:01,011:INFO:Assigning column types.
2025-10-28 10:15:01,014:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:15:01,062:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,065:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,095:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,095:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,155:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,156:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,189:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,189:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,189:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:15:01,238:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,269:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,316:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:15:01,345:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,346:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,347:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:15:01,423:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,424:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,498:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,499:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,500:INFO:Preparing preprocessing pipeline...
2025-10-28 10:15:01,501:INFO:Set up label encoding.
2025-10-28 10:15:01,501:INFO:Set up simple imputation.
2025-10-28 10:15:01,527:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:15:01,530:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:15:01,530:INFO:Creating final display dataframe.
2025-10-28 10:15:01,616:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               f1e3
2025-10-28 10:15:01,696:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,697:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,773:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,773:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:15:01,775:INFO:setup() successfully completed in 0.78s...............
2025-10-28 10:15:25,030:INFO:PyCaret ClassificationExperiment
2025-10-28 10:15:25,030:INFO:Logging name: clf-default-name
2025-10-28 10:15:25,030:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:15:25,030:INFO:version 3.3.2
2025-10-28 10:15:25,030:INFO:Initializing setup()
2025-10-28 10:15:25,030:INFO:self.USI: 1386
2025-10-28 10:15:25,030:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:15:25,034:INFO:Checking environment
2025-10-28 10:15:25,034:INFO:python_version: 3.11.14
2025-10-28 10:15:25,034:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:15:25,034:INFO:machine: AMD64
2025-10-28 10:15:25,034:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:15:25,034:INFO:Memory: svmem(total=16788250624, available=5386625024, percent=67.9, used=11401625600, free=5386625024)
2025-10-28 10:15:25,034:INFO:Physical Core: 12
2025-10-28 10:15:25,034:INFO:Logical Core: 16
2025-10-28 10:15:25,034:INFO:Checking libraries
2025-10-28 10:15:25,034:INFO:System:
2025-10-28 10:15:25,034:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:15:25,034:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:15:25,034:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:15:25,034:INFO:PyCaret required dependencies:
2025-10-28 10:15:25,036:INFO:                 pip: 25.2
2025-10-28 10:15:25,036:INFO:          setuptools: 80.9.0
2025-10-28 10:15:25,036:INFO:             pycaret: 3.3.2
2025-10-28 10:15:25,036:INFO:             IPython: 9.6.0
2025-10-28 10:15:25,037:INFO:          ipywidgets: 8.1.7
2025-10-28 10:15:25,037:INFO:                tqdm: 4.67.1
2025-10-28 10:15:25,037:INFO:               numpy: 1.26.4
2025-10-28 10:15:25,037:INFO:              pandas: 2.1.4
2025-10-28 10:15:25,037:INFO:              jinja2: 3.1.6
2025-10-28 10:15:25,037:INFO:               scipy: 1.11.4
2025-10-28 10:15:25,037:INFO:              joblib: 1.3.2
2025-10-28 10:15:25,037:INFO:             sklearn: 1.4.2
2025-10-28 10:15:25,038:INFO:                pyod: 2.0.5
2025-10-28 10:15:25,038:INFO:            imblearn: 0.14.0
2025-10-28 10:15:25,038:INFO:   category_encoders: 2.7.0
2025-10-28 10:15:25,038:INFO:            lightgbm: 4.6.0
2025-10-28 10:15:25,038:INFO:               numba: 0.62.1
2025-10-28 10:15:25,038:INFO:            requests: 2.32.5
2025-10-28 10:15:25,038:INFO:          matplotlib: 3.10.7
2025-10-28 10:15:25,038:INFO:          scikitplot: 0.3.7
2025-10-28 10:15:25,038:INFO:         yellowbrick: 1.5
2025-10-28 10:15:25,038:INFO:              plotly: 6.3.1
2025-10-28 10:15:25,038:INFO:    plotly-resampler: Not installed
2025-10-28 10:15:25,038:INFO:             kaleido: 0.2.1
2025-10-28 10:15:25,038:INFO:           schemdraw: 0.15
2025-10-28 10:15:25,038:INFO:         statsmodels: 0.14.5
2025-10-28 10:15:25,038:INFO:              sktime: 0.26.0
2025-10-28 10:15:25,038:INFO:               tbats: 1.1.3
2025-10-28 10:15:25,039:INFO:            pmdarima: 2.0.4
2025-10-28 10:15:25,039:INFO:              psutil: 7.1.1
2025-10-28 10:15:25,040:INFO:          markupsafe: 3.0.3
2025-10-28 10:15:25,041:INFO:             pickle5: Not installed
2025-10-28 10:15:25,042:INFO:         cloudpickle: 3.1.1
2025-10-28 10:15:25,042:INFO:         deprecation: 2.1.0
2025-10-28 10:15:25,043:INFO:              xxhash: 3.6.0
2025-10-28 10:15:25,043:INFO:           wurlitzer: 3.1.1
2025-10-28 10:15:25,043:INFO:PyCaret optional dependencies:
2025-10-28 10:15:25,043:INFO:                shap: Not installed
2025-10-28 10:15:25,043:INFO:           interpret: Not installed
2025-10-28 10:15:25,043:INFO:                umap: 0.5.9.post2
2025-10-28 10:15:25,043:INFO:     ydata_profiling: Not installed
2025-10-28 10:15:25,043:INFO:  explainerdashboard: Not installed
2025-10-28 10:15:25,043:INFO:             autoviz: Not installed
2025-10-28 10:15:25,044:INFO:           fairlearn: Not installed
2025-10-28 10:15:25,044:INFO:          deepchecks: Not installed
2025-10-28 10:15:25,044:INFO:             xgboost: Not installed
2025-10-28 10:15:25,044:INFO:            catboost: Not installed
2025-10-28 10:15:25,044:INFO:              kmodes: Not installed
2025-10-28 10:15:25,044:INFO:             mlxtend: Not installed
2025-10-28 10:15:25,044:INFO:       statsforecast: Not installed
2025-10-28 10:15:25,045:INFO:        tune_sklearn: Not installed
2025-10-28 10:15:25,045:INFO:                 ray: Not installed
2025-10-28 10:15:25,045:INFO:            hyperopt: Not installed
2025-10-28 10:15:25,045:INFO:              optuna: Not installed
2025-10-28 10:15:25,045:INFO:               skopt: Not installed
2025-10-28 10:15:25,046:INFO:              mlflow: Not installed
2025-10-28 10:15:25,046:INFO:              gradio: Not installed
2025-10-28 10:15:25,046:INFO:             fastapi: Not installed
2025-10-28 10:15:25,047:INFO:             uvicorn: Not installed
2025-10-28 10:15:25,047:INFO:              m2cgen: Not installed
2025-10-28 10:15:25,047:INFO:           evidently: Not installed
2025-10-28 10:15:25,048:INFO:               fugue: Not installed
2025-10-28 10:15:25,048:INFO:           streamlit: 1.50.0
2025-10-28 10:15:25,048:INFO:             prophet: Not installed
2025-10-28 10:15:25,048:INFO:None
2025-10-28 10:15:25,048:INFO:Set up data.
2025-10-28 10:15:25,059:INFO:Set up folding strategy.
2025-10-28 10:15:25,060:INFO:Set up train/test split.
2025-10-28 10:25:05,085:INFO:PyCaret RegressionExperiment
2025-10-28 10:25:05,085:INFO:Logging name: reg-default-name
2025-10-28 10:25:05,085:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:25:05,085:INFO:version 3.3.2
2025-10-28 10:25:05,085:INFO:Initializing setup()
2025-10-28 10:25:05,089:INFO:self.USI: d46f
2025-10-28 10:25:05,089:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:25:05,089:INFO:Checking environment
2025-10-28 10:25:05,089:INFO:python_version: 3.11.14
2025-10-28 10:25:05,089:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:05,089:INFO:machine: AMD64
2025-10-28 10:25:05,089:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:05,090:INFO:Memory: svmem(total=16788250624, available=4029124608, percent=76.0, used=12759126016, free=4029124608)
2025-10-28 10:25:05,090:INFO:Physical Core: 12
2025-10-28 10:25:05,090:INFO:Logical Core: 16
2025-10-28 10:25:05,090:INFO:Checking libraries
2025-10-28 10:25:05,090:INFO:System:
2025-10-28 10:25:05,090:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:05,090:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:05,091:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:05,091:INFO:PyCaret required dependencies:
2025-10-28 10:25:05,091:INFO:                 pip: 25.2
2025-10-28 10:25:05,091:INFO:          setuptools: 80.9.0
2025-10-28 10:25:05,093:INFO:             pycaret: 3.3.2
2025-10-28 10:25:05,093:INFO:             IPython: 9.6.0
2025-10-28 10:25:05,093:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:05,093:INFO:                tqdm: 4.67.1
2025-10-28 10:25:05,093:INFO:               numpy: 1.26.4
2025-10-28 10:25:05,094:INFO:              pandas: 2.1.4
2025-10-28 10:25:05,094:INFO:              jinja2: 3.1.6
2025-10-28 10:25:05,094:INFO:               scipy: 1.11.4
2025-10-28 10:25:05,094:INFO:              joblib: 1.3.2
2025-10-28 10:25:05,094:INFO:             sklearn: 1.4.2
2025-10-28 10:25:05,094:INFO:                pyod: 2.0.5
2025-10-28 10:25:05,094:INFO:            imblearn: 0.14.0
2025-10-28 10:25:05,094:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:05,094:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:05,094:INFO:               numba: 0.62.1
2025-10-28 10:25:05,094:INFO:            requests: 2.32.5
2025-10-28 10:25:05,094:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:05,094:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:05,094:INFO:         yellowbrick: 1.5
2025-10-28 10:25:05,094:INFO:              plotly: 6.3.1
2025-10-28 10:25:05,096:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:05,096:INFO:             kaleido: 0.2.1
2025-10-28 10:25:05,096:INFO:           schemdraw: 0.15
2025-10-28 10:25:05,096:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:05,096:INFO:              sktime: 0.26.0
2025-10-28 10:25:05,096:INFO:               tbats: 1.1.3
2025-10-28 10:25:05,096:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:05,096:INFO:              psutil: 7.1.1
2025-10-28 10:25:05,096:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:05,096:INFO:             pickle5: Not installed
2025-10-28 10:25:05,096:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:05,096:INFO:         deprecation: 2.1.0
2025-10-28 10:25:05,096:INFO:              xxhash: 3.6.0
2025-10-28 10:25:05,096:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:05,096:INFO:PyCaret optional dependencies:
2025-10-28 10:25:05,096:INFO:                shap: Not installed
2025-10-28 10:25:05,096:INFO:           interpret: Not installed
2025-10-28 10:25:05,096:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:05,096:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:05,096:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:05,096:INFO:             autoviz: Not installed
2025-10-28 10:25:05,096:INFO:           fairlearn: Not installed
2025-10-28 10:25:05,096:INFO:          deepchecks: Not installed
2025-10-28 10:25:05,096:INFO:             xgboost: Not installed
2025-10-28 10:25:05,096:INFO:            catboost: Not installed
2025-10-28 10:25:05,096:INFO:              kmodes: Not installed
2025-10-28 10:25:05,096:INFO:             mlxtend: Not installed
2025-10-28 10:25:05,096:INFO:       statsforecast: Not installed
2025-10-28 10:25:05,100:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:05,100:INFO:                 ray: Not installed
2025-10-28 10:25:05,100:INFO:            hyperopt: Not installed
2025-10-28 10:25:05,100:INFO:              optuna: Not installed
2025-10-28 10:25:05,100:INFO:               skopt: Not installed
2025-10-28 10:25:05,100:INFO:              mlflow: Not installed
2025-10-28 10:25:05,101:INFO:              gradio: Not installed
2025-10-28 10:25:05,101:INFO:             fastapi: Not installed
2025-10-28 10:25:05,101:INFO:             uvicorn: Not installed
2025-10-28 10:25:05,101:INFO:              m2cgen: Not installed
2025-10-28 10:25:05,102:INFO:           evidently: Not installed
2025-10-28 10:25:05,102:INFO:               fugue: Not installed
2025-10-28 10:25:05,102:INFO:           streamlit: 1.50.0
2025-10-28 10:25:05,103:INFO:             prophet: Not installed
2025-10-28 10:25:05,103:INFO:None
2025-10-28 10:25:05,103:INFO:Set up data.
2025-10-28 10:25:05,119:INFO:Set up folding strategy.
2025-10-28 10:25:05,119:INFO:Set up train/test split.
2025-10-28 10:25:05,129:INFO:Set up index.
2025-10-28 10:25:05,130:INFO:Assigning column types.
2025-10-28 10:25:05,137:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:05,137:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,144:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,153:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,278:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,353:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,354:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,355:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,362:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,370:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,470:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,547:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,549:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,550:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:25:05,559:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,568:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,672:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,747:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,749:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,749:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,758:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,766:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,865:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,944:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:05,944:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,945:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:05,946:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:25:05,961:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,057:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,138:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,139:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,140:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,157:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,262:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,339:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,340:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,340:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,341:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:25:06,459:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,532:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,534:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,534:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,650:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,724:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,725:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,725:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,728:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:06,841:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:06,918:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:06,918:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,041:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:07,126:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,126:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,127:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:25:07,328:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,328:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,519:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,519:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:07,522:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:07,522:INFO:Set up simple imputation.
2025-10-28 10:25:07,526:INFO:Set up encoding of categorical features.
2025-10-28 10:25:07,527:INFO:Set up column name cleaning.
2025-10-28 10:25:07,650:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:07,663:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:25:07,663:INFO:Creating final display dataframe.
2025-10-28 10:25:07,988:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              d46f
2025-10-28 10:25:08,176:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,177:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,369:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,370:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:08,371:INFO:setup() successfully completed in 3.29s...............
2025-10-28 10:25:20,165:INFO:PyCaret RegressionExperiment
2025-10-28 10:25:20,165:INFO:Logging name: reg-default-name
2025-10-28 10:25:20,165:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:25:20,165:INFO:version 3.3.2
2025-10-28 10:25:20,165:INFO:Initializing setup()
2025-10-28 10:25:20,165:INFO:self.USI: e94c
2025-10-28 10:25:20,165:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:25:20,165:INFO:Checking environment
2025-10-28 10:25:20,165:INFO:python_version: 3.11.14
2025-10-28 10:25:20,165:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:20,165:INFO:machine: AMD64
2025-10-28 10:25:20,165:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:20,165:INFO:Memory: svmem(total=16788250624, available=4416757760, percent=73.7, used=12371492864, free=4416757760)
2025-10-28 10:25:20,165:INFO:Physical Core: 12
2025-10-28 10:25:20,165:INFO:Logical Core: 16
2025-10-28 10:25:20,165:INFO:Checking libraries
2025-10-28 10:25:20,165:INFO:System:
2025-10-28 10:25:20,165:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:20,165:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:20,165:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:20,165:INFO:PyCaret required dependencies:
2025-10-28 10:25:20,165:INFO:                 pip: 25.2
2025-10-28 10:25:20,165:INFO:          setuptools: 80.9.0
2025-10-28 10:25:20,165:INFO:             pycaret: 3.3.2
2025-10-28 10:25:20,165:INFO:             IPython: 9.6.0
2025-10-28 10:25:20,165:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:20,165:INFO:                tqdm: 4.67.1
2025-10-28 10:25:20,165:INFO:               numpy: 1.26.4
2025-10-28 10:25:20,165:INFO:              pandas: 2.1.4
2025-10-28 10:25:20,165:INFO:              jinja2: 3.1.6
2025-10-28 10:25:20,165:INFO:               scipy: 1.11.4
2025-10-28 10:25:20,165:INFO:              joblib: 1.3.2
2025-10-28 10:25:20,165:INFO:             sklearn: 1.4.2
2025-10-28 10:25:20,165:INFO:                pyod: 2.0.5
2025-10-28 10:25:20,165:INFO:            imblearn: 0.14.0
2025-10-28 10:25:20,165:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:20,165:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:20,171:INFO:               numba: 0.62.1
2025-10-28 10:25:20,171:INFO:            requests: 2.32.5
2025-10-28 10:25:20,171:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:20,171:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:20,171:INFO:         yellowbrick: 1.5
2025-10-28 10:25:20,171:INFO:              plotly: 6.3.1
2025-10-28 10:25:20,171:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:20,171:INFO:             kaleido: 0.2.1
2025-10-28 10:25:20,171:INFO:           schemdraw: 0.15
2025-10-28 10:25:20,171:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:20,171:INFO:              sktime: 0.26.0
2025-10-28 10:25:20,171:INFO:               tbats: 1.1.3
2025-10-28 10:25:20,171:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:20,171:INFO:              psutil: 7.1.1
2025-10-28 10:25:20,171:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:20,171:INFO:             pickle5: Not installed
2025-10-28 10:25:20,171:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:20,171:INFO:         deprecation: 2.1.0
2025-10-28 10:25:20,171:INFO:              xxhash: 3.6.0
2025-10-28 10:25:20,171:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:20,171:INFO:PyCaret optional dependencies:
2025-10-28 10:25:20,176:INFO:                shap: Not installed
2025-10-28 10:25:20,176:INFO:           interpret: Not installed
2025-10-28 10:25:20,176:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:20,176:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:20,176:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:20,176:INFO:             autoviz: Not installed
2025-10-28 10:25:20,176:INFO:           fairlearn: Not installed
2025-10-28 10:25:20,176:INFO:          deepchecks: Not installed
2025-10-28 10:25:20,176:INFO:             xgboost: Not installed
2025-10-28 10:25:20,176:INFO:            catboost: Not installed
2025-10-28 10:25:20,176:INFO:              kmodes: Not installed
2025-10-28 10:25:20,176:INFO:             mlxtend: Not installed
2025-10-28 10:25:20,176:INFO:       statsforecast: Not installed
2025-10-28 10:25:20,176:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:20,176:INFO:                 ray: Not installed
2025-10-28 10:25:20,176:INFO:            hyperopt: Not installed
2025-10-28 10:25:20,176:INFO:              optuna: Not installed
2025-10-28 10:25:20,176:INFO:               skopt: Not installed
2025-10-28 10:25:20,176:INFO:              mlflow: Not installed
2025-10-28 10:25:20,176:INFO:              gradio: Not installed
2025-10-28 10:25:20,179:INFO:             fastapi: Not installed
2025-10-28 10:25:20,179:INFO:             uvicorn: Not installed
2025-10-28 10:25:20,179:INFO:              m2cgen: Not installed
2025-10-28 10:25:20,179:INFO:           evidently: Not installed
2025-10-28 10:25:20,179:INFO:               fugue: Not installed
2025-10-28 10:25:20,179:INFO:           streamlit: 1.50.0
2025-10-28 10:25:20,179:INFO:             prophet: Not installed
2025-10-28 10:25:20,179:INFO:None
2025-10-28 10:25:20,179:INFO:Set up data.
2025-10-28 10:25:20,188:INFO:Set up folding strategy.
2025-10-28 10:25:20,188:INFO:Set up train/test split.
2025-10-28 10:25:20,198:INFO:Set up index.
2025-10-28 10:25:20,198:INFO:Assigning column types.
2025-10-28 10:25:20,204:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:20,204:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,212:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,220:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,320:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,397:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,398:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,398:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,399:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,406:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,414:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,511:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,588:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,590:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:25:20,598:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,607:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,737:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,847:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,849:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,849:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:20,857:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,865:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:20,962:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,047:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,048:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,048:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:25:21,064:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,166:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,243:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,243:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,244:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,260:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,437:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,439:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,439:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,440:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:25:21,554:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,632:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,633:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,634:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,745:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,821:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:21,822:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,822:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:21,823:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:21,937:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:22,014:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:22,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,203:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,203:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:25:22,404:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,615:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,615:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:22,617:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:22,617:INFO:Set up simple imputation.
2025-10-28 10:25:22,621:INFO:Set up encoding of categorical features.
2025-10-28 10:25:22,622:INFO:Set up column name cleaning.
2025-10-28 10:25:22,731:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:22,744:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:25:22,744:INFO:Creating final display dataframe.
2025-10-28 10:25:23,096:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              e94c
2025-10-28 10:25:23,304:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,304:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,505:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,505:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:23,506:INFO:setup() successfully completed in 3.35s...............
2025-10-28 10:25:35,381:INFO:PyCaret RegressionExperiment
2025-10-28 10:25:35,381:INFO:Logging name: reg-default-name
2025-10-28 10:25:35,381:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:25:35,381:INFO:version 3.3.2
2025-10-28 10:25:35,381:INFO:Initializing setup()
2025-10-28 10:25:35,381:INFO:self.USI: 7bd9
2025-10-28 10:25:35,381:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:25:35,381:INFO:Checking environment
2025-10-28 10:25:35,381:INFO:python_version: 3.11.14
2025-10-28 10:25:35,381:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:35,383:INFO:machine: AMD64
2025-10-28 10:25:35,383:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:35,383:INFO:Memory: svmem(total=16788250624, available=4392570880, percent=73.8, used=12395679744, free=4392570880)
2025-10-28 10:25:35,383:INFO:Physical Core: 12
2025-10-28 10:25:35,383:INFO:Logical Core: 16
2025-10-28 10:25:35,383:INFO:Checking libraries
2025-10-28 10:25:35,388:INFO:System:
2025-10-28 10:25:35,389:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:35,389:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:35,389:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:35,389:INFO:PyCaret required dependencies:
2025-10-28 10:25:35,389:INFO:                 pip: 25.2
2025-10-28 10:25:35,389:INFO:          setuptools: 80.9.0
2025-10-28 10:25:35,389:INFO:             pycaret: 3.3.2
2025-10-28 10:25:35,389:INFO:             IPython: 9.6.0
2025-10-28 10:25:35,389:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:35,389:INFO:                tqdm: 4.67.1
2025-10-28 10:25:35,389:INFO:               numpy: 1.26.4
2025-10-28 10:25:35,390:INFO:              pandas: 2.1.4
2025-10-28 10:25:35,390:INFO:              jinja2: 3.1.6
2025-10-28 10:25:35,390:INFO:               scipy: 1.11.4
2025-10-28 10:25:35,390:INFO:              joblib: 1.3.2
2025-10-28 10:25:35,390:INFO:             sklearn: 1.4.2
2025-10-28 10:25:35,390:INFO:                pyod: 2.0.5
2025-10-28 10:25:35,390:INFO:            imblearn: 0.14.0
2025-10-28 10:25:35,390:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:35,390:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:35,390:INFO:               numba: 0.62.1
2025-10-28 10:25:35,390:INFO:            requests: 2.32.5
2025-10-28 10:25:35,390:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:35,390:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:35,390:INFO:         yellowbrick: 1.5
2025-10-28 10:25:35,390:INFO:              plotly: 6.3.1
2025-10-28 10:25:35,392:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:35,392:INFO:             kaleido: 0.2.1
2025-10-28 10:25:35,392:INFO:           schemdraw: 0.15
2025-10-28 10:25:35,392:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:35,392:INFO:              sktime: 0.26.0
2025-10-28 10:25:35,392:INFO:               tbats: 1.1.3
2025-10-28 10:25:35,392:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:35,393:INFO:              psutil: 7.1.1
2025-10-28 10:25:35,394:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:35,395:INFO:             pickle5: Not installed
2025-10-28 10:25:35,395:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:35,395:INFO:         deprecation: 2.1.0
2025-10-28 10:25:35,395:INFO:              xxhash: 3.6.0
2025-10-28 10:25:35,395:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:35,395:INFO:PyCaret optional dependencies:
2025-10-28 10:25:35,396:INFO:                shap: Not installed
2025-10-28 10:25:35,396:INFO:           interpret: Not installed
2025-10-28 10:25:35,396:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:35,396:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:35,396:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:35,396:INFO:             autoviz: Not installed
2025-10-28 10:25:35,396:INFO:           fairlearn: Not installed
2025-10-28 10:25:35,396:INFO:          deepchecks: Not installed
2025-10-28 10:25:35,396:INFO:             xgboost: Not installed
2025-10-28 10:25:35,396:INFO:            catboost: Not installed
2025-10-28 10:25:35,396:INFO:              kmodes: Not installed
2025-10-28 10:25:35,397:INFO:             mlxtend: Not installed
2025-10-28 10:25:35,397:INFO:       statsforecast: Not installed
2025-10-28 10:25:35,397:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:35,397:INFO:                 ray: Not installed
2025-10-28 10:25:35,398:INFO:            hyperopt: Not installed
2025-10-28 10:25:35,398:INFO:              optuna: Not installed
2025-10-28 10:25:35,398:INFO:               skopt: Not installed
2025-10-28 10:25:35,398:INFO:              mlflow: Not installed
2025-10-28 10:25:35,398:INFO:              gradio: Not installed
2025-10-28 10:25:35,398:INFO:             fastapi: Not installed
2025-10-28 10:25:35,398:INFO:             uvicorn: Not installed
2025-10-28 10:25:35,398:INFO:              m2cgen: Not installed
2025-10-28 10:25:35,398:INFO:           evidently: Not installed
2025-10-28 10:25:35,398:INFO:               fugue: Not installed
2025-10-28 10:25:35,398:INFO:           streamlit: 1.50.0
2025-10-28 10:25:35,398:INFO:             prophet: Not installed
2025-10-28 10:25:35,398:INFO:None
2025-10-28 10:25:35,399:INFO:Set up data.
2025-10-28 10:25:35,407:INFO:Set up folding strategy.
2025-10-28 10:25:35,407:INFO:Set up train/test split.
2025-10-28 10:25:35,413:INFO:Set up index.
2025-10-28 10:25:35,414:INFO:Assigning column types.
2025-10-28 10:25:35,420:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:35,420:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,428:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,435:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,534:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,610:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,611:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,612:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,612:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,619:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,627:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,727:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,804:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,804:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:35,805:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:25:35,814:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,821:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:35,924:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,006:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,015:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,023:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,127:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,205:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,206:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,206:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,207:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:25:36,223:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,326:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,402:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,403:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,404:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,420:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,526:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,605:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,607:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,607:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,608:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:25:36,730:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,809:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:36,810:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:36,927:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,001:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,002:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,002:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,003:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:37,118:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,197:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,197:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,309:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:25:37,387:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,387:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,388:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:25:37,587:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,587:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,782:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,783:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:37,785:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:37,785:INFO:Set up simple imputation.
2025-10-28 10:25:37,789:INFO:Set up encoding of categorical features.
2025-10-28 10:25:37,866:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:37,880:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['sepal_width', 'petal_length',
                                             'petal_width'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['species'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('onehot_encoding',
                 TransformerWrapper(include=['species'],
                                    transformer=OneHotEncoder(cols=['species'],
                                                              handle_missing='return_nan',
                                                              use_cat_names=True)))])
2025-10-28 10:25:37,881:INFO:Creating final display dataframe.
2025-10-28 10:25:38,156:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target      sepal_length
2                   Target type        Regression
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 7)
5   Transformed train set shape          (105, 7)
6    Transformed test set shape           (45, 7)
7              Numeric features                 3
8          Categorical features                 1
9                    Preprocess              True
10              Imputation type            simple
11           Numeric imputation              mean
12       Categorical imputation              mode
13     Maximum one-hot encoding                25
14              Encoding method              None
15               Fold Generator             KFold
16                  Fold Number                10
17                     CPU Jobs                -1
18                      Use GPU             False
19               Log Experiment             False
20              Experiment Name  reg-default-name
21                          USI              7bd9
2025-10-28 10:25:38,354:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,355:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,547:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,548:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:38,549:INFO:setup() successfully completed in 3.18s...............
2025-10-28 10:25:41,511:INFO:PyCaret ClassificationExperiment
2025-10-28 10:25:41,511:INFO:Logging name: clf-default-name
2025-10-28 10:25:41,511:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:25:41,511:INFO:version 3.3.2
2025-10-28 10:25:41,515:INFO:Initializing setup()
2025-10-28 10:25:41,515:INFO:self.USI: 6a64
2025-10-28 10:25:41,515:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:25:41,515:INFO:Checking environment
2025-10-28 10:25:41,517:INFO:python_version: 3.11.14
2025-10-28 10:25:41,517:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:25:41,517:INFO:machine: AMD64
2025-10-28 10:25:41,517:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:25:41,517:INFO:Memory: svmem(total=16788250624, available=4360937472, percent=74.0, used=12427313152, free=4360937472)
2025-10-28 10:25:41,519:INFO:Physical Core: 12
2025-10-28 10:25:41,519:INFO:Logical Core: 16
2025-10-28 10:25:41,519:INFO:Checking libraries
2025-10-28 10:25:41,519:INFO:System:
2025-10-28 10:25:41,519:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:25:41,519:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:25:41,519:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:25:41,519:INFO:PyCaret required dependencies:
2025-10-28 10:25:41,520:INFO:                 pip: 25.2
2025-10-28 10:25:41,520:INFO:          setuptools: 80.9.0
2025-10-28 10:25:41,520:INFO:             pycaret: 3.3.2
2025-10-28 10:25:41,520:INFO:             IPython: 9.6.0
2025-10-28 10:25:41,520:INFO:          ipywidgets: 8.1.7
2025-10-28 10:25:41,520:INFO:                tqdm: 4.67.1
2025-10-28 10:25:41,520:INFO:               numpy: 1.26.4
2025-10-28 10:25:41,520:INFO:              pandas: 2.1.4
2025-10-28 10:25:41,520:INFO:              jinja2: 3.1.6
2025-10-28 10:25:41,520:INFO:               scipy: 1.11.4
2025-10-28 10:25:41,520:INFO:              joblib: 1.3.2
2025-10-28 10:25:41,520:INFO:             sklearn: 1.4.2
2025-10-28 10:25:41,521:INFO:                pyod: 2.0.5
2025-10-28 10:25:41,521:INFO:            imblearn: 0.14.0
2025-10-28 10:25:41,521:INFO:   category_encoders: 2.7.0
2025-10-28 10:25:41,521:INFO:            lightgbm: 4.6.0
2025-10-28 10:25:41,521:INFO:               numba: 0.62.1
2025-10-28 10:25:41,521:INFO:            requests: 2.32.5
2025-10-28 10:25:41,521:INFO:          matplotlib: 3.10.7
2025-10-28 10:25:41,521:INFO:          scikitplot: 0.3.7
2025-10-28 10:25:41,521:INFO:         yellowbrick: 1.5
2025-10-28 10:25:41,521:INFO:              plotly: 6.3.1
2025-10-28 10:25:41,521:INFO:    plotly-resampler: Not installed
2025-10-28 10:25:41,521:INFO:             kaleido: 0.2.1
2025-10-28 10:25:41,521:INFO:           schemdraw: 0.15
2025-10-28 10:25:41,521:INFO:         statsmodels: 0.14.5
2025-10-28 10:25:41,521:INFO:              sktime: 0.26.0
2025-10-28 10:25:41,521:INFO:               tbats: 1.1.3
2025-10-28 10:25:41,522:INFO:            pmdarima: 2.0.4
2025-10-28 10:25:41,522:INFO:              psutil: 7.1.1
2025-10-28 10:25:41,522:INFO:          markupsafe: 3.0.3
2025-10-28 10:25:41,522:INFO:             pickle5: Not installed
2025-10-28 10:25:41,522:INFO:         cloudpickle: 3.1.1
2025-10-28 10:25:41,522:INFO:         deprecation: 2.1.0
2025-10-28 10:25:41,522:INFO:              xxhash: 3.6.0
2025-10-28 10:25:41,522:INFO:           wurlitzer: 3.1.1
2025-10-28 10:25:41,522:INFO:PyCaret optional dependencies:
2025-10-28 10:25:41,522:INFO:                shap: Not installed
2025-10-28 10:25:41,522:INFO:           interpret: Not installed
2025-10-28 10:25:41,522:INFO:                umap: 0.5.9.post2
2025-10-28 10:25:41,522:INFO:     ydata_profiling: Not installed
2025-10-28 10:25:41,522:INFO:  explainerdashboard: Not installed
2025-10-28 10:25:41,522:INFO:             autoviz: Not installed
2025-10-28 10:25:41,522:INFO:           fairlearn: Not installed
2025-10-28 10:25:41,522:INFO:          deepchecks: Not installed
2025-10-28 10:25:41,523:INFO:             xgboost: Not installed
2025-10-28 10:25:41,523:INFO:            catboost: Not installed
2025-10-28 10:25:41,523:INFO:              kmodes: Not installed
2025-10-28 10:25:41,523:INFO:             mlxtend: Not installed
2025-10-28 10:25:41,524:INFO:       statsforecast: Not installed
2025-10-28 10:25:41,524:INFO:        tune_sklearn: Not installed
2025-10-28 10:25:41,524:INFO:                 ray: Not installed
2025-10-28 10:25:41,524:INFO:            hyperopt: Not installed
2025-10-28 10:25:41,525:INFO:              optuna: Not installed
2025-10-28 10:25:41,525:INFO:               skopt: Not installed
2025-10-28 10:25:41,525:INFO:              mlflow: Not installed
2025-10-28 10:25:41,525:INFO:              gradio: Not installed
2025-10-28 10:25:41,525:INFO:             fastapi: Not installed
2025-10-28 10:25:41,526:INFO:             uvicorn: Not installed
2025-10-28 10:25:41,526:INFO:              m2cgen: Not installed
2025-10-28 10:25:41,526:INFO:           evidently: Not installed
2025-10-28 10:25:41,526:INFO:               fugue: Not installed
2025-10-28 10:25:41,526:INFO:           streamlit: 1.50.0
2025-10-28 10:25:41,526:INFO:             prophet: Not installed
2025-10-28 10:25:41,526:INFO:None
2025-10-28 10:25:41,527:INFO:Set up data.
2025-10-28 10:25:41,534:INFO:Set up folding strategy.
2025-10-28 10:25:41,535:INFO:Set up train/test split.
2025-10-28 10:25:41,543:INFO:Set up index.
2025-10-28 10:25:41,544:INFO:Assigning column types.
2025-10-28 10:25:41,551:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:25:41,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,642:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,691:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,692:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,771:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,773:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,825:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,826:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,826:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:25:41,915:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:41,978:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:41,979:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,073:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:25:42,132:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,132:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,133:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:25:42,283:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,283:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,444:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,444:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,446:INFO:Preparing preprocessing pipeline...
2025-10-28 10:25:42,448:INFO:Set up label encoding.
2025-10-28 10:25:42,448:INFO:Set up simple imputation.
2025-10-28 10:25:42,497:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:25:42,504:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:25:42,505:INFO:Creating final display dataframe.
2025-10-28 10:25:42,684:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               6a64
2025-10-28 10:25:42,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:42,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:43,043:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:43,044:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:25:43,046:INFO:setup() successfully completed in 1.55s...............
2025-10-28 10:26:44,745:INFO:PyCaret ClassificationExperiment
2025-10-28 10:26:44,745:INFO:Logging name: clf-default-name
2025-10-28 10:26:44,747:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:26:44,747:INFO:version 3.3.2
2025-10-28 10:26:44,747:INFO:Initializing setup()
2025-10-28 10:26:44,750:INFO:self.USI: 9f13
2025-10-28 10:26:44,750:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:26:44,750:INFO:Checking environment
2025-10-28 10:26:44,750:INFO:python_version: 3.11.14
2025-10-28 10:26:44,751:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:26:44,753:INFO:machine: AMD64
2025-10-28 10:26:44,753:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:26:44,753:INFO:Memory: svmem(total=16788250624, available=4344684544, percent=74.1, used=12443566080, free=4344684544)
2025-10-28 10:26:44,753:INFO:Physical Core: 12
2025-10-28 10:26:44,753:INFO:Logical Core: 16
2025-10-28 10:26:44,763:INFO:Checking libraries
2025-10-28 10:26:44,764:INFO:System:
2025-10-28 10:26:44,764:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:26:44,764:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:26:44,765:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:26:44,766:INFO:PyCaret required dependencies:
2025-10-28 10:26:44,768:INFO:                 pip: 25.2
2025-10-28 10:26:44,768:INFO:          setuptools: 80.9.0
2025-10-28 10:26:44,769:INFO:             pycaret: 3.3.2
2025-10-28 10:26:44,769:INFO:             IPython: 9.6.0
2025-10-28 10:26:44,769:INFO:          ipywidgets: 8.1.7
2025-10-28 10:26:44,769:INFO:                tqdm: 4.67.1
2025-10-28 10:26:44,769:INFO:               numpy: 1.26.4
2025-10-28 10:26:44,769:INFO:              pandas: 2.1.4
2025-10-28 10:26:44,769:INFO:              jinja2: 3.1.6
2025-10-28 10:26:44,769:INFO:               scipy: 1.11.4
2025-10-28 10:26:44,770:INFO:              joblib: 1.3.2
2025-10-28 10:26:44,770:INFO:             sklearn: 1.4.2
2025-10-28 10:26:44,770:INFO:                pyod: 2.0.5
2025-10-28 10:26:44,770:INFO:            imblearn: 0.14.0
2025-10-28 10:26:44,770:INFO:   category_encoders: 2.7.0
2025-10-28 10:26:44,770:INFO:            lightgbm: 4.6.0
2025-10-28 10:26:44,770:INFO:               numba: 0.62.1
2025-10-28 10:26:44,771:INFO:            requests: 2.32.5
2025-10-28 10:26:44,771:INFO:          matplotlib: 3.10.7
2025-10-28 10:26:44,771:INFO:          scikitplot: 0.3.7
2025-10-28 10:26:44,771:INFO:         yellowbrick: 1.5
2025-10-28 10:26:44,771:INFO:              plotly: 6.3.1
2025-10-28 10:26:44,771:INFO:    plotly-resampler: Not installed
2025-10-28 10:26:44,771:INFO:             kaleido: 0.2.1
2025-10-28 10:26:44,771:INFO:           schemdraw: 0.15
2025-10-28 10:26:44,771:INFO:         statsmodels: 0.14.5
2025-10-28 10:26:44,771:INFO:              sktime: 0.26.0
2025-10-28 10:26:44,771:INFO:               tbats: 1.1.3
2025-10-28 10:26:44,772:INFO:            pmdarima: 2.0.4
2025-10-28 10:26:44,772:INFO:              psutil: 7.1.1
2025-10-28 10:26:44,772:INFO:          markupsafe: 3.0.3
2025-10-28 10:26:44,772:INFO:             pickle5: Not installed
2025-10-28 10:26:44,772:INFO:         cloudpickle: 3.1.1
2025-10-28 10:26:44,772:INFO:         deprecation: 2.1.0
2025-10-28 10:26:44,772:INFO:              xxhash: 3.6.0
2025-10-28 10:26:44,772:INFO:           wurlitzer: 3.1.1
2025-10-28 10:26:44,772:INFO:PyCaret optional dependencies:
2025-10-28 10:26:44,772:INFO:                shap: Not installed
2025-10-28 10:26:44,772:INFO:           interpret: Not installed
2025-10-28 10:26:44,772:INFO:                umap: 0.5.9.post2
2025-10-28 10:26:44,772:INFO:     ydata_profiling: Not installed
2025-10-28 10:26:44,773:INFO:  explainerdashboard: Not installed
2025-10-28 10:26:44,773:INFO:             autoviz: Not installed
2025-10-28 10:26:44,773:INFO:           fairlearn: Not installed
2025-10-28 10:26:44,774:INFO:          deepchecks: Not installed
2025-10-28 10:26:44,774:INFO:             xgboost: Not installed
2025-10-28 10:26:44,774:INFO:            catboost: Not installed
2025-10-28 10:26:44,774:INFO:              kmodes: Not installed
2025-10-28 10:26:44,774:INFO:             mlxtend: Not installed
2025-10-28 10:26:44,774:INFO:       statsforecast: Not installed
2025-10-28 10:26:44,774:INFO:        tune_sklearn: Not installed
2025-10-28 10:26:44,774:INFO:                 ray: Not installed
2025-10-28 10:26:44,774:INFO:            hyperopt: Not installed
2025-10-28 10:26:44,774:INFO:              optuna: Not installed
2025-10-28 10:26:44,774:INFO:               skopt: Not installed
2025-10-28 10:26:44,774:INFO:              mlflow: Not installed
2025-10-28 10:26:44,774:INFO:              gradio: Not installed
2025-10-28 10:26:44,774:INFO:             fastapi: Not installed
2025-10-28 10:26:44,775:INFO:             uvicorn: Not installed
2025-10-28 10:26:44,775:INFO:              m2cgen: Not installed
2025-10-28 10:26:44,775:INFO:           evidently: Not installed
2025-10-28 10:26:44,776:INFO:               fugue: Not installed
2025-10-28 10:26:44,777:INFO:           streamlit: 1.50.0
2025-10-28 10:26:44,777:INFO:             prophet: Not installed
2025-10-28 10:26:44,777:INFO:None
2025-10-28 10:26:44,777:INFO:Set up data.
2025-10-28 10:26:44,787:INFO:Set up folding strategy.
2025-10-28 10:26:44,787:INFO:Set up train/test split.
2025-10-28 10:26:44,794:INFO:Set up index.
2025-10-28 10:26:44,795:INFO:Assigning column types.
2025-10-28 10:26:44,801:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:26:44,915:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:26:44,917:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:44,987:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:44,988:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,082:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,083:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,146:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,147:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,148:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:26:45,242:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,319:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,319:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,426:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:26:45,491:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,492:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,493:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:26:45,645:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,646:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,882:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,883:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:45,886:INFO:Preparing preprocessing pipeline...
2025-10-28 10:26:45,888:INFO:Set up label encoding.
2025-10-28 10:26:45,888:INFO:Set up simple imputation.
2025-10-28 10:26:45,943:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:26:45,953:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:26:45,953:INFO:Creating final display dataframe.
2025-10-28 10:26:46,129:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               9f13
2025-10-28 10:26:46,268:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,268:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,394:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,395:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:26:46,398:INFO:setup() successfully completed in 1.66s...............
2025-10-28 10:27:32,655:INFO:PyCaret ClassificationExperiment
2025-10-28 10:27:32,655:INFO:Logging name: clf-default-name
2025-10-28 10:27:32,655:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 10:27:32,655:INFO:version 3.3.2
2025-10-28 10:27:32,655:INFO:Initializing setup()
2025-10-28 10:27:32,655:INFO:self.USI: 320c
2025-10-28 10:27:32,655:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 10:27:32,655:INFO:Checking environment
2025-10-28 10:27:32,655:INFO:python_version: 3.11.14
2025-10-28 10:27:32,655:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:27:32,655:INFO:machine: AMD64
2025-10-28 10:27:32,655:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:27:32,655:INFO:Memory: svmem(total=16788250624, available=4493541376, percent=73.2, used=12294709248, free=4493541376)
2025-10-28 10:27:32,655:INFO:Physical Core: 12
2025-10-28 10:27:32,655:INFO:Logical Core: 16
2025-10-28 10:27:32,655:INFO:Checking libraries
2025-10-28 10:27:32,655:INFO:System:
2025-10-28 10:27:32,655:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:27:32,655:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:27:32,655:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:27:32,655:INFO:PyCaret required dependencies:
2025-10-28 10:27:32,655:INFO:                 pip: 25.2
2025-10-28 10:27:32,655:INFO:          setuptools: 80.9.0
2025-10-28 10:27:32,655:INFO:             pycaret: 3.3.2
2025-10-28 10:27:32,655:INFO:             IPython: 9.6.0
2025-10-28 10:27:32,655:INFO:          ipywidgets: 8.1.7
2025-10-28 10:27:32,655:INFO:                tqdm: 4.67.1
2025-10-28 10:27:32,655:INFO:               numpy: 1.26.4
2025-10-28 10:27:32,655:INFO:              pandas: 2.1.4
2025-10-28 10:27:32,655:INFO:              jinja2: 3.1.6
2025-10-28 10:27:32,655:INFO:               scipy: 1.11.4
2025-10-28 10:27:32,655:INFO:              joblib: 1.3.2
2025-10-28 10:27:32,655:INFO:             sklearn: 1.4.2
2025-10-28 10:27:32,655:INFO:                pyod: 2.0.5
2025-10-28 10:27:32,655:INFO:            imblearn: 0.14.0
2025-10-28 10:27:32,655:INFO:   category_encoders: 2.7.0
2025-10-28 10:27:32,655:INFO:            lightgbm: 4.6.0
2025-10-28 10:27:32,655:INFO:               numba: 0.62.1
2025-10-28 10:27:32,655:INFO:            requests: 2.32.5
2025-10-28 10:27:32,655:INFO:          matplotlib: 3.10.7
2025-10-28 10:27:32,655:INFO:          scikitplot: 0.3.7
2025-10-28 10:27:32,655:INFO:         yellowbrick: 1.5
2025-10-28 10:27:32,655:INFO:              plotly: 6.3.1
2025-10-28 10:27:32,655:INFO:    plotly-resampler: Not installed
2025-10-28 10:27:32,655:INFO:             kaleido: 0.2.1
2025-10-28 10:27:32,655:INFO:           schemdraw: 0.15
2025-10-28 10:27:32,655:INFO:         statsmodels: 0.14.5
2025-10-28 10:27:32,655:INFO:              sktime: 0.26.0
2025-10-28 10:27:32,655:INFO:               tbats: 1.1.3
2025-10-28 10:27:32,655:INFO:            pmdarima: 2.0.4
2025-10-28 10:27:32,655:INFO:              psutil: 7.1.1
2025-10-28 10:27:32,655:INFO:          markupsafe: 3.0.3
2025-10-28 10:27:32,655:INFO:             pickle5: Not installed
2025-10-28 10:27:32,655:INFO:         cloudpickle: 3.1.1
2025-10-28 10:27:32,655:INFO:         deprecation: 2.1.0
2025-10-28 10:27:32,655:INFO:              xxhash: 3.6.0
2025-10-28 10:27:32,655:INFO:           wurlitzer: 3.1.1
2025-10-28 10:27:32,655:INFO:PyCaret optional dependencies:
2025-10-28 10:27:32,655:INFO:                shap: Not installed
2025-10-28 10:27:32,655:INFO:           interpret: Not installed
2025-10-28 10:27:32,655:INFO:                umap: 0.5.9.post2
2025-10-28 10:27:32,655:INFO:     ydata_profiling: Not installed
2025-10-28 10:27:32,655:INFO:  explainerdashboard: Not installed
2025-10-28 10:27:32,655:INFO:             autoviz: Not installed
2025-10-28 10:27:32,660:INFO:           fairlearn: Not installed
2025-10-28 10:27:32,660:INFO:          deepchecks: Not installed
2025-10-28 10:27:32,660:INFO:             xgboost: Not installed
2025-10-28 10:27:32,660:INFO:            catboost: Not installed
2025-10-28 10:27:32,660:INFO:              kmodes: Not installed
2025-10-28 10:27:32,660:INFO:             mlxtend: Not installed
2025-10-28 10:27:32,660:INFO:       statsforecast: Not installed
2025-10-28 10:27:32,660:INFO:        tune_sklearn: Not installed
2025-10-28 10:27:32,660:INFO:                 ray: Not installed
2025-10-28 10:27:32,660:INFO:            hyperopt: Not installed
2025-10-28 10:27:32,660:INFO:              optuna: Not installed
2025-10-28 10:27:32,660:INFO:               skopt: Not installed
2025-10-28 10:27:32,660:INFO:              mlflow: Not installed
2025-10-28 10:27:32,660:INFO:              gradio: Not installed
2025-10-28 10:27:32,660:INFO:             fastapi: Not installed
2025-10-28 10:27:32,660:INFO:             uvicorn: Not installed
2025-10-28 10:27:32,660:INFO:              m2cgen: Not installed
2025-10-28 10:27:32,660:INFO:           evidently: Not installed
2025-10-28 10:27:32,660:INFO:               fugue: Not installed
2025-10-28 10:27:32,660:INFO:           streamlit: 1.50.0
2025-10-28 10:27:32,660:INFO:             prophet: Not installed
2025-10-28 10:27:32,660:INFO:None
2025-10-28 10:27:32,660:INFO:Set up data.
2025-10-28 10:27:32,665:INFO:Set up folding strategy.
2025-10-28 10:27:32,665:INFO:Set up train/test split.
2025-10-28 10:27:32,672:INFO:Set up index.
2025-10-28 10:27:32,672:INFO:Assigning column types.
2025-10-28 10:27:32,676:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:27:32,729:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,731:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,766:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,766:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,817:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,818:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,847:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,848:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,848:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:27:32,900:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:32,937:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,937:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:32,993:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 10:27:33,038:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,040:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 10:27:33,122:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,123:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,203:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,204:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,205:INFO:Preparing preprocessing pipeline...
2025-10-28 10:27:33,206:INFO:Set up label encoding.
2025-10-28 10:27:33,206:INFO:Set up simple imputation.
2025-10-28 10:27:33,244:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:27:33,249:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('label_encoding',
                 TransformerWrapperWithInverse(exclude=None, include=None,
                                               transformer=LabelEncoder())),
                ('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal_length', 'sepal_width',
                                             'petal_length', 'petal_width'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'))),
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent')))],
         verbose=False)
2025-10-28 10:27:33,249:INFO:Creating final display dataframe.
2025-10-28 10:27:33,336:INFO:Setup _display_container:                     Description                                              Value
0                    Session id                                                123
1                        Target                                            species
2                   Target type                                         Multiclass
3                Target mapping  Iris-setosa: 0, Iris-versicolor: 1, Iris-virgi...
4           Original data shape                                           (150, 5)
5        Transformed data shape                                           (150, 5)
6   Transformed train set shape                                           (105, 5)
7    Transformed test set shape                                            (45, 5)
8              Numeric features                                                  4
9                    Preprocess                                               True
10              Imputation type                                             simple
11           Numeric imputation                                               mean
12       Categorical imputation                                               mode
13               Fold Generator                                    StratifiedKFold
14                  Fold Number                                                 10
15                     CPU Jobs                                                 -1
16                      Use GPU                                              False
17               Log Experiment                                              False
18              Experiment Name                                   clf-default-name
19                          USI                                               320c
2025-10-28 10:27:33,427:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,428:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,521:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,521:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:27:33,523:INFO:setup() successfully completed in 0.87s...............
2025-10-28 10:31:08,850:INFO:PyCaret RegressionExperiment
2025-10-28 10:31:08,850:INFO:Logging name: reg-default-name
2025-10-28 10:31:08,850:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:31:08,850:INFO:version 3.3.2
2025-10-28 10:31:08,850:INFO:Initializing setup()
2025-10-28 10:31:08,850:INFO:self.USI: 69e1
2025-10-28 10:31:08,850:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:31:08,850:INFO:Checking environment
2025-10-28 10:31:08,852:INFO:python_version: 3.11.14
2025-10-28 10:31:08,852:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:31:08,852:INFO:machine: AMD64
2025-10-28 10:31:08,853:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:31:08,853:INFO:Memory: svmem(total=16788250624, available=3938975744, percent=76.5, used=12849274880, free=3938975744)
2025-10-28 10:31:08,853:INFO:Physical Core: 12
2025-10-28 10:31:08,853:INFO:Logical Core: 16
2025-10-28 10:31:08,853:INFO:Checking libraries
2025-10-28 10:31:08,853:INFO:System:
2025-10-28 10:31:08,861:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:31:08,862:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:31:08,863:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:31:08,866:INFO:PyCaret required dependencies:
2025-10-28 10:31:08,866:INFO:                 pip: 25.2
2025-10-28 10:31:08,866:INFO:          setuptools: 80.9.0
2025-10-28 10:31:08,866:INFO:             pycaret: 3.3.2
2025-10-28 10:31:08,866:INFO:             IPython: 9.6.0
2025-10-28 10:31:08,867:INFO:          ipywidgets: 8.1.7
2025-10-28 10:31:08,867:INFO:                tqdm: 4.67.1
2025-10-28 10:31:08,867:INFO:               numpy: 1.26.4
2025-10-28 10:31:08,868:INFO:              pandas: 2.1.4
2025-10-28 10:31:08,869:INFO:              jinja2: 3.1.6
2025-10-28 10:31:08,869:INFO:               scipy: 1.11.4
2025-10-28 10:31:08,870:INFO:              joblib: 1.3.2
2025-10-28 10:31:08,870:INFO:             sklearn: 1.4.2
2025-10-28 10:31:08,870:INFO:                pyod: 2.0.5
2025-10-28 10:31:08,870:INFO:            imblearn: 0.14.0
2025-10-28 10:31:08,871:INFO:   category_encoders: 2.7.0
2025-10-28 10:31:08,871:INFO:            lightgbm: 4.6.0
2025-10-28 10:31:08,871:INFO:               numba: 0.62.1
2025-10-28 10:31:08,874:INFO:            requests: 2.32.5
2025-10-28 10:31:08,876:INFO:          matplotlib: 3.10.7
2025-10-28 10:31:08,877:INFO:          scikitplot: 0.3.7
2025-10-28 10:31:08,877:INFO:         yellowbrick: 1.5
2025-10-28 10:31:08,878:INFO:              plotly: 6.3.1
2025-10-28 10:31:08,878:INFO:    plotly-resampler: Not installed
2025-10-28 10:31:08,879:INFO:             kaleido: 0.2.1
2025-10-28 10:31:08,879:INFO:           schemdraw: 0.15
2025-10-28 10:31:08,879:INFO:         statsmodels: 0.14.5
2025-10-28 10:31:08,879:INFO:              sktime: 0.26.0
2025-10-28 10:31:08,879:INFO:               tbats: 1.1.3
2025-10-28 10:31:08,880:INFO:            pmdarima: 2.0.4
2025-10-28 10:31:08,880:INFO:              psutil: 7.1.1
2025-10-28 10:31:08,881:INFO:          markupsafe: 3.0.3
2025-10-28 10:31:08,882:INFO:             pickle5: Not installed
2025-10-28 10:31:08,882:INFO:         cloudpickle: 3.1.1
2025-10-28 10:31:08,882:INFO:         deprecation: 2.1.0
2025-10-28 10:31:08,882:INFO:              xxhash: 3.6.0
2025-10-28 10:31:08,882:INFO:           wurlitzer: 3.1.1
2025-10-28 10:31:08,882:INFO:PyCaret optional dependencies:
2025-10-28 10:31:08,884:INFO:                shap: Not installed
2025-10-28 10:31:08,885:INFO:           interpret: Not installed
2025-10-28 10:31:08,886:INFO:                umap: 0.5.9.post2
2025-10-28 10:31:08,886:INFO:     ydata_profiling: Not installed
2025-10-28 10:31:08,887:INFO:  explainerdashboard: Not installed
2025-10-28 10:31:08,887:INFO:             autoviz: Not installed
2025-10-28 10:31:08,888:INFO:           fairlearn: Not installed
2025-10-28 10:31:08,888:INFO:          deepchecks: Not installed
2025-10-28 10:31:08,889:INFO:             xgboost: Not installed
2025-10-28 10:31:08,890:INFO:            catboost: Not installed
2025-10-28 10:31:08,890:INFO:              kmodes: Not installed
2025-10-28 10:31:08,891:INFO:             mlxtend: Not installed
2025-10-28 10:31:08,891:INFO:       statsforecast: Not installed
2025-10-28 10:31:08,891:INFO:        tune_sklearn: Not installed
2025-10-28 10:31:08,891:INFO:                 ray: Not installed
2025-10-28 10:31:08,891:INFO:            hyperopt: Not installed
2025-10-28 10:31:08,891:INFO:              optuna: Not installed
2025-10-28 10:31:08,891:INFO:               skopt: Not installed
2025-10-28 10:31:08,891:INFO:              mlflow: Not installed
2025-10-28 10:31:08,891:INFO:              gradio: Not installed
2025-10-28 10:31:08,891:INFO:             fastapi: Not installed
2025-10-28 10:31:08,891:INFO:             uvicorn: Not installed
2025-10-28 10:31:08,892:INFO:              m2cgen: Not installed
2025-10-28 10:31:08,892:INFO:           evidently: Not installed
2025-10-28 10:31:08,892:INFO:               fugue: Not installed
2025-10-28 10:31:08,892:INFO:           streamlit: 1.50.0
2025-10-28 10:31:08,892:INFO:             prophet: Not installed
2025-10-28 10:31:08,892:INFO:None
2025-10-28 10:31:08,892:INFO:Set up data.
2025-10-28 10:31:08,901:INFO:Set up folding strategy.
2025-10-28 10:31:08,901:INFO:Set up train/test split.
2025-10-28 10:31:08,909:INFO:Set up index.
2025-10-28 10:31:08,909:INFO:Assigning column types.
2025-10-28 10:31:08,916:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:31:08,916:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:31:08,924:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:08,934:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,046:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,128:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,129:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,130:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,130:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,139:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,146:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,249:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,334:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,335:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,336:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,336:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:31:09,346:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,355:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,485:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,570:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,573:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,574:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,585:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,599:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,718:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,803:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,803:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,803:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:09,804:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:31:09,822:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:09,930:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,012:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,013:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,014:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,032:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,146:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,230:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,232:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,233:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,234:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:31:10,360:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,449:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,450:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,451:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,563:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,640:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,641:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,642:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,643:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:31:10,765:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:10,844:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,844:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:10,966:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:31:11,053:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,053:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,054:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:31:11,305:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,306:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,667:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,668:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:11,670:INFO:Preparing preprocessing pipeline...
2025-10-28 10:31:11,670:INFO:Set up simple imputation.
2025-10-28 10:31:11,678:INFO:Set up encoding of categorical features.
2025-10-28 10:31:11,679:INFO:Set up column name cleaning.
2025-10-28 10:31:11,841:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:31:11,860:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:31:11,861:INFO:Creating final display dataframe.
2025-10-28 10:31:12,277:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              69e1
2025-10-28 10:31:12,575:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,575:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,875:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,876:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:31:12,877:INFO:setup() successfully completed in 4.03s...............
2025-10-28 10:50:43,212:INFO:PyCaret RegressionExperiment
2025-10-28 10:50:43,212:INFO:Logging name: reg-default-name
2025-10-28 10:50:43,212:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-28 10:50:43,212:INFO:version 3.3.2
2025-10-28 10:50:43,212:INFO:Initializing setup()
2025-10-28 10:50:43,212:INFO:self.USI: fd6b
2025-10-28 10:50:43,212:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'transform_target_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase'}
2025-10-28 10:50:43,212:INFO:Checking environment
2025-10-28 10:50:43,212:INFO:python_version: 3.11.14
2025-10-28 10:50:43,212:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 10:50:43,212:INFO:machine: AMD64
2025-10-28 10:50:43,212:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 10:50:43,212:INFO:Memory: svmem(total=16788250624, available=3230248960, percent=80.8, used=13558001664, free=3230248960)
2025-10-28 10:50:43,212:INFO:Physical Core: 12
2025-10-28 10:50:43,212:INFO:Logical Core: 16
2025-10-28 10:50:43,212:INFO:Checking libraries
2025-10-28 10:50:43,212:INFO:System:
2025-10-28 10:50:43,212:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 10:50:43,212:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 10:50:43,212:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 10:50:43,212:INFO:PyCaret required dependencies:
2025-10-28 10:50:43,213:INFO:                 pip: 25.2
2025-10-28 10:50:43,213:INFO:          setuptools: 80.9.0
2025-10-28 10:50:43,213:INFO:             pycaret: 3.3.2
2025-10-28 10:50:43,213:INFO:             IPython: 9.6.0
2025-10-28 10:50:43,213:INFO:          ipywidgets: 8.1.7
2025-10-28 10:50:43,213:INFO:                tqdm: 4.67.1
2025-10-28 10:50:43,213:INFO:               numpy: 1.26.4
2025-10-28 10:50:43,213:INFO:              pandas: 2.1.4
2025-10-28 10:50:43,213:INFO:              jinja2: 3.1.6
2025-10-28 10:50:43,213:INFO:               scipy: 1.11.4
2025-10-28 10:50:43,213:INFO:              joblib: 1.3.2
2025-10-28 10:50:43,213:INFO:             sklearn: 1.4.2
2025-10-28 10:50:43,213:INFO:                pyod: 2.0.5
2025-10-28 10:50:43,213:INFO:            imblearn: 0.14.0
2025-10-28 10:50:43,213:INFO:   category_encoders: 2.7.0
2025-10-28 10:50:43,213:INFO:            lightgbm: 4.6.0
2025-10-28 10:50:43,213:INFO:               numba: 0.62.1
2025-10-28 10:50:43,213:INFO:            requests: 2.32.5
2025-10-28 10:50:43,213:INFO:          matplotlib: 3.10.7
2025-10-28 10:50:43,213:INFO:          scikitplot: 0.3.7
2025-10-28 10:50:43,213:INFO:         yellowbrick: 1.5
2025-10-28 10:50:43,213:INFO:              plotly: 6.3.1
2025-10-28 10:50:43,213:INFO:    plotly-resampler: Not installed
2025-10-28 10:50:43,213:INFO:             kaleido: 0.2.1
2025-10-28 10:50:43,213:INFO:           schemdraw: 0.15
2025-10-28 10:50:43,213:INFO:         statsmodels: 0.14.5
2025-10-28 10:50:43,213:INFO:              sktime: 0.26.0
2025-10-28 10:50:43,214:INFO:               tbats: 1.1.3
2025-10-28 10:50:43,214:INFO:            pmdarima: 2.0.4
2025-10-28 10:50:43,214:INFO:              psutil: 7.1.1
2025-10-28 10:50:43,214:INFO:          markupsafe: 3.0.3
2025-10-28 10:50:43,214:INFO:             pickle5: Not installed
2025-10-28 10:50:43,214:INFO:         cloudpickle: 3.1.1
2025-10-28 10:50:43,214:INFO:         deprecation: 2.1.0
2025-10-28 10:50:43,214:INFO:              xxhash: 3.6.0
2025-10-28 10:50:43,214:INFO:           wurlitzer: 3.1.1
2025-10-28 10:50:43,214:INFO:PyCaret optional dependencies:
2025-10-28 10:50:43,215:INFO:                shap: Not installed
2025-10-28 10:50:43,215:INFO:           interpret: Not installed
2025-10-28 10:50:43,216:INFO:                umap: 0.5.9.post2
2025-10-28 10:50:43,216:INFO:     ydata_profiling: Not installed
2025-10-28 10:50:43,216:INFO:  explainerdashboard: Not installed
2025-10-28 10:50:43,216:INFO:             autoviz: Not installed
2025-10-28 10:50:43,217:INFO:           fairlearn: Not installed
2025-10-28 10:50:43,217:INFO:          deepchecks: Not installed
2025-10-28 10:50:43,217:INFO:             xgboost: Not installed
2025-10-28 10:50:43,217:INFO:            catboost: Not installed
2025-10-28 10:50:43,217:INFO:              kmodes: Not installed
2025-10-28 10:50:43,217:INFO:             mlxtend: Not installed
2025-10-28 10:50:43,217:INFO:       statsforecast: Not installed
2025-10-28 10:50:43,217:INFO:        tune_sklearn: Not installed
2025-10-28 10:50:43,219:INFO:                 ray: Not installed
2025-10-28 10:50:43,219:INFO:            hyperopt: Not installed
2025-10-28 10:50:43,219:INFO:              optuna: Not installed
2025-10-28 10:50:43,219:INFO:               skopt: Not installed
2025-10-28 10:50:43,219:INFO:              mlflow: Not installed
2025-10-28 10:50:43,220:INFO:              gradio: Not installed
2025-10-28 10:50:43,220:INFO:             fastapi: Not installed
2025-10-28 10:50:43,220:INFO:             uvicorn: Not installed
2025-10-28 10:50:43,220:INFO:              m2cgen: Not installed
2025-10-28 10:50:43,220:INFO:           evidently: Not installed
2025-10-28 10:50:43,220:INFO:               fugue: Not installed
2025-10-28 10:50:43,220:INFO:           streamlit: 1.50.0
2025-10-28 10:50:43,221:INFO:             prophet: Not installed
2025-10-28 10:50:43,221:INFO:None
2025-10-28 10:50:43,221:INFO:Set up data.
2025-10-28 10:50:43,230:INFO:Set up folding strategy.
2025-10-28 10:50:43,230:INFO:Set up train/test split.
2025-10-28 10:50:43,237:INFO:Set up index.
2025-10-28 10:50:43,237:INFO:Assigning column types.
2025-10-28 10:50:43,243:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 10:50:43,244:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,259:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,274:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,415:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,506:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,507:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,507:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,509:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,517:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,524:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,599:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,648:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,649:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,649:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,649:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-28 10:50:43,654:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,665:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,748:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,820:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,823:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,823:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,831:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,846:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,929:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,979:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:43,980:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,980:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:43,980:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-28 10:50:43,989:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,054:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,097:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,099:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,099:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,109:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,160:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,232:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,235:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,237:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,237:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-28 10:50:44,401:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,487:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,488:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,488:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,577:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,642:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,643:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,643:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,643:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 10:50:44,804:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:44,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:44,995:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-28 10:50:45,048:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,049:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,049:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-28 10:50:45,224:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,225:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,390:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,390:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,391:INFO:Preparing preprocessing pipeline...
2025-10-28 10:50:45,391:INFO:Set up simple imputation.
2025-10-28 10:50:45,395:INFO:Set up encoding of categorical features.
2025-10-28 10:50:45,396:INFO:Set up column name cleaning.
2025-10-28 10:50:45,470:INFO:Finished creating preprocessing pipeline.
2025-10-28 10:50:45,481:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-28 10:50:45,482:INFO:Creating final display dataframe.
2025-10-28 10:50:45,717:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                -1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              fd6b
2025-10-28 10:50:45,841:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:45,841:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:46,035:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:46,035:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 10:50:46,036:INFO:setup() successfully completed in 2.83s...............
2025-10-28 10:50:46,036:INFO:Initializing compare_models()
2025-10-28 10:50:46,036:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-28 10:50:46,036:INFO:Checking exceptions
2025-10-28 10:50:46,039:INFO:Preparing display monitor
2025-10-28 10:50:46,045:INFO:Initializing Linear Regression
2025-10-28 10:50:46,046:INFO:Total runtime is 1.694361368815104e-05 minutes
2025-10-28 10:50:46,046:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:46,047:INFO:Initializing create_model()
2025-10-28 10:50:46,047:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:46,047:INFO:Checking exceptions
2025-10-28 10:50:46,047:INFO:Importing libraries
2025-10-28 10:50:46,047:INFO:Copying training dataset
2025-10-28 10:50:46,052:INFO:Defining folds
2025-10-28 10:50:46,052:INFO:Declaring metric variables
2025-10-28 10:50:46,053:INFO:Importing untrained model
2025-10-28 10:50:46,053:INFO:Linear Regression Imported successfully
2025-10-28 10:50:46,054:INFO:Starting cross validation
2025-10-28 10:50:46,055:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:50,175:INFO:Calculating mean and std
2025-10-28 10:50:50,177:INFO:Creating metrics dataframe
2025-10-28 10:50:50,184:INFO:Uploading results into container
2025-10-28 10:50:50,185:INFO:Uploading model into container now
2025-10-28 10:50:50,186:INFO:_master_model_container: 1
2025-10-28 10:50:50,186:INFO:_display_container: 2
2025-10-28 10:50:50,187:INFO:LinearRegression(n_jobs=-1)
2025-10-28 10:50:50,187:INFO:create_model() successfully completed......................................
2025-10-28 10:50:50,370:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:50,370:INFO:Creating metrics dataframe
2025-10-28 10:50:50,374:INFO:Initializing Lasso Regression
2025-10-28 10:50:50,375:INFO:Total runtime is 0.07217872540156046 minutes
2025-10-28 10:50:50,375:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:50,375:INFO:Initializing create_model()
2025-10-28 10:50:50,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:50,376:INFO:Checking exceptions
2025-10-28 10:50:50,376:INFO:Importing libraries
2025-10-28 10:50:50,376:INFO:Copying training dataset
2025-10-28 10:50:50,384:INFO:Defining folds
2025-10-28 10:50:50,384:INFO:Declaring metric variables
2025-10-28 10:50:50,384:INFO:Importing untrained model
2025-10-28 10:50:50,385:INFO:Lasso Regression Imported successfully
2025-10-28 10:50:50,385:INFO:Starting cross validation
2025-10-28 10:50:50,386:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:53,329:INFO:Calculating mean and std
2025-10-28 10:50:53,331:INFO:Creating metrics dataframe
2025-10-28 10:50:53,336:INFO:Uploading results into container
2025-10-28 10:50:53,337:INFO:Uploading model into container now
2025-10-28 10:50:53,339:INFO:_master_model_container: 2
2025-10-28 10:50:53,339:INFO:_display_container: 2
2025-10-28 10:50:53,340:INFO:Lasso(random_state=123)
2025-10-28 10:50:53,340:INFO:create_model() successfully completed......................................
2025-10-28 10:50:53,487:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:53,487:INFO:Creating metrics dataframe
2025-10-28 10:50:53,495:INFO:Initializing Ridge Regression
2025-10-28 10:50:53,495:INFO:Total runtime is 0.12417167027791341 minutes
2025-10-28 10:50:53,496:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:53,496:INFO:Initializing create_model()
2025-10-28 10:50:53,496:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:53,496:INFO:Checking exceptions
2025-10-28 10:50:53,496:INFO:Importing libraries
2025-10-28 10:50:53,496:INFO:Copying training dataset
2025-10-28 10:50:53,513:INFO:Defining folds
2025-10-28 10:50:53,513:INFO:Declaring metric variables
2025-10-28 10:50:53,513:INFO:Importing untrained model
2025-10-28 10:50:53,514:INFO:Ridge Regression Imported successfully
2025-10-28 10:50:53,515:INFO:Starting cross validation
2025-10-28 10:50:53,517:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:53,659:INFO:Calculating mean and std
2025-10-28 10:50:53,661:INFO:Creating metrics dataframe
2025-10-28 10:50:53,664:INFO:Uploading results into container
2025-10-28 10:50:53,665:INFO:Uploading model into container now
2025-10-28 10:50:53,666:INFO:_master_model_container: 3
2025-10-28 10:50:53,666:INFO:_display_container: 2
2025-10-28 10:50:53,666:INFO:Ridge(random_state=123)
2025-10-28 10:50:53,666:INFO:create_model() successfully completed......................................
2025-10-28 10:50:53,819:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:53,820:INFO:Creating metrics dataframe
2025-10-28 10:50:53,827:INFO:Initializing Elastic Net
2025-10-28 10:50:53,827:INFO:Total runtime is 0.1297106186548869 minutes
2025-10-28 10:50:53,827:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:53,829:INFO:Initializing create_model()
2025-10-28 10:50:53,829:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:53,829:INFO:Checking exceptions
2025-10-28 10:50:53,830:INFO:Importing libraries
2025-10-28 10:50:53,831:INFO:Copying training dataset
2025-10-28 10:50:53,845:INFO:Defining folds
2025-10-28 10:50:53,846:INFO:Declaring metric variables
2025-10-28 10:50:53,846:INFO:Importing untrained model
2025-10-28 10:50:53,847:INFO:Elastic Net Imported successfully
2025-10-28 10:50:53,849:INFO:Starting cross validation
2025-10-28 10:50:53,851:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:53,960:INFO:Calculating mean and std
2025-10-28 10:50:53,961:INFO:Creating metrics dataframe
2025-10-28 10:50:53,965:INFO:Uploading results into container
2025-10-28 10:50:53,967:INFO:Uploading model into container now
2025-10-28 10:50:53,967:INFO:_master_model_container: 4
2025-10-28 10:50:53,967:INFO:_display_container: 2
2025-10-28 10:50:53,969:INFO:ElasticNet(random_state=123)
2025-10-28 10:50:53,969:INFO:create_model() successfully completed......................................
2025-10-28 10:50:54,097:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:54,097:INFO:Creating metrics dataframe
2025-10-28 10:50:54,102:INFO:Initializing Least Angle Regression
2025-10-28 10:50:54,103:INFO:Total runtime is 0.1343059857686361 minutes
2025-10-28 10:50:54,103:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:54,104:INFO:Initializing create_model()
2025-10-28 10:50:54,104:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:54,104:INFO:Checking exceptions
2025-10-28 10:50:54,104:INFO:Importing libraries
2025-10-28 10:50:54,104:INFO:Copying training dataset
2025-10-28 10:50:54,116:INFO:Defining folds
2025-10-28 10:50:54,116:INFO:Declaring metric variables
2025-10-28 10:50:54,117:INFO:Importing untrained model
2025-10-28 10:50:54,118:INFO:Least Angle Regression Imported successfully
2025-10-28 10:50:54,120:INFO:Starting cross validation
2025-10-28 10:50:54,122:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:54,369:INFO:Calculating mean and std
2025-10-28 10:50:54,370:INFO:Creating metrics dataframe
2025-10-28 10:50:54,372:INFO:Uploading results into container
2025-10-28 10:50:54,373:INFO:Uploading model into container now
2025-10-28 10:50:54,373:INFO:_master_model_container: 5
2025-10-28 10:50:54,374:INFO:_display_container: 2
2025-10-28 10:50:54,374:INFO:Lars(random_state=123)
2025-10-28 10:50:54,374:INFO:create_model() successfully completed......................................
2025-10-28 10:50:54,505:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:54,506:INFO:Creating metrics dataframe
2025-10-28 10:50:54,511:INFO:Initializing Lasso Least Angle Regression
2025-10-28 10:50:54,511:INFO:Total runtime is 0.1411040226618449 minutes
2025-10-28 10:50:54,511:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:54,511:INFO:Initializing create_model()
2025-10-28 10:50:54,511:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:54,511:INFO:Checking exceptions
2025-10-28 10:50:54,511:INFO:Importing libraries
2025-10-28 10:50:54,511:INFO:Copying training dataset
2025-10-28 10:50:54,518:INFO:Defining folds
2025-10-28 10:50:54,518:INFO:Declaring metric variables
2025-10-28 10:50:54,519:INFO:Importing untrained model
2025-10-28 10:50:54,519:INFO:Lasso Least Angle Regression Imported successfully
2025-10-28 10:50:54,519:INFO:Starting cross validation
2025-10-28 10:50:54,520:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:54,689:INFO:Calculating mean and std
2025-10-28 10:50:54,691:INFO:Creating metrics dataframe
2025-10-28 10:50:54,694:INFO:Uploading results into container
2025-10-28 10:50:54,695:INFO:Uploading model into container now
2025-10-28 10:50:54,696:INFO:_master_model_container: 6
2025-10-28 10:50:54,697:INFO:_display_container: 2
2025-10-28 10:50:54,697:INFO:LassoLars(random_state=123)
2025-10-28 10:50:54,697:INFO:create_model() successfully completed......................................
2025-10-28 10:50:54,851:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:54,851:INFO:Creating metrics dataframe
2025-10-28 10:50:54,857:INFO:Initializing Orthogonal Matching Pursuit
2025-10-28 10:50:54,857:INFO:Total runtime is 0.14687641461690268 minutes
2025-10-28 10:50:54,859:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:54,859:INFO:Initializing create_model()
2025-10-28 10:50:54,859:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:54,859:INFO:Checking exceptions
2025-10-28 10:50:54,859:INFO:Importing libraries
2025-10-28 10:50:54,860:INFO:Copying training dataset
2025-10-28 10:50:54,868:INFO:Defining folds
2025-10-28 10:50:54,868:INFO:Declaring metric variables
2025-10-28 10:50:54,868:INFO:Importing untrained model
2025-10-28 10:50:54,868:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-28 10:50:54,868:INFO:Starting cross validation
2025-10-28 10:50:54,869:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:55,031:INFO:Calculating mean and std
2025-10-28 10:50:55,033:INFO:Creating metrics dataframe
2025-10-28 10:50:55,035:INFO:Uploading results into container
2025-10-28 10:50:55,036:INFO:Uploading model into container now
2025-10-28 10:50:55,037:INFO:_master_model_container: 7
2025-10-28 10:50:55,037:INFO:_display_container: 2
2025-10-28 10:50:55,037:INFO:OrthogonalMatchingPursuit()
2025-10-28 10:50:55,037:INFO:create_model() successfully completed......................................
2025-10-28 10:50:55,159:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:55,159:INFO:Creating metrics dataframe
2025-10-28 10:50:55,163:INFO:Initializing Bayesian Ridge
2025-10-28 10:50:55,163:INFO:Total runtime is 0.1519800106684367 minutes
2025-10-28 10:50:55,164:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:55,164:INFO:Initializing create_model()
2025-10-28 10:50:55,164:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:55,164:INFO:Checking exceptions
2025-10-28 10:50:55,164:INFO:Importing libraries
2025-10-28 10:50:55,164:INFO:Copying training dataset
2025-10-28 10:50:55,177:INFO:Defining folds
2025-10-28 10:50:55,177:INFO:Declaring metric variables
2025-10-28 10:50:55,177:INFO:Importing untrained model
2025-10-28 10:50:55,178:INFO:Bayesian Ridge Imported successfully
2025-10-28 10:50:55,178:INFO:Starting cross validation
2025-10-28 10:50:55,179:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:55,414:INFO:Calculating mean and std
2025-10-28 10:50:55,415:INFO:Creating metrics dataframe
2025-10-28 10:50:55,417:INFO:Uploading results into container
2025-10-28 10:50:55,417:INFO:Uploading model into container now
2025-10-28 10:50:55,419:INFO:_master_model_container: 8
2025-10-28 10:50:55,419:INFO:_display_container: 2
2025-10-28 10:50:55,419:INFO:BayesianRidge()
2025-10-28 10:50:55,419:INFO:create_model() successfully completed......................................
2025-10-28 10:50:55,538:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:55,538:INFO:Creating metrics dataframe
2025-10-28 10:50:55,542:INFO:Initializing Passive Aggressive Regressor
2025-10-28 10:50:55,542:INFO:Total runtime is 0.1582977016766866 minutes
2025-10-28 10:50:55,543:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:55,543:INFO:Initializing create_model()
2025-10-28 10:50:55,543:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:55,543:INFO:Checking exceptions
2025-10-28 10:50:55,543:INFO:Importing libraries
2025-10-28 10:50:55,543:INFO:Copying training dataset
2025-10-28 10:50:55,552:INFO:Defining folds
2025-10-28 10:50:55,552:INFO:Declaring metric variables
2025-10-28 10:50:55,552:INFO:Importing untrained model
2025-10-28 10:50:55,552:INFO:Passive Aggressive Regressor Imported successfully
2025-10-28 10:50:55,553:INFO:Starting cross validation
2025-10-28 10:50:55,554:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:55,736:INFO:Calculating mean and std
2025-10-28 10:50:55,737:INFO:Creating metrics dataframe
2025-10-28 10:50:55,740:INFO:Uploading results into container
2025-10-28 10:50:55,740:INFO:Uploading model into container now
2025-10-28 10:50:55,741:INFO:_master_model_container: 9
2025-10-28 10:50:55,741:INFO:_display_container: 2
2025-10-28 10:50:55,741:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-28 10:50:55,741:INFO:create_model() successfully completed......................................
2025-10-28 10:50:55,867:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:55,869:INFO:Creating metrics dataframe
2025-10-28 10:50:55,875:INFO:Initializing Huber Regressor
2025-10-28 10:50:55,875:INFO:Total runtime is 0.1638387084007263 minutes
2025-10-28 10:50:55,876:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:55,876:INFO:Initializing create_model()
2025-10-28 10:50:55,877:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:55,877:INFO:Checking exceptions
2025-10-28 10:50:55,877:INFO:Importing libraries
2025-10-28 10:50:55,877:INFO:Copying training dataset
2025-10-28 10:50:55,882:INFO:Defining folds
2025-10-28 10:50:55,882:INFO:Declaring metric variables
2025-10-28 10:50:55,883:INFO:Importing untrained model
2025-10-28 10:50:55,883:INFO:Huber Regressor Imported successfully
2025-10-28 10:50:55,883:INFO:Starting cross validation
2025-10-28 10:50:55,884:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:56,013:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,017:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,017:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,029:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,036:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,045:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,047:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,052:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,062:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-28 10:50:56,089:INFO:Calculating mean and std
2025-10-28 10:50:56,090:INFO:Creating metrics dataframe
2025-10-28 10:50:56,093:INFO:Uploading results into container
2025-10-28 10:50:56,094:INFO:Uploading model into container now
2025-10-28 10:50:56,094:INFO:_master_model_container: 10
2025-10-28 10:50:56,094:INFO:_display_container: 2
2025-10-28 10:50:56,095:INFO:HuberRegressor()
2025-10-28 10:50:56,095:INFO:create_model() successfully completed......................................
2025-10-28 10:50:56,234:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:56,234:INFO:Creating metrics dataframe
2025-10-28 10:50:56,236:INFO:Initializing K Neighbors Regressor
2025-10-28 10:50:56,236:INFO:Total runtime is 0.16985756953557332 minutes
2025-10-28 10:50:56,236:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:56,236:INFO:Initializing create_model()
2025-10-28 10:50:56,236:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:56,236:INFO:Checking exceptions
2025-10-28 10:50:56,236:INFO:Importing libraries
2025-10-28 10:50:56,236:INFO:Copying training dataset
2025-10-28 10:50:56,242:INFO:Defining folds
2025-10-28 10:50:56,243:INFO:Declaring metric variables
2025-10-28 10:50:56,243:INFO:Importing untrained model
2025-10-28 10:50:56,243:INFO:K Neighbors Regressor Imported successfully
2025-10-28 10:50:56,243:INFO:Starting cross validation
2025-10-28 10:50:56,244:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:56,435:INFO:Calculating mean and std
2025-10-28 10:50:56,436:INFO:Creating metrics dataframe
2025-10-28 10:50:56,441:INFO:Uploading results into container
2025-10-28 10:50:56,442:INFO:Uploading model into container now
2025-10-28 10:50:56,443:INFO:_master_model_container: 11
2025-10-28 10:50:56,443:INFO:_display_container: 2
2025-10-28 10:50:56,444:INFO:KNeighborsRegressor(n_jobs=-1)
2025-10-28 10:50:56,444:INFO:create_model() successfully completed......................................
2025-10-28 10:50:56,595:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:56,595:INFO:Creating metrics dataframe
2025-10-28 10:50:56,600:INFO:Initializing Decision Tree Regressor
2025-10-28 10:50:56,600:INFO:Total runtime is 0.17593318223953247 minutes
2025-10-28 10:50:56,600:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:56,602:INFO:Initializing create_model()
2025-10-28 10:50:56,602:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:56,602:INFO:Checking exceptions
2025-10-28 10:50:56,602:INFO:Importing libraries
2025-10-28 10:50:56,602:INFO:Copying training dataset
2025-10-28 10:50:56,609:INFO:Defining folds
2025-10-28 10:50:56,609:INFO:Declaring metric variables
2025-10-28 10:50:56,609:INFO:Importing untrained model
2025-10-28 10:50:56,611:INFO:Decision Tree Regressor Imported successfully
2025-10-28 10:50:56,611:INFO:Starting cross validation
2025-10-28 10:50:56,613:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:56,777:INFO:Calculating mean and std
2025-10-28 10:50:56,778:INFO:Creating metrics dataframe
2025-10-28 10:50:56,782:INFO:Uploading results into container
2025-10-28 10:50:56,782:INFO:Uploading model into container now
2025-10-28 10:50:56,783:INFO:_master_model_container: 12
2025-10-28 10:50:56,783:INFO:_display_container: 2
2025-10-28 10:50:56,783:INFO:DecisionTreeRegressor(random_state=123)
2025-10-28 10:50:56,784:INFO:create_model() successfully completed......................................
2025-10-28 10:50:56,939:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:56,939:INFO:Creating metrics dataframe
2025-10-28 10:50:56,943:INFO:Initializing Random Forest Regressor
2025-10-28 10:50:56,944:INFO:Total runtime is 0.18163890441258748 minutes
2025-10-28 10:50:56,944:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:56,944:INFO:Initializing create_model()
2025-10-28 10:50:56,944:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:56,945:INFO:Checking exceptions
2025-10-28 10:50:56,945:INFO:Importing libraries
2025-10-28 10:50:56,945:INFO:Copying training dataset
2025-10-28 10:50:56,951:INFO:Defining folds
2025-10-28 10:50:56,951:INFO:Declaring metric variables
2025-10-28 10:50:56,951:INFO:Importing untrained model
2025-10-28 10:50:56,951:INFO:Random Forest Regressor Imported successfully
2025-10-28 10:50:56,951:INFO:Starting cross validation
2025-10-28 10:50:56,953:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:58,257:INFO:Calculating mean and std
2025-10-28 10:50:58,257:INFO:Creating metrics dataframe
2025-10-28 10:50:58,260:INFO:Uploading results into container
2025-10-28 10:50:58,261:INFO:Uploading model into container now
2025-10-28 10:50:58,262:INFO:_master_model_container: 13
2025-10-28 10:50:58,262:INFO:_display_container: 2
2025-10-28 10:50:58,262:INFO:RandomForestRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:50:58,262:INFO:create_model() successfully completed......................................
2025-10-28 10:50:58,404:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:58,405:INFO:Creating metrics dataframe
2025-10-28 10:50:58,409:INFO:Initializing Extra Trees Regressor
2025-10-28 10:50:58,409:INFO:Total runtime is 0.20608212153116862 minutes
2025-10-28 10:50:58,409:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:58,409:INFO:Initializing create_model()
2025-10-28 10:50:58,409:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:58,410:INFO:Checking exceptions
2025-10-28 10:50:58,410:INFO:Importing libraries
2025-10-28 10:50:58,410:INFO:Copying training dataset
2025-10-28 10:50:58,420:INFO:Defining folds
2025-10-28 10:50:58,421:INFO:Declaring metric variables
2025-10-28 10:50:58,421:INFO:Importing untrained model
2025-10-28 10:50:58,421:INFO:Extra Trees Regressor Imported successfully
2025-10-28 10:50:58,421:INFO:Starting cross validation
2025-10-28 10:50:58,422:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:59,163:INFO:Calculating mean and std
2025-10-28 10:50:59,165:INFO:Creating metrics dataframe
2025-10-28 10:50:59,167:INFO:Uploading results into container
2025-10-28 10:50:59,167:INFO:Uploading model into container now
2025-10-28 10:50:59,167:INFO:_master_model_container: 14
2025-10-28 10:50:59,167:INFO:_display_container: 2
2025-10-28 10:50:59,169:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:50:59,169:INFO:create_model() successfully completed......................................
2025-10-28 10:50:59,291:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:59,292:INFO:Creating metrics dataframe
2025-10-28 10:50:59,297:INFO:Initializing AdaBoost Regressor
2025-10-28 10:50:59,297:INFO:Total runtime is 0.22087352275848388 minutes
2025-10-28 10:50:59,297:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:59,297:INFO:Initializing create_model()
2025-10-28 10:50:59,297:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:59,297:INFO:Checking exceptions
2025-10-28 10:50:59,297:INFO:Importing libraries
2025-10-28 10:50:59,297:INFO:Copying training dataset
2025-10-28 10:50:59,307:INFO:Defining folds
2025-10-28 10:50:59,307:INFO:Declaring metric variables
2025-10-28 10:50:59,307:INFO:Importing untrained model
2025-10-28 10:50:59,307:INFO:AdaBoost Regressor Imported successfully
2025-10-28 10:50:59,307:INFO:Starting cross validation
2025-10-28 10:50:59,309:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:50:59,790:INFO:Calculating mean and std
2025-10-28 10:50:59,791:INFO:Creating metrics dataframe
2025-10-28 10:50:59,793:INFO:Uploading results into container
2025-10-28 10:50:59,794:INFO:Uploading model into container now
2025-10-28 10:50:59,794:INFO:_master_model_container: 15
2025-10-28 10:50:59,795:INFO:_display_container: 2
2025-10-28 10:50:59,795:INFO:AdaBoostRegressor(random_state=123)
2025-10-28 10:50:59,795:INFO:create_model() successfully completed......................................
2025-10-28 10:50:59,917:INFO:SubProcess create_model() end ==================================
2025-10-28 10:50:59,917:INFO:Creating metrics dataframe
2025-10-28 10:50:59,922:INFO:Initializing Gradient Boosting Regressor
2025-10-28 10:50:59,922:INFO:Total runtime is 0.231285019715627 minutes
2025-10-28 10:50:59,922:INFO:SubProcess create_model() called ==================================
2025-10-28 10:50:59,922:INFO:Initializing create_model()
2025-10-28 10:50:59,922:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:50:59,922:INFO:Checking exceptions
2025-10-28 10:50:59,923:INFO:Importing libraries
2025-10-28 10:50:59,923:INFO:Copying training dataset
2025-10-28 10:50:59,930:INFO:Defining folds
2025-10-28 10:50:59,930:INFO:Declaring metric variables
2025-10-28 10:50:59,930:INFO:Importing untrained model
2025-10-28 10:50:59,931:INFO:Gradient Boosting Regressor Imported successfully
2025-10-28 10:50:59,931:INFO:Starting cross validation
2025-10-28 10:50:59,932:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:51:00,689:INFO:Calculating mean and std
2025-10-28 10:51:00,690:INFO:Creating metrics dataframe
2025-10-28 10:51:00,692:INFO:Uploading results into container
2025-10-28 10:51:00,693:INFO:Uploading model into container now
2025-10-28 10:51:00,693:INFO:_master_model_container: 16
2025-10-28 10:51:00,693:INFO:_display_container: 2
2025-10-28 10:51:00,694:INFO:GradientBoostingRegressor(random_state=123)
2025-10-28 10:51:00,694:INFO:create_model() successfully completed......................................
2025-10-28 10:51:00,831:INFO:SubProcess create_model() end ==================================
2025-10-28 10:51:00,831:INFO:Creating metrics dataframe
2025-10-28 10:51:00,835:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 10:51:00,836:INFO:Total runtime is 0.24651980797449746 minutes
2025-10-28 10:51:00,836:INFO:SubProcess create_model() called ==================================
2025-10-28 10:51:00,836:INFO:Initializing create_model()
2025-10-28 10:51:00,837:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:51:00,837:INFO:Checking exceptions
2025-10-28 10:51:00,837:INFO:Importing libraries
2025-10-28 10:51:00,837:INFO:Copying training dataset
2025-10-28 10:51:00,844:INFO:Defining folds
2025-10-28 10:51:00,845:INFO:Declaring metric variables
2025-10-28 10:51:00,845:INFO:Importing untrained model
2025-10-28 10:51:00,847:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 10:51:00,849:INFO:Starting cross validation
2025-10-28 10:51:00,852:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:51:02,344:INFO:Calculating mean and std
2025-10-28 10:51:02,345:INFO:Creating metrics dataframe
2025-10-28 10:51:02,348:INFO:Uploading results into container
2025-10-28 10:51:02,349:INFO:Uploading model into container now
2025-10-28 10:51:02,349:INFO:_master_model_container: 17
2025-10-28 10:51:02,349:INFO:_display_container: 2
2025-10-28 10:51:02,350:INFO:LGBMRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:51:02,350:INFO:create_model() successfully completed......................................
2025-10-28 10:51:02,464:INFO:SubProcess create_model() end ==================================
2025-10-28 10:51:02,465:INFO:Creating metrics dataframe
2025-10-28 10:51:02,468:INFO:Initializing Dummy Regressor
2025-10-28 10:51:02,468:INFO:Total runtime is 0.27373257478078206 minutes
2025-10-28 10:51:02,469:INFO:SubProcess create_model() called ==================================
2025-10-28 10:51:02,469:INFO:Initializing create_model()
2025-10-28 10:51:02,469:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D359C3D0>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:51:02,469:INFO:Checking exceptions
2025-10-28 10:51:02,469:INFO:Importing libraries
2025-10-28 10:51:02,469:INFO:Copying training dataset
2025-10-28 10:51:02,478:INFO:Defining folds
2025-10-28 10:51:02,478:INFO:Declaring metric variables
2025-10-28 10:51:02,478:INFO:Importing untrained model
2025-10-28 10:51:02,478:INFO:Dummy Regressor Imported successfully
2025-10-28 10:51:02,478:INFO:Starting cross validation
2025-10-28 10:51:02,480:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 10:51:02,650:INFO:Calculating mean and std
2025-10-28 10:51:02,651:INFO:Creating metrics dataframe
2025-10-28 10:51:02,653:INFO:Uploading results into container
2025-10-28 10:51:02,654:INFO:Uploading model into container now
2025-10-28 10:51:02,654:INFO:_master_model_container: 18
2025-10-28 10:51:02,654:INFO:_display_container: 2
2025-10-28 10:51:02,655:INFO:DummyRegressor()
2025-10-28 10:51:02,655:INFO:create_model() successfully completed......................................
2025-10-28 10:51:02,795:INFO:SubProcess create_model() end ==================================
2025-10-28 10:51:02,795:INFO:Creating metrics dataframe
2025-10-28 10:51:02,805:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 10:51:02,807:INFO:Initializing create_model()
2025-10-28 10:51:02,809:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 10:51:02,809:INFO:Checking exceptions
2025-10-28 10:51:02,810:INFO:Importing libraries
2025-10-28 10:51:02,810:INFO:Copying training dataset
2025-10-28 10:51:02,818:INFO:Defining folds
2025-10-28 10:51:02,818:INFO:Declaring metric variables
2025-10-28 10:51:02,819:INFO:Importing untrained model
2025-10-28 10:51:02,819:INFO:Declaring custom model
2025-10-28 10:51:02,819:INFO:Extra Trees Regressor Imported successfully
2025-10-28 10:51:02,821:INFO:Cross validation set to False
2025-10-28 10:51:02,821:INFO:Fitting Model
2025-10-28 10:51:02,999:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:51:02,999:INFO:create_model() successfully completed......................................
2025-10-28 10:51:03,160:INFO:_master_model_container: 18
2025-10-28 10:51:03,160:INFO:_display_container: 2
2025-10-28 10:51:03,161:INFO:ExtraTreesRegressor(n_jobs=-1, random_state=123)
2025-10-28 10:51:03,161:INFO:compare_models() successfully completed......................................
2025-10-28 10:51:28,802:INFO:Initializing plot_model()
2025-10-28 10:51:28,802:INFO:plot_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), plot=feature, scale=1, save=True, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=None)
2025-10-28 10:51:28,802:INFO:Checking exceptions
2025-10-28 10:51:28,848:INFO:Preloading libraries
2025-10-28 10:51:28,915:INFO:Copying training dataset
2025-10-28 10:51:28,915:INFO:Plot type: feature
2025-10-28 10:51:28,915:WARNING:No coef_ found. Trying feature_importances_
2025-10-28 10:51:29,099:INFO:Saving 'Feature Importance.png'
2025-10-28 10:51:29,343:INFO:Visual Rendered Successfully
2025-10-28 10:51:29,469:INFO:plot_model() successfully completed......................................
2025-10-28 10:51:29,525:INFO:Initializing predict_model()
2025-10-28 10:51:29,525:INFO:predict_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000218D3628810>, estimator=ExtraTreesRegressor(n_jobs=-1, random_state=123), probability_threshold=None, encoded_labels=False, raw_score=False, round=4, verbose=True, ml_usecase=None, preprocess=True, encode_labels=<function _SupervisedExperiment.predict_model.<locals>.encode_labels at 0x00000218D405EDE0>)
2025-10-28 10:51:29,525:INFO:Checking exceptions
2025-10-28 10:51:29,525:INFO:Preloading libraries
2025-10-28 10:51:29,526:INFO:Set up data.
2025-10-28 10:51:29,535:INFO:Set up index.
2025-10-28 10:51:29,659:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_regression.py:483: FutureWarning: 'squared' is deprecated in version 1.4 and will be removed in 1.6. To calculate the root mean squared error, use the function'root_mean_squared_error'.
  warnings.warn(

2025-10-28 10:55:42,797:INFO:Initializing load_model()
2025-10-28 10:55:42,797:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 10:56:43,412:INFO:Initializing load_model()
2025-10-28 10:56:43,412:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 10:56:50,993:INFO:Initializing load_model()
2025-10-28 10:56:50,993:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 10:56:55,622:INFO:Initializing load_model()
2025-10-28 10:56:55,623:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 11:01:53,301:INFO:Initializing load_model()
2025-10-28 11:01:53,301:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 11:01:53,301:INFO:Initializing load_model()
2025-10-28 11:01:53,301:INFO:load_model(model_name=your_model_name, platform=None, authentication=None, verbose=True)
2025-10-28 11:07:12,907:INFO:PyCaret ClassificationExperiment
2025-10-28 11:07:12,907:INFO:Logging name: clf-default-name
2025-10-28 11:07:12,907:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 11:07:12,908:INFO:version 3.3.2
2025-10-28 11:07:12,908:INFO:Initializing setup()
2025-10-28 11:07:12,908:INFO:self.USI: 6f69
2025-10-28 11:07:12,908:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 11:07:12,908:INFO:Checking environment
2025-10-28 11:07:12,908:INFO:python_version: 3.11.14
2025-10-28 11:07:12,908:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 11:07:12,908:INFO:machine: AMD64
2025-10-28 11:07:12,908:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 11:07:12,909:INFO:Memory: svmem(total=16788250624, available=4903288832, percent=70.8, used=11884961792, free=4903288832)
2025-10-28 11:07:12,909:INFO:Physical Core: 12
2025-10-28 11:07:12,909:INFO:Logical Core: 16
2025-10-28 11:07:12,909:INFO:Checking libraries
2025-10-28 11:07:12,909:INFO:System:
2025-10-28 11:07:12,909:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 11:07:12,909:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 11:07:12,909:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 11:07:12,909:INFO:PyCaret required dependencies:
2025-10-28 11:07:12,910:INFO:                 pip: 25.2
2025-10-28 11:07:12,910:INFO:          setuptools: 80.9.0
2025-10-28 11:07:12,910:INFO:             pycaret: 3.3.2
2025-10-28 11:07:12,910:INFO:             IPython: 9.6.0
2025-10-28 11:07:12,911:INFO:          ipywidgets: 8.1.7
2025-10-28 11:07:12,911:INFO:                tqdm: 4.67.1
2025-10-28 11:07:12,911:INFO:               numpy: 1.26.4
2025-10-28 11:07:12,911:INFO:              pandas: 2.1.4
2025-10-28 11:07:12,912:INFO:              jinja2: 3.1.6
2025-10-28 11:07:12,912:INFO:               scipy: 1.11.4
2025-10-28 11:07:12,912:INFO:              joblib: 1.3.2
2025-10-28 11:07:12,912:INFO:             sklearn: 1.4.2
2025-10-28 11:07:12,914:INFO:                pyod: 2.0.5
2025-10-28 11:07:12,914:INFO:            imblearn: 0.14.0
2025-10-28 11:07:12,914:INFO:   category_encoders: 2.7.0
2025-10-28 11:07:12,914:INFO:            lightgbm: 4.6.0
2025-10-28 11:07:12,914:INFO:               numba: 0.62.1
2025-10-28 11:07:12,914:INFO:            requests: 2.32.5
2025-10-28 11:07:12,914:INFO:          matplotlib: 3.10.7
2025-10-28 11:07:12,914:INFO:          scikitplot: 0.3.7
2025-10-28 11:07:12,915:INFO:         yellowbrick: 1.5
2025-10-28 11:07:12,915:INFO:              plotly: 6.3.1
2025-10-28 11:07:12,915:INFO:    plotly-resampler: Not installed
2025-10-28 11:07:12,915:INFO:             kaleido: 0.2.1
2025-10-28 11:07:12,915:INFO:           schemdraw: 0.15
2025-10-28 11:07:12,915:INFO:         statsmodels: 0.14.5
2025-10-28 11:07:12,916:INFO:              sktime: 0.26.0
2025-10-28 11:07:12,916:INFO:               tbats: 1.1.3
2025-10-28 11:07:12,916:INFO:            pmdarima: 2.0.4
2025-10-28 11:07:12,916:INFO:              psutil: 7.1.1
2025-10-28 11:07:12,916:INFO:          markupsafe: 3.0.3
2025-10-28 11:07:12,917:INFO:             pickle5: Not installed
2025-10-28 11:07:12,917:INFO:         cloudpickle: 3.1.1
2025-10-28 11:07:12,917:INFO:         deprecation: 2.1.0
2025-10-28 11:07:12,917:INFO:              xxhash: 3.6.0
2025-10-28 11:07:12,917:INFO:           wurlitzer: 3.1.1
2025-10-28 11:07:12,917:INFO:PyCaret optional dependencies:
2025-10-28 11:07:12,918:INFO:                shap: Not installed
2025-10-28 11:07:12,918:INFO:           interpret: Not installed
2025-10-28 11:07:12,918:INFO:                umap: 0.5.9.post2
2025-10-28 11:07:12,918:INFO:     ydata_profiling: Not installed
2025-10-28 11:07:12,919:INFO:  explainerdashboard: Not installed
2025-10-28 11:07:12,919:INFO:             autoviz: Not installed
2025-10-28 11:07:12,919:INFO:           fairlearn: Not installed
2025-10-28 11:07:12,919:INFO:          deepchecks: Not installed
2025-10-28 11:07:12,920:INFO:             xgboost: Not installed
2025-10-28 11:07:12,920:INFO:            catboost: Not installed
2025-10-28 11:07:12,920:INFO:              kmodes: Not installed
2025-10-28 11:07:12,920:INFO:             mlxtend: Not installed
2025-10-28 11:07:12,920:INFO:       statsforecast: Not installed
2025-10-28 11:07:12,920:INFO:        tune_sklearn: Not installed
2025-10-28 11:07:12,921:INFO:                 ray: Not installed
2025-10-28 11:07:12,921:INFO:            hyperopt: Not installed
2025-10-28 11:07:12,921:INFO:              optuna: Not installed
2025-10-28 11:07:12,921:INFO:               skopt: Not installed
2025-10-28 11:07:12,921:INFO:              mlflow: Not installed
2025-10-28 11:07:12,922:INFO:              gradio: Not installed
2025-10-28 11:07:12,922:INFO:             fastapi: Not installed
2025-10-28 11:07:12,922:INFO:             uvicorn: Not installed
2025-10-28 11:07:12,922:INFO:              m2cgen: Not installed
2025-10-28 11:07:12,922:INFO:           evidently: Not installed
2025-10-28 11:07:12,922:INFO:               fugue: Not installed
2025-10-28 11:07:12,923:INFO:           streamlit: 1.50.0
2025-10-28 11:07:12,923:INFO:             prophet: Not installed
2025-10-28 11:07:12,924:INFO:None
2025-10-28 11:07:12,925:INFO:Set up data.
2025-10-28 11:07:12,932:INFO:Set up folding strategy.
2025-10-28 11:07:12,932:INFO:Set up train/test split.
2025-10-28 11:07:12,943:INFO:Set up index.
2025-10-28 11:07:12,943:INFO:Assigning column types.
2025-10-28 11:07:12,950:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 11:07:13,074:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,075:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,116:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,116:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,226:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,228:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,273:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,273:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,274:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 11:07:13,319:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,350:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,350:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,398:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:07:13,430:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,430:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,432:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 11:07:13,570:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,570:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,675:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,675:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,678:INFO:Preparing preprocessing pipeline...
2025-10-28 11:07:13,679:INFO:Set up simple imputation.
2025-10-28 11:07:13,680:INFO:Set up column name cleaning.
2025-10-28 11:07:13,702:INFO:Finished creating preprocessing pipeline.
2025-10-28 11:07:13,708:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-28 11:07:13,708:INFO:Creating final display dataframe.
2025-10-28 11:07:13,784:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              6f69
2025-10-28 11:07:13,877:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,878:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,984:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,986:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:07:13,986:INFO:setup() successfully completed in 1.08s...............
2025-10-28 11:07:13,986:INFO:Initializing compare_models()
2025-10-28 11:07:13,986:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-28 11:07:13,986:INFO:Checking exceptions
2025-10-28 11:07:13,991:INFO:Preparing display monitor
2025-10-28 11:07:13,993:INFO:Initializing Logistic Regression
2025-10-28 11:07:13,993:INFO:Total runtime is 0.0 minutes
2025-10-28 11:07:13,993:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:13,993:INFO:Initializing create_model()
2025-10-28 11:07:13,993:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:13,993:INFO:Checking exceptions
2025-10-28 11:07:13,993:INFO:Importing libraries
2025-10-28 11:07:13,993:INFO:Copying training dataset
2025-10-28 11:07:13,996:INFO:Defining folds
2025-10-28 11:07:13,996:INFO:Declaring metric variables
2025-10-28 11:07:13,996:INFO:Importing untrained model
2025-10-28 11:07:13,996:INFO:Logistic Regression Imported successfully
2025-10-28 11:07:13,997:INFO:Starting cross validation
2025-10-28 11:07:13,997:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:17,862:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,870:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,874:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,877:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,877:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,890:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,894:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,901:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,902:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:17,923:INFO:Calculating mean and std
2025-10-28 11:07:17,924:INFO:Creating metrics dataframe
2025-10-28 11:07:17,928:INFO:Uploading results into container
2025-10-28 11:07:17,929:INFO:Uploading model into container now
2025-10-28 11:07:17,929:INFO:_master_model_container: 1
2025-10-28 11:07:17,929:INFO:_display_container: 2
2025-10-28 11:07:17,930:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:07:17,930:INFO:create_model() successfully completed......................................
2025-10-28 11:07:18,091:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:18,091:INFO:Creating metrics dataframe
2025-10-28 11:07:18,094:INFO:Initializing K Neighbors Classifier
2025-10-28 11:07:18,094:INFO:Total runtime is 0.06834901968638102 minutes
2025-10-28 11:07:18,094:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:18,095:INFO:Initializing create_model()
2025-10-28 11:07:18,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:18,095:INFO:Checking exceptions
2025-10-28 11:07:18,095:INFO:Importing libraries
2025-10-28 11:07:18,095:INFO:Copying training dataset
2025-10-28 11:07:18,100:INFO:Defining folds
2025-10-28 11:07:18,100:INFO:Declaring metric variables
2025-10-28 11:07:18,101:INFO:Importing untrained model
2025-10-28 11:07:18,101:INFO:K Neighbors Classifier Imported successfully
2025-10-28 11:07:18,102:INFO:Starting cross validation
2025-10-28 11:07:18,103:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:20,896:INFO:Calculating mean and std
2025-10-28 11:07:20,899:INFO:Creating metrics dataframe
2025-10-28 11:07:20,901:INFO:Uploading results into container
2025-10-28 11:07:20,902:INFO:Uploading model into container now
2025-10-28 11:07:20,902:INFO:_master_model_container: 2
2025-10-28 11:07:20,902:INFO:_display_container: 2
2025-10-28 11:07:20,903:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-28 11:07:20,903:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,039:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,039:INFO:Creating metrics dataframe
2025-10-28 11:07:21,046:INFO:Initializing Naive Bayes
2025-10-28 11:07:21,046:INFO:Total runtime is 0.11754014094670613 minutes
2025-10-28 11:07:21,046:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,047:INFO:Initializing create_model()
2025-10-28 11:07:21,047:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,047:INFO:Checking exceptions
2025-10-28 11:07:21,047:INFO:Importing libraries
2025-10-28 11:07:21,047:INFO:Copying training dataset
2025-10-28 11:07:21,052:INFO:Defining folds
2025-10-28 11:07:21,052:INFO:Declaring metric variables
2025-10-28 11:07:21,052:INFO:Importing untrained model
2025-10-28 11:07:21,053:INFO:Naive Bayes Imported successfully
2025-10-28 11:07:21,053:INFO:Starting cross validation
2025-10-28 11:07:21,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,132:INFO:Calculating mean and std
2025-10-28 11:07:21,133:INFO:Creating metrics dataframe
2025-10-28 11:07:21,137:INFO:Uploading results into container
2025-10-28 11:07:21,138:INFO:Uploading model into container now
2025-10-28 11:07:21,139:INFO:_master_model_container: 3
2025-10-28 11:07:21,139:INFO:_display_container: 2
2025-10-28 11:07:21,140:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-28 11:07:21,140:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,265:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,265:INFO:Creating metrics dataframe
2025-10-28 11:07:21,268:INFO:Initializing Decision Tree Classifier
2025-10-28 11:07:21,268:INFO:Total runtime is 0.12124522527058919 minutes
2025-10-28 11:07:21,268:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,268:INFO:Initializing create_model()
2025-10-28 11:07:21,268:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,268:INFO:Checking exceptions
2025-10-28 11:07:21,268:INFO:Importing libraries
2025-10-28 11:07:21,269:INFO:Copying training dataset
2025-10-28 11:07:21,274:INFO:Defining folds
2025-10-28 11:07:21,274:INFO:Declaring metric variables
2025-10-28 11:07:21,274:INFO:Importing untrained model
2025-10-28 11:07:21,274:INFO:Decision Tree Classifier Imported successfully
2025-10-28 11:07:21,274:INFO:Starting cross validation
2025-10-28 11:07:21,275:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,330:INFO:Calculating mean and std
2025-10-28 11:07:21,331:INFO:Creating metrics dataframe
2025-10-28 11:07:21,334:INFO:Uploading results into container
2025-10-28 11:07:21,335:INFO:Uploading model into container now
2025-10-28 11:07:21,336:INFO:_master_model_container: 4
2025-10-28 11:07:21,337:INFO:_display_container: 2
2025-10-28 11:07:21,337:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-28 11:07:21,337:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,471:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,472:INFO:Creating metrics dataframe
2025-10-28 11:07:21,477:INFO:Initializing SVM - Linear Kernel
2025-10-28 11:07:21,477:INFO:Total runtime is 0.1247215469678243 minutes
2025-10-28 11:07:21,477:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,477:INFO:Initializing create_model()
2025-10-28 11:07:21,477:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,477:INFO:Checking exceptions
2025-10-28 11:07:21,477:INFO:Importing libraries
2025-10-28 11:07:21,477:INFO:Copying training dataset
2025-10-28 11:07:21,481:INFO:Defining folds
2025-10-28 11:07:21,481:INFO:Declaring metric variables
2025-10-28 11:07:21,481:INFO:Importing untrained model
2025-10-28 11:07:21,482:INFO:SVM - Linear Kernel Imported successfully
2025-10-28 11:07:21,482:INFO:Starting cross validation
2025-10-28 11:07:21,483:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,535:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,535:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,536:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,537:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,541:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,542:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,542:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,557:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,558:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,560:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,562:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,562:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,563:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,564:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:21,577:INFO:Calculating mean and std
2025-10-28 11:07:21,579:INFO:Creating metrics dataframe
2025-10-28 11:07:21,584:INFO:Uploading results into container
2025-10-28 11:07:21,586:INFO:Uploading model into container now
2025-10-28 11:07:21,587:INFO:_master_model_container: 5
2025-10-28 11:07:21,587:INFO:_display_container: 2
2025-10-28 11:07:21,588:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-28 11:07:21,588:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,733:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,733:INFO:Creating metrics dataframe
2025-10-28 11:07:21,739:INFO:Initializing Ridge Classifier
2025-10-28 11:07:21,739:INFO:Total runtime is 0.12908904949824015 minutes
2025-10-28 11:07:21,739:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,739:INFO:Initializing create_model()
2025-10-28 11:07:21,740:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,740:INFO:Checking exceptions
2025-10-28 11:07:21,740:INFO:Importing libraries
2025-10-28 11:07:21,740:INFO:Copying training dataset
2025-10-28 11:07:21,744:INFO:Defining folds
2025-10-28 11:07:21,744:INFO:Declaring metric variables
2025-10-28 11:07:21,746:INFO:Importing untrained model
2025-10-28 11:07:21,746:INFO:Ridge Classifier Imported successfully
2025-10-28 11:07:21,747:INFO:Starting cross validation
2025-10-28 11:07:21,748:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:21,822:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,822:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,822:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,824:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,827:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,827:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,827:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,828:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,831:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:21,845:INFO:Calculating mean and std
2025-10-28 11:07:21,846:INFO:Creating metrics dataframe
2025-10-28 11:07:21,852:INFO:Uploading results into container
2025-10-28 11:07:21,853:INFO:Uploading model into container now
2025-10-28 11:07:21,853:INFO:_master_model_container: 6
2025-10-28 11:07:21,853:INFO:_display_container: 2
2025-10-28 11:07:21,854:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-28 11:07:21,854:INFO:create_model() successfully completed......................................
2025-10-28 11:07:21,987:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:21,988:INFO:Creating metrics dataframe
2025-10-28 11:07:21,992:INFO:Initializing Random Forest Classifier
2025-10-28 11:07:21,992:INFO:Total runtime is 0.13331883748372397 minutes
2025-10-28 11:07:21,992:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:21,992:INFO:Initializing create_model()
2025-10-28 11:07:21,992:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:21,992:INFO:Checking exceptions
2025-10-28 11:07:21,992:INFO:Importing libraries
2025-10-28 11:07:21,992:INFO:Copying training dataset
2025-10-28 11:07:21,997:INFO:Defining folds
2025-10-28 11:07:21,997:INFO:Declaring metric variables
2025-10-28 11:07:21,997:INFO:Importing untrained model
2025-10-28 11:07:21,998:INFO:Random Forest Classifier Imported successfully
2025-10-28 11:07:21,999:INFO:Starting cross validation
2025-10-28 11:07:22,000:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:22,310:INFO:Calculating mean and std
2025-10-28 11:07:22,310:INFO:Creating metrics dataframe
2025-10-28 11:07:22,313:INFO:Uploading results into container
2025-10-28 11:07:22,315:INFO:Uploading model into container now
2025-10-28 11:07:22,315:INFO:_master_model_container: 7
2025-10-28 11:07:22,315:INFO:_display_container: 2
2025-10-28 11:07:22,316:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-28 11:07:22,316:INFO:create_model() successfully completed......................................
2025-10-28 11:07:22,444:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:22,444:INFO:Creating metrics dataframe
2025-10-28 11:07:22,448:INFO:Initializing Quadratic Discriminant Analysis
2025-10-28 11:07:22,448:INFO:Total runtime is 0.1409042278925578 minutes
2025-10-28 11:07:22,449:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:22,449:INFO:Initializing create_model()
2025-10-28 11:07:22,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:22,449:INFO:Checking exceptions
2025-10-28 11:07:22,449:INFO:Importing libraries
2025-10-28 11:07:22,449:INFO:Copying training dataset
2025-10-28 11:07:22,452:INFO:Defining folds
2025-10-28 11:07:22,452:INFO:Declaring metric variables
2025-10-28 11:07:22,453:INFO:Importing untrained model
2025-10-28 11:07:22,453:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-28 11:07:22,453:INFO:Starting cross validation
2025-10-28 11:07:22,455:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:22,524:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,526:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,527:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,528:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,529:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,533:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,536:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,542:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,572:INFO:Calculating mean and std
2025-10-28 11:07:22,572:INFO:Creating metrics dataframe
2025-10-28 11:07:22,574:INFO:Uploading results into container
2025-10-28 11:07:22,574:INFO:Uploading model into container now
2025-10-28 11:07:22,574:INFO:_master_model_container: 8
2025-10-28 11:07:22,574:INFO:_display_container: 2
2025-10-28 11:07:22,574:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-28 11:07:22,574:INFO:create_model() successfully completed......................................
2025-10-28 11:07:22,695:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:22,695:INFO:Creating metrics dataframe
2025-10-28 11:07:22,704:INFO:Initializing Ada Boost Classifier
2025-10-28 11:07:22,704:INFO:Total runtime is 0.1451822876930237 minutes
2025-10-28 11:07:22,704:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:22,704:INFO:Initializing create_model()
2025-10-28 11:07:22,704:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:22,704:INFO:Checking exceptions
2025-10-28 11:07:22,704:INFO:Importing libraries
2025-10-28 11:07:22,704:INFO:Copying training dataset
2025-10-28 11:07:22,708:INFO:Defining folds
2025-10-28 11:07:22,708:INFO:Declaring metric variables
2025-10-28 11:07:22,708:INFO:Importing untrained model
2025-10-28 11:07:22,708:INFO:Ada Boost Classifier Imported successfully
2025-10-28 11:07:22,708:INFO:Starting cross validation
2025-10-28 11:07:22,708:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:22,750:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,752:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,754:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,761:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,761:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,765:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,767:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,768:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,772:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:07:22,925:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,926:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,931:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,933:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,935:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,939:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,939:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,941:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,950:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,950:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:22,968:INFO:Calculating mean and std
2025-10-28 11:07:22,968:INFO:Creating metrics dataframe
2025-10-28 11:07:22,971:INFO:Uploading results into container
2025-10-28 11:07:22,971:INFO:Uploading model into container now
2025-10-28 11:07:22,971:INFO:_master_model_container: 9
2025-10-28 11:07:22,971:INFO:_display_container: 2
2025-10-28 11:07:22,971:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-28 11:07:22,971:INFO:create_model() successfully completed......................................
2025-10-28 11:07:23,113:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:23,113:INFO:Creating metrics dataframe
2025-10-28 11:07:23,117:INFO:Initializing Gradient Boosting Classifier
2025-10-28 11:07:23,117:INFO:Total runtime is 0.1520699461301168 minutes
2025-10-28 11:07:23,117:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:23,117:INFO:Initializing create_model()
2025-10-28 11:07:23,122:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:23,122:INFO:Checking exceptions
2025-10-28 11:07:23,122:INFO:Importing libraries
2025-10-28 11:07:23,122:INFO:Copying training dataset
2025-10-28 11:07:23,126:INFO:Defining folds
2025-10-28 11:07:23,126:INFO:Declaring metric variables
2025-10-28 11:07:23,130:INFO:Importing untrained model
2025-10-28 11:07:23,130:INFO:Gradient Boosting Classifier Imported successfully
2025-10-28 11:07:23,130:INFO:Starting cross validation
2025-10-28 11:07:23,130:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:23,537:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,543:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,545:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,557:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,562:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,573:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,588:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,609:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,626:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,649:INFO:Calculating mean and std
2025-10-28 11:07:23,649:INFO:Creating metrics dataframe
2025-10-28 11:07:23,651:INFO:Uploading results into container
2025-10-28 11:07:23,652:INFO:Uploading model into container now
2025-10-28 11:07:23,652:INFO:_master_model_container: 10
2025-10-28 11:07:23,652:INFO:_display_container: 2
2025-10-28 11:07:23,652:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-28 11:07:23,652:INFO:create_model() successfully completed......................................
2025-10-28 11:07:23,785:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:23,785:INFO:Creating metrics dataframe
2025-10-28 11:07:23,789:INFO:Initializing Linear Discriminant Analysis
2025-10-28 11:07:23,789:INFO:Total runtime is 0.16325873533884686 minutes
2025-10-28 11:07:23,789:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:23,789:INFO:Initializing create_model()
2025-10-28 11:07:23,790:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:23,790:INFO:Checking exceptions
2025-10-28 11:07:23,790:INFO:Importing libraries
2025-10-28 11:07:23,790:INFO:Copying training dataset
2025-10-28 11:07:23,794:INFO:Defining folds
2025-10-28 11:07:23,794:INFO:Declaring metric variables
2025-10-28 11:07:23,794:INFO:Importing untrained model
2025-10-28 11:07:23,794:INFO:Linear Discriminant Analysis Imported successfully
2025-10-28 11:07:23,794:INFO:Starting cross validation
2025-10-28 11:07:23,795:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:23,857:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,857:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,860:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,862:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,863:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,863:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:07:23,900:INFO:Calculating mean and std
2025-10-28 11:07:23,903:INFO:Creating metrics dataframe
2025-10-28 11:07:23,908:INFO:Uploading results into container
2025-10-28 11:07:23,909:INFO:Uploading model into container now
2025-10-28 11:07:23,910:INFO:_master_model_container: 11
2025-10-28 11:07:23,911:INFO:_display_container: 2
2025-10-28 11:07:23,912:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-28 11:07:23,912:INFO:create_model() successfully completed......................................
2025-10-28 11:07:24,046:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:24,046:INFO:Creating metrics dataframe
2025-10-28 11:07:24,049:INFO:Initializing Extra Trees Classifier
2025-10-28 11:07:24,051:INFO:Total runtime is 0.16762837171554568 minutes
2025-10-28 11:07:24,051:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:24,051:INFO:Initializing create_model()
2025-10-28 11:07:24,051:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:24,051:INFO:Checking exceptions
2025-10-28 11:07:24,052:INFO:Importing libraries
2025-10-28 11:07:24,052:INFO:Copying training dataset
2025-10-28 11:07:24,056:INFO:Defining folds
2025-10-28 11:07:24,056:INFO:Declaring metric variables
2025-10-28 11:07:24,056:INFO:Importing untrained model
2025-10-28 11:07:24,056:INFO:Extra Trees Classifier Imported successfully
2025-10-28 11:07:24,056:INFO:Starting cross validation
2025-10-28 11:07:24,057:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:24,391:INFO:Calculating mean and std
2025-10-28 11:07:24,393:INFO:Creating metrics dataframe
2025-10-28 11:07:24,395:INFO:Uploading results into container
2025-10-28 11:07:24,396:INFO:Uploading model into container now
2025-10-28 11:07:24,397:INFO:_master_model_container: 12
2025-10-28 11:07:24,397:INFO:_display_container: 2
2025-10-28 11:07:24,398:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-28 11:07:24,398:INFO:create_model() successfully completed......................................
2025-10-28 11:07:24,532:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:24,532:INFO:Creating metrics dataframe
2025-10-28 11:07:24,540:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 11:07:24,540:INFO:Total runtime is 0.1757723649342855 minutes
2025-10-28 11:07:24,540:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:24,541:INFO:Initializing create_model()
2025-10-28 11:07:24,541:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:24,541:INFO:Checking exceptions
2025-10-28 11:07:24,541:INFO:Importing libraries
2025-10-28 11:07:24,541:INFO:Copying training dataset
2025-10-28 11:07:24,548:INFO:Defining folds
2025-10-28 11:07:24,548:INFO:Declaring metric variables
2025-10-28 11:07:24,549:INFO:Importing untrained model
2025-10-28 11:07:24,550:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 11:07:24,550:INFO:Starting cross validation
2025-10-28 11:07:24,551:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:25,678:INFO:Calculating mean and std
2025-10-28 11:07:25,679:INFO:Creating metrics dataframe
2025-10-28 11:07:25,681:INFO:Uploading results into container
2025-10-28 11:07:25,681:INFO:Uploading model into container now
2025-10-28 11:07:25,682:INFO:_master_model_container: 13
2025-10-28 11:07:25,682:INFO:_display_container: 2
2025-10-28 11:07:25,682:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-28 11:07:25,682:INFO:create_model() successfully completed......................................
2025-10-28 11:07:25,789:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:25,789:INFO:Creating metrics dataframe
2025-10-28 11:07:25,794:INFO:Initializing Dummy Classifier
2025-10-28 11:07:25,795:INFO:Total runtime is 0.19668071667353315 minutes
2025-10-28 11:07:25,795:INFO:SubProcess create_model() called ==================================
2025-10-28 11:07:25,795:INFO:Initializing create_model()
2025-10-28 11:07:25,795:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D350D550>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:25,795:INFO:Checking exceptions
2025-10-28 11:07:25,796:INFO:Importing libraries
2025-10-28 11:07:25,796:INFO:Copying training dataset
2025-10-28 11:07:25,801:INFO:Defining folds
2025-10-28 11:07:25,801:INFO:Declaring metric variables
2025-10-28 11:07:25,801:INFO:Importing untrained model
2025-10-28 11:07:25,801:INFO:Dummy Classifier Imported successfully
2025-10-28 11:07:25,802:INFO:Starting cross validation
2025-10-28 11:07:25,803:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:07:25,861:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,861:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,861:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,866:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,868:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,868:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,870:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,873:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,874:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,875:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:07:25,888:INFO:Calculating mean and std
2025-10-28 11:07:25,890:INFO:Creating metrics dataframe
2025-10-28 11:07:25,894:INFO:Uploading results into container
2025-10-28 11:07:25,895:INFO:Uploading model into container now
2025-10-28 11:07:25,896:INFO:_master_model_container: 14
2025-10-28 11:07:25,896:INFO:_display_container: 2
2025-10-28 11:07:25,897:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-28 11:07:25,897:INFO:create_model() successfully completed......................................
2025-10-28 11:07:26,039:INFO:SubProcess create_model() end ==================================
2025-10-28 11:07:26,039:INFO:Creating metrics dataframe
2025-10-28 11:07:26,043:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 11:07:26,045:INFO:Initializing create_model()
2025-10-28 11:07:26,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:07:26,045:INFO:Checking exceptions
2025-10-28 11:07:26,046:INFO:Importing libraries
2025-10-28 11:07:26,046:INFO:Copying training dataset
2025-10-28 11:07:26,050:INFO:Defining folds
2025-10-28 11:07:26,050:INFO:Declaring metric variables
2025-10-28 11:07:26,050:INFO:Importing untrained model
2025-10-28 11:07:26,050:INFO:Declaring custom model
2025-10-28 11:07:26,052:INFO:Logistic Regression Imported successfully
2025-10-28 11:07:26,053:INFO:Cross validation set to False
2025-10-28 11:07:26,053:INFO:Fitting Model
2025-10-28 11:07:26,083:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:07:26,083:INFO:create_model() successfully completed......................................
2025-10-28 11:07:26,230:INFO:_master_model_container: 14
2025-10-28 11:07:26,230:INFO:_display_container: 2
2025-10-28 11:07:26,231:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:07:26,231:INFO:compare_models() successfully completed......................................
2025-10-28 11:07:26,236:INFO:Initializing plot_model()
2025-10-28 11:07:26,236:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D3AE33D0>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-10-28 11:07:26,236:INFO:Checking exceptions
2025-10-28 11:07:26,236:INFO:Soft dependency imported: streamlit: 1.50.0
2025-10-28 11:07:26,238:INFO:Preloading libraries
2025-10-28 11:07:26,239:INFO:Copying training dataset
2025-10-28 11:07:26,239:INFO:Plot type: feature
2025-10-28 11:07:26,348:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

2025-10-28 11:07:26,348:INFO:Visual Rendered Successfully
2025-10-28 11:07:26,468:INFO:plot_model() successfully completed......................................
2025-10-28 11:09:40,481:INFO:PyCaret ClassificationExperiment
2025-10-28 11:09:40,482:INFO:Logging name: clf-default-name
2025-10-28 11:09:40,482:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-28 11:09:40,482:INFO:version 3.3.2
2025-10-28 11:09:40,482:INFO:Initializing setup()
2025-10-28 11:09:40,482:INFO:self.USI: eaf7
2025-10-28 11:09:40,482:INFO:self._variable_keys: {'X', 'X_test', 'html_param', 'n_jobs_param', 'idx', 'target_param', 'y_train', 'is_multiclass', 'USI', 'gpu_n_jobs_param', 'y_test', 'X_train', 'fold_groups_param', 'exp_name_log', 'pipeline', 'logging_param', 'exp_id', 'memory', 'y', 'fold_generator', '_available_plots', 'seed', 'data', 'fold_shuffle_param', 'gpu_param', 'log_plots_param', '_ml_usecase', 'fix_imbalance'}
2025-10-28 11:09:40,482:INFO:Checking environment
2025-10-28 11:09:40,482:INFO:python_version: 3.11.14
2025-10-28 11:09:40,482:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-28 11:09:40,482:INFO:machine: AMD64
2025-10-28 11:09:40,482:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-28 11:09:40,484:INFO:Memory: svmem(total=16788250624, available=2777448448, percent=83.5, used=14010802176, free=2777448448)
2025-10-28 11:09:40,484:INFO:Physical Core: 12
2025-10-28 11:09:40,484:INFO:Logical Core: 16
2025-10-28 11:09:40,484:INFO:Checking libraries
2025-10-28 11:09:40,484:INFO:System:
2025-10-28 11:09:40,484:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-28 11:09:40,485:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-28 11:09:40,485:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-28 11:09:40,485:INFO:PyCaret required dependencies:
2025-10-28 11:09:40,485:INFO:                 pip: 25.2
2025-10-28 11:09:40,485:INFO:          setuptools: 80.9.0
2025-10-28 11:09:40,485:INFO:             pycaret: 3.3.2
2025-10-28 11:09:40,485:INFO:             IPython: 9.6.0
2025-10-28 11:09:40,485:INFO:          ipywidgets: 8.1.7
2025-10-28 11:09:40,486:INFO:                tqdm: 4.67.1
2025-10-28 11:09:40,486:INFO:               numpy: 1.26.4
2025-10-28 11:09:40,486:INFO:              pandas: 2.1.4
2025-10-28 11:09:40,486:INFO:              jinja2: 3.1.6
2025-10-28 11:09:40,486:INFO:               scipy: 1.11.4
2025-10-28 11:09:40,486:INFO:              joblib: 1.3.2
2025-10-28 11:09:40,486:INFO:             sklearn: 1.4.2
2025-10-28 11:09:40,488:INFO:                pyod: 2.0.5
2025-10-28 11:09:40,488:INFO:            imblearn: 0.14.0
2025-10-28 11:09:40,488:INFO:   category_encoders: 2.7.0
2025-10-28 11:09:40,488:INFO:            lightgbm: 4.6.0
2025-10-28 11:09:40,489:INFO:               numba: 0.62.1
2025-10-28 11:09:40,489:INFO:            requests: 2.32.5
2025-10-28 11:09:40,489:INFO:          matplotlib: 3.10.7
2025-10-28 11:09:40,489:INFO:          scikitplot: 0.3.7
2025-10-28 11:09:40,489:INFO:         yellowbrick: 1.5
2025-10-28 11:09:40,489:INFO:              plotly: 6.3.1
2025-10-28 11:09:40,489:INFO:    plotly-resampler: Not installed
2025-10-28 11:09:40,491:INFO:             kaleido: 0.2.1
2025-10-28 11:09:40,491:INFO:           schemdraw: 0.15
2025-10-28 11:09:40,491:INFO:         statsmodels: 0.14.5
2025-10-28 11:09:40,491:INFO:              sktime: 0.26.0
2025-10-28 11:09:40,492:INFO:               tbats: 1.1.3
2025-10-28 11:09:40,492:INFO:            pmdarima: 2.0.4
2025-10-28 11:09:40,492:INFO:              psutil: 7.1.1
2025-10-28 11:09:40,492:INFO:          markupsafe: 3.0.3
2025-10-28 11:09:40,492:INFO:             pickle5: Not installed
2025-10-28 11:09:40,492:INFO:         cloudpickle: 3.1.1
2025-10-28 11:09:40,492:INFO:         deprecation: 2.1.0
2025-10-28 11:09:40,492:INFO:              xxhash: 3.6.0
2025-10-28 11:09:40,493:INFO:           wurlitzer: 3.1.1
2025-10-28 11:09:40,493:INFO:PyCaret optional dependencies:
2025-10-28 11:09:40,493:INFO:                shap: Not installed
2025-10-28 11:09:40,493:INFO:           interpret: Not installed
2025-10-28 11:09:40,494:INFO:                umap: 0.5.9.post2
2025-10-28 11:09:40,494:INFO:     ydata_profiling: Not installed
2025-10-28 11:09:40,494:INFO:  explainerdashboard: Not installed
2025-10-28 11:09:40,494:INFO:             autoviz: Not installed
2025-10-28 11:09:40,494:INFO:           fairlearn: Not installed
2025-10-28 11:09:40,494:INFO:          deepchecks: Not installed
2025-10-28 11:09:40,494:INFO:             xgboost: Not installed
2025-10-28 11:09:40,494:INFO:            catboost: Not installed
2025-10-28 11:09:40,494:INFO:              kmodes: Not installed
2025-10-28 11:09:40,494:INFO:             mlxtend: Not installed
2025-10-28 11:09:40,494:INFO:       statsforecast: Not installed
2025-10-28 11:09:40,494:INFO:        tune_sklearn: Not installed
2025-10-28 11:09:40,494:INFO:                 ray: Not installed
2025-10-28 11:09:40,494:INFO:            hyperopt: Not installed
2025-10-28 11:09:40,494:INFO:              optuna: Not installed
2025-10-28 11:09:40,494:INFO:               skopt: Not installed
2025-10-28 11:09:40,494:INFO:              mlflow: Not installed
2025-10-28 11:09:40,494:INFO:              gradio: Not installed
2025-10-28 11:09:40,494:INFO:             fastapi: Not installed
2025-10-28 11:09:40,494:INFO:             uvicorn: Not installed
2025-10-28 11:09:40,494:INFO:              m2cgen: Not installed
2025-10-28 11:09:40,494:INFO:           evidently: Not installed
2025-10-28 11:09:40,494:INFO:               fugue: Not installed
2025-10-28 11:09:40,494:INFO:           streamlit: 1.50.0
2025-10-28 11:09:40,494:INFO:             prophet: Not installed
2025-10-28 11:09:40,494:INFO:None
2025-10-28 11:09:40,494:INFO:Set up data.
2025-10-28 11:09:40,497:INFO:Set up folding strategy.
2025-10-28 11:09:40,497:INFO:Set up train/test split.
2025-10-28 11:09:40,505:INFO:Set up index.
2025-10-28 11:09:40,506:INFO:Assigning column types.
2025-10-28 11:09:40,512:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-28 11:09:40,639:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,641:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,699:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,700:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,777:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,778:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,811:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,811:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,812:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-28 11:09:40,870:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,901:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,901:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,959:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-28 11:09:40,998:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,998:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:40,998:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-28 11:09:41,085:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,085:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,184:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,184:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,185:INFO:Preparing preprocessing pipeline...
2025-10-28 11:09:41,186:INFO:Set up simple imputation.
2025-10-28 11:09:41,187:INFO:Set up column name cleaning.
2025-10-28 11:09:41,211:INFO:Finished creating preprocessing pipeline.
2025-10-28 11:09:41,217:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-28 11:09:41,217:INFO:Creating final display dataframe.
2025-10-28 11:09:41,299:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                -1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              eaf7
2025-10-28 11:09:41,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,448:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,584:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,584:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-28 11:09:41,586:INFO:setup() successfully completed in 1.11s...............
2025-10-28 11:09:41,587:INFO:Initializing compare_models()
2025-10-28 11:09:41,587:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=1, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 1, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-28 11:09:41,587:INFO:Checking exceptions
2025-10-28 11:09:41,591:INFO:Preparing display monitor
2025-10-28 11:09:41,594:INFO:Initializing Logistic Regression
2025-10-28 11:09:41,594:INFO:Total runtime is 0.0 minutes
2025-10-28 11:09:41,594:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:41,596:INFO:Initializing create_model()
2025-10-28 11:09:41,596:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:41,596:INFO:Checking exceptions
2025-10-28 11:09:41,596:INFO:Importing libraries
2025-10-28 11:09:41,596:INFO:Copying training dataset
2025-10-28 11:09:41,598:INFO:Defining folds
2025-10-28 11:09:41,599:INFO:Declaring metric variables
2025-10-28 11:09:41,599:INFO:Importing untrained model
2025-10-28 11:09:41,600:INFO:Logistic Regression Imported successfully
2025-10-28 11:09:41,600:INFO:Starting cross validation
2025-10-28 11:09:41,601:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:41,670:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,670:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,671:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,675:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,675:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,681:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,685:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,695:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,696:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:41,720:INFO:Calculating mean and std
2025-10-28 11:09:41,721:INFO:Creating metrics dataframe
2025-10-28 11:09:41,725:INFO:Uploading results into container
2025-10-28 11:09:41,726:INFO:Uploading model into container now
2025-10-28 11:09:41,727:INFO:_master_model_container: 1
2025-10-28 11:09:41,727:INFO:_display_container: 2
2025-10-28 11:09:41,728:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:09:41,728:INFO:create_model() successfully completed......................................
2025-10-28 11:09:41,872:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:41,872:INFO:Creating metrics dataframe
2025-10-28 11:09:41,874:INFO:Initializing K Neighbors Classifier
2025-10-28 11:09:41,874:INFO:Total runtime is 0.004668609301249186 minutes
2025-10-28 11:09:41,874:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:41,875:INFO:Initializing create_model()
2025-10-28 11:09:41,875:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:41,875:INFO:Checking exceptions
2025-10-28 11:09:41,875:INFO:Importing libraries
2025-10-28 11:09:41,875:INFO:Copying training dataset
2025-10-28 11:09:41,878:INFO:Defining folds
2025-10-28 11:09:41,879:INFO:Declaring metric variables
2025-10-28 11:09:41,879:INFO:Importing untrained model
2025-10-28 11:09:41,879:INFO:K Neighbors Classifier Imported successfully
2025-10-28 11:09:41,880:INFO:Starting cross validation
2025-10-28 11:09:41,881:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,008:INFO:Calculating mean and std
2025-10-28 11:09:42,009:INFO:Creating metrics dataframe
2025-10-28 11:09:42,012:INFO:Uploading results into container
2025-10-28 11:09:42,013:INFO:Uploading model into container now
2025-10-28 11:09:42,013:INFO:_master_model_container: 2
2025-10-28 11:09:42,014:INFO:_display_container: 2
2025-10-28 11:09:42,014:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=-1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-28 11:09:42,014:INFO:create_model() successfully completed......................................
2025-10-28 11:09:42,144:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:42,145:INFO:Creating metrics dataframe
2025-10-28 11:09:42,153:INFO:Initializing Naive Bayes
2025-10-28 11:09:42,153:INFO:Total runtime is 0.009309331576029459 minutes
2025-10-28 11:09:42,154:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:42,154:INFO:Initializing create_model()
2025-10-28 11:09:42,155:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:42,155:INFO:Checking exceptions
2025-10-28 11:09:42,155:INFO:Importing libraries
2025-10-28 11:09:42,155:INFO:Copying training dataset
2025-10-28 11:09:42,163:INFO:Defining folds
2025-10-28 11:09:42,163:INFO:Declaring metric variables
2025-10-28 11:09:42,163:INFO:Importing untrained model
2025-10-28 11:09:42,164:INFO:Naive Bayes Imported successfully
2025-10-28 11:09:42,164:INFO:Starting cross validation
2025-10-28 11:09:42,165:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,295:INFO:Calculating mean and std
2025-10-28 11:09:42,297:INFO:Creating metrics dataframe
2025-10-28 11:09:42,302:INFO:Uploading results into container
2025-10-28 11:09:42,302:INFO:Uploading model into container now
2025-10-28 11:09:42,304:INFO:_master_model_container: 3
2025-10-28 11:09:42,304:INFO:_display_container: 2
2025-10-28 11:09:42,305:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-28 11:09:42,305:INFO:create_model() successfully completed......................................
2025-10-28 11:09:42,449:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:42,450:INFO:Creating metrics dataframe
2025-10-28 11:09:42,458:INFO:Initializing Decision Tree Classifier
2025-10-28 11:09:42,458:INFO:Total runtime is 0.014404563109079997 minutes
2025-10-28 11:09:42,459:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:42,459:INFO:Initializing create_model()
2025-10-28 11:09:42,459:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:42,459:INFO:Checking exceptions
2025-10-28 11:09:42,461:INFO:Importing libraries
2025-10-28 11:09:42,461:INFO:Copying training dataset
2025-10-28 11:09:42,467:INFO:Defining folds
2025-10-28 11:09:42,468:INFO:Declaring metric variables
2025-10-28 11:09:42,468:INFO:Importing untrained model
2025-10-28 11:09:42,468:INFO:Decision Tree Classifier Imported successfully
2025-10-28 11:09:42,469:INFO:Starting cross validation
2025-10-28 11:09:42,470:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,596:INFO:Calculating mean and std
2025-10-28 11:09:42,598:INFO:Creating metrics dataframe
2025-10-28 11:09:42,601:INFO:Uploading results into container
2025-10-28 11:09:42,602:INFO:Uploading model into container now
2025-10-28 11:09:42,604:INFO:_master_model_container: 4
2025-10-28 11:09:42,604:INFO:_display_container: 2
2025-10-28 11:09:42,605:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-28 11:09:42,605:INFO:create_model() successfully completed......................................
2025-10-28 11:09:42,756:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:42,756:INFO:Creating metrics dataframe
2025-10-28 11:09:42,761:INFO:Initializing SVM - Linear Kernel
2025-10-28 11:09:42,762:INFO:Total runtime is 0.019458580017089843 minutes
2025-10-28 11:09:42,762:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:42,763:INFO:Initializing create_model()
2025-10-28 11:09:42,763:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:42,763:INFO:Checking exceptions
2025-10-28 11:09:42,763:INFO:Importing libraries
2025-10-28 11:09:42,763:INFO:Copying training dataset
2025-10-28 11:09:42,768:INFO:Defining folds
2025-10-28 11:09:42,768:INFO:Declaring metric variables
2025-10-28 11:09:42,768:INFO:Importing untrained model
2025-10-28 11:09:42,769:INFO:SVM - Linear Kernel Imported successfully
2025-10-28 11:09:42,769:INFO:Starting cross validation
2025-10-28 11:09:42,771:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:42,864:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,864:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,865:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,867:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,867:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,868:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,870:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,871:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,871:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,873:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,877:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,879:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,881:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:42,884:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,887:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,888:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:42,902:INFO:Calculating mean and std
2025-10-28 11:09:42,903:INFO:Creating metrics dataframe
2025-10-28 11:09:42,905:INFO:Uploading results into container
2025-10-28 11:09:42,906:INFO:Uploading model into container now
2025-10-28 11:09:42,906:INFO:_master_model_container: 5
2025-10-28 11:09:42,906:INFO:_display_container: 2
2025-10-28 11:09:42,907:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=-1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-28 11:09:42,907:INFO:create_model() successfully completed......................................
2025-10-28 11:09:43,029:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:43,029:INFO:Creating metrics dataframe
2025-10-28 11:09:43,036:INFO:Initializing Ridge Classifier
2025-10-28 11:09:43,036:INFO:Total runtime is 0.02403590679168701 minutes
2025-10-28 11:09:43,037:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:43,037:INFO:Initializing create_model()
2025-10-28 11:09:43,038:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:43,038:INFO:Checking exceptions
2025-10-28 11:09:43,038:INFO:Importing libraries
2025-10-28 11:09:43,038:INFO:Copying training dataset
2025-10-28 11:09:43,046:INFO:Defining folds
2025-10-28 11:09:43,046:INFO:Declaring metric variables
2025-10-28 11:09:43,046:INFO:Importing untrained model
2025-10-28 11:09:43,046:INFO:Ridge Classifier Imported successfully
2025-10-28 11:09:43,047:INFO:Starting cross validation
2025-10-28 11:09:43,048:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:43,108:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,109:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,109:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,110:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,110:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,114:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,117:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,118:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,129:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,135:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,154:INFO:Calculating mean and std
2025-10-28 11:09:43,155:INFO:Creating metrics dataframe
2025-10-28 11:09:43,160:INFO:Uploading results into container
2025-10-28 11:09:43,161:INFO:Uploading model into container now
2025-10-28 11:09:43,162:INFO:_master_model_container: 6
2025-10-28 11:09:43,162:INFO:_display_container: 2
2025-10-28 11:09:43,162:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-28 11:09:43,162:INFO:create_model() successfully completed......................................
2025-10-28 11:09:43,306:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:43,306:INFO:Creating metrics dataframe
2025-10-28 11:09:43,309:INFO:Initializing Random Forest Classifier
2025-10-28 11:09:43,309:INFO:Total runtime is 0.028588700294494628 minutes
2025-10-28 11:09:43,310:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:43,310:INFO:Initializing create_model()
2025-10-28 11:09:43,310:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:43,311:INFO:Checking exceptions
2025-10-28 11:09:43,311:INFO:Importing libraries
2025-10-28 11:09:43,311:INFO:Copying training dataset
2025-10-28 11:09:43,321:INFO:Defining folds
2025-10-28 11:09:43,321:INFO:Declaring metric variables
2025-10-28 11:09:43,322:INFO:Importing untrained model
2025-10-28 11:09:43,322:INFO:Random Forest Classifier Imported successfully
2025-10-28 11:09:43,322:INFO:Starting cross validation
2025-10-28 11:09:43,324:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:43,683:INFO:Calculating mean and std
2025-10-28 11:09:43,684:INFO:Creating metrics dataframe
2025-10-28 11:09:43,686:INFO:Uploading results into container
2025-10-28 11:09:43,686:INFO:Uploading model into container now
2025-10-28 11:09:43,687:INFO:_master_model_container: 7
2025-10-28 11:09:43,687:INFO:_display_container: 2
2025-10-28 11:09:43,688:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=-1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-28 11:09:43,688:INFO:create_model() successfully completed......................................
2025-10-28 11:09:43,816:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:43,816:INFO:Creating metrics dataframe
2025-10-28 11:09:43,822:INFO:Initializing Quadratic Discriminant Analysis
2025-10-28 11:09:43,822:INFO:Total runtime is 0.0371234933535258 minutes
2025-10-28 11:09:43,823:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:43,824:INFO:Initializing create_model()
2025-10-28 11:09:43,824:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:43,825:INFO:Checking exceptions
2025-10-28 11:09:43,825:INFO:Importing libraries
2025-10-28 11:09:43,825:INFO:Copying training dataset
2025-10-28 11:09:43,831:INFO:Defining folds
2025-10-28 11:09:43,831:INFO:Declaring metric variables
2025-10-28 11:09:43,832:INFO:Importing untrained model
2025-10-28 11:09:43,832:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-28 11:09:43,832:INFO:Starting cross validation
2025-10-28 11:09:43,834:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:43,916:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,918:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,919:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,923:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,931:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,934:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,936:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,936:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,937:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,944:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:43,964:INFO:Calculating mean and std
2025-10-28 11:09:43,966:INFO:Creating metrics dataframe
2025-10-28 11:09:43,969:INFO:Uploading results into container
2025-10-28 11:09:43,970:INFO:Uploading model into container now
2025-10-28 11:09:43,970:INFO:_master_model_container: 8
2025-10-28 11:09:43,971:INFO:_display_container: 2
2025-10-28 11:09:43,971:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-28 11:09:43,971:INFO:create_model() successfully completed......................................
2025-10-28 11:09:44,090:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:44,090:INFO:Creating metrics dataframe
2025-10-28 11:09:44,094:INFO:Initializing Ada Boost Classifier
2025-10-28 11:09:44,094:INFO:Total runtime is 0.04166093667348226 minutes
2025-10-28 11:09:44,094:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:44,095:INFO:Initializing create_model()
2025-10-28 11:09:44,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:44,095:INFO:Checking exceptions
2025-10-28 11:09:44,095:INFO:Importing libraries
2025-10-28 11:09:44,095:INFO:Copying training dataset
2025-10-28 11:09:44,098:INFO:Defining folds
2025-10-28 11:09:44,098:INFO:Declaring metric variables
2025-10-28 11:09:44,099:INFO:Importing untrained model
2025-10-28 11:09:44,099:INFO:Ada Boost Classifier Imported successfully
2025-10-28 11:09:44,099:INFO:Starting cross validation
2025-10-28 11:09:44,100:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:44,122:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,127:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,129:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,134:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,136:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,139:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,142:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,145:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,147:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,148:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-28 11:09:44,304:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,311:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,313:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,314:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,315:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,322:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,322:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,324:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,325:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,330:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,351:INFO:Calculating mean and std
2025-10-28 11:09:44,352:INFO:Creating metrics dataframe
2025-10-28 11:09:44,354:INFO:Uploading results into container
2025-10-28 11:09:44,355:INFO:Uploading model into container now
2025-10-28 11:09:44,355:INFO:_master_model_container: 9
2025-10-28 11:09:44,356:INFO:_display_container: 2
2025-10-28 11:09:44,356:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-28 11:09:44,356:INFO:create_model() successfully completed......................................
2025-10-28 11:09:44,497:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:44,497:INFO:Creating metrics dataframe
2025-10-28 11:09:44,504:INFO:Initializing Gradient Boosting Classifier
2025-10-28 11:09:44,504:INFO:Total runtime is 0.04849430322647095 minutes
2025-10-28 11:09:44,505:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:44,505:INFO:Initializing create_model()
2025-10-28 11:09:44,505:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:44,505:INFO:Checking exceptions
2025-10-28 11:09:44,505:INFO:Importing libraries
2025-10-28 11:09:44,506:INFO:Copying training dataset
2025-10-28 11:09:44,512:INFO:Defining folds
2025-10-28 11:09:44,512:INFO:Declaring metric variables
2025-10-28 11:09:44,512:INFO:Importing untrained model
2025-10-28 11:09:44,512:INFO:Gradient Boosting Classifier Imported successfully
2025-10-28 11:09:44,514:INFO:Starting cross validation
2025-10-28 11:09:44,515:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:44,967:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,974:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,979:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,982:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,990:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:44,995:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,001:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,001:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,034:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,057:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,076:INFO:Calculating mean and std
2025-10-28 11:09:45,078:INFO:Creating metrics dataframe
2025-10-28 11:09:45,081:INFO:Uploading results into container
2025-10-28 11:09:45,082:INFO:Uploading model into container now
2025-10-28 11:09:45,082:INFO:_master_model_container: 10
2025-10-28 11:09:45,082:INFO:_display_container: 2
2025-10-28 11:09:45,084:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-28 11:09:45,084:INFO:create_model() successfully completed......................................
2025-10-28 11:09:45,237:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:45,237:INFO:Creating metrics dataframe
2025-10-28 11:09:45,242:INFO:Initializing Linear Discriminant Analysis
2025-10-28 11:09:45,242:INFO:Total runtime is 0.060796531041463216 minutes
2025-10-28 11:09:45,242:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:45,242:INFO:Initializing create_model()
2025-10-28 11:09:45,242:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:45,242:INFO:Checking exceptions
2025-10-28 11:09:45,242:INFO:Importing libraries
2025-10-28 11:09:45,242:INFO:Copying training dataset
2025-10-28 11:09:45,247:INFO:Defining folds
2025-10-28 11:09:45,247:INFO:Declaring metric variables
2025-10-28 11:09:45,247:INFO:Importing untrained model
2025-10-28 11:09:45,247:INFO:Linear Discriminant Analysis Imported successfully
2025-10-28 11:09:45,247:INFO:Starting cross validation
2025-10-28 11:09:45,248:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:45,300:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,300:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,301:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,302:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,303:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,304:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,306:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,307:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,310:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,310:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-28 11:09:45,334:INFO:Calculating mean and std
2025-10-28 11:09:45,336:INFO:Creating metrics dataframe
2025-10-28 11:09:45,340:INFO:Uploading results into container
2025-10-28 11:09:45,341:INFO:Uploading model into container now
2025-10-28 11:09:45,342:INFO:_master_model_container: 11
2025-10-28 11:09:45,342:INFO:_display_container: 2
2025-10-28 11:09:45,342:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-28 11:09:45,344:INFO:create_model() successfully completed......................................
2025-10-28 11:09:45,479:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:45,480:INFO:Creating metrics dataframe
2025-10-28 11:09:45,487:INFO:Initializing Extra Trees Classifier
2025-10-28 11:09:45,488:INFO:Total runtime is 0.06489071846008301 minutes
2025-10-28 11:09:45,488:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:45,488:INFO:Initializing create_model()
2025-10-28 11:09:45,489:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:45,489:INFO:Checking exceptions
2025-10-28 11:09:45,489:INFO:Importing libraries
2025-10-28 11:09:45,490:INFO:Copying training dataset
2025-10-28 11:09:45,495:INFO:Defining folds
2025-10-28 11:09:45,495:INFO:Declaring metric variables
2025-10-28 11:09:45,495:INFO:Importing untrained model
2025-10-28 11:09:45,496:INFO:Extra Trees Classifier Imported successfully
2025-10-28 11:09:45,496:INFO:Starting cross validation
2025-10-28 11:09:45,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:45,800:INFO:Calculating mean and std
2025-10-28 11:09:45,801:INFO:Creating metrics dataframe
2025-10-28 11:09:45,805:INFO:Uploading results into container
2025-10-28 11:09:45,805:INFO:Uploading model into container now
2025-10-28 11:09:45,806:INFO:_master_model_container: 12
2025-10-28 11:09:45,806:INFO:_display_container: 2
2025-10-28 11:09:45,807:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=-1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-28 11:09:45,807:INFO:create_model() successfully completed......................................
2025-10-28 11:09:45,938:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:45,938:INFO:Creating metrics dataframe
2025-10-28 11:09:45,943:INFO:Initializing Light Gradient Boosting Machine
2025-10-28 11:09:45,943:INFO:Total runtime is 0.07247526248296103 minutes
2025-10-28 11:09:45,943:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:45,944:INFO:Initializing create_model()
2025-10-28 11:09:45,944:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:45,944:INFO:Checking exceptions
2025-10-28 11:09:45,944:INFO:Importing libraries
2025-10-28 11:09:45,944:INFO:Copying training dataset
2025-10-28 11:09:45,950:INFO:Defining folds
2025-10-28 11:09:45,950:INFO:Declaring metric variables
2025-10-28 11:09:45,950:INFO:Importing untrained model
2025-10-28 11:09:45,951:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-28 11:09:45,952:INFO:Starting cross validation
2025-10-28 11:09:45,952:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:46,979:INFO:Calculating mean and std
2025-10-28 11:09:46,979:INFO:Creating metrics dataframe
2025-10-28 11:09:46,981:INFO:Uploading results into container
2025-10-28 11:09:46,982:INFO:Uploading model into container now
2025-10-28 11:09:46,982:INFO:_master_model_container: 13
2025-10-28 11:09:46,982:INFO:_display_container: 2
2025-10-28 11:09:46,984:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=-1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-28 11:09:46,984:INFO:create_model() successfully completed......................................
2025-10-28 11:09:47,089:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:47,089:INFO:Creating metrics dataframe
2025-10-28 11:09:47,094:INFO:Initializing Dummy Classifier
2025-10-28 11:09:47,095:INFO:Total runtime is 0.09168450435002645 minutes
2025-10-28 11:09:47,095:INFO:SubProcess create_model() called ==================================
2025-10-28 11:09:47,095:INFO:Initializing create_model()
2025-10-28 11:09:47,095:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000218D1841D90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:47,095:INFO:Checking exceptions
2025-10-28 11:09:47,095:INFO:Importing libraries
2025-10-28 11:09:47,096:INFO:Copying training dataset
2025-10-28 11:09:47,104:INFO:Defining folds
2025-10-28 11:09:47,104:INFO:Declaring metric variables
2025-10-28 11:09:47,105:INFO:Importing untrained model
2025-10-28 11:09:47,105:INFO:Dummy Classifier Imported successfully
2025-10-28 11:09:47,105:INFO:Starting cross validation
2025-10-28 11:09:47,107:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=-1
2025-10-28 11:09:47,180:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,182:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,189:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,191:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,192:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,194:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,201:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,206:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,206:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,208:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-28 11:09:47,220:INFO:Calculating mean and std
2025-10-28 11:09:47,221:INFO:Creating metrics dataframe
2025-10-28 11:09:47,224:INFO:Uploading results into container
2025-10-28 11:09:47,225:INFO:Uploading model into container now
2025-10-28 11:09:47,225:INFO:_master_model_container: 14
2025-10-28 11:09:47,226:INFO:_display_container: 2
2025-10-28 11:09:47,226:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-28 11:09:47,226:INFO:create_model() successfully completed......................................
2025-10-28 11:09:47,361:INFO:SubProcess create_model() end ==================================
2025-10-28 11:09:47,361:INFO:Creating metrics dataframe
2025-10-28 11:09:47,368:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-28 11:09:47,372:INFO:Initializing create_model()
2025-10-28 11:09:47,372:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-28 11:09:47,372:INFO:Checking exceptions
2025-10-28 11:09:47,374:INFO:Importing libraries
2025-10-28 11:09:47,374:INFO:Copying training dataset
2025-10-28 11:09:47,379:INFO:Defining folds
2025-10-28 11:09:47,379:INFO:Declaring metric variables
2025-10-28 11:09:47,379:INFO:Importing untrained model
2025-10-28 11:09:47,379:INFO:Declaring custom model
2025-10-28 11:09:47,380:INFO:Logistic Regression Imported successfully
2025-10-28 11:09:47,382:INFO:Cross validation set to False
2025-10-28 11:09:47,382:INFO:Fitting Model
2025-10-28 11:09:47,422:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:09:47,422:INFO:create_model() successfully completed......................................
2025-10-28 11:09:47,561:INFO:_master_model_container: 14
2025-10-28 11:09:47,561:INFO:_display_container: 2
2025-10-28 11:09:47,562:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-28 11:09:47,562:INFO:compare_models() successfully completed......................................
2025-10-28 11:09:47,567:INFO:Initializing plot_model()
2025-10-28 11:09:47,567:INFO:plot_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000218D36CD510>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), plot=feature, scale=1, save=False, fold=None, fit_kwargs=None, plot_kwargs=None, groups=None, feature_name=None, label=False, verbose=True, system=True, display=None, display_format=streamlit)
2025-10-28 11:09:47,567:INFO:Checking exceptions
2025-10-28 11:09:47,567:INFO:Soft dependency imported: streamlit: 1.50.0
2025-10-28 11:09:47,568:INFO:Preloading libraries
2025-10-28 11:09:47,569:INFO:Copying training dataset
2025-10-28 11:09:47,569:INFO:Plot type: feature
2025-10-28 11:09:47,666:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\tabular_experiment.py:1867: UserWarning: FigureCanvasAgg is non-interactive, and thus cannot be shown
  plt.show()

2025-10-28 11:09:47,666:INFO:Visual Rendered Successfully
2025-10-28 11:09:47,834:INFO:plot_model() successfully completed......................................
