2025-10-29 12:26:01,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-29 12:26:01,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-29 12:26:01,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-29 12:26:01,049:WARNING:
'cuml' is a soft dependency and not included in the pycaret installation. Please run: `pip install cuml` to install.
2025-10-29 12:26:17,672:INFO:PyCaret ClassificationExperiment
2025-10-29 12:26:17,672:INFO:Logging name: clf-default-name
2025-10-29 12:26:17,673:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-29 12:26:17,673:INFO:version 3.3.2
2025-10-29 12:26:17,673:INFO:Initializing setup()
2025-10-29 12:26:17,673:INFO:self.USI: 43a4
2025-10-29 12:26:17,675:INFO:self._variable_keys: {'gpu_param', 'target_param', 'logging_param', 'y_train', 'exp_name_log', '_ml_usecase', 'X', 'fix_imbalance', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'seed', '_available_plots', 'y', 'fold_generator', 'USI', 'is_multiclass', 'exp_id', 'pipeline', 'n_jobs_param', 'fold_groups_param', 'memory', 'idx', 'X_train', 'X_test', 'html_param', 'data', 'log_plots_param'}
2025-10-29 12:26:17,675:INFO:Checking environment
2025-10-29 12:26:17,675:INFO:python_version: 3.11.14
2025-10-29 12:26:17,675:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-29 12:26:17,675:INFO:machine: AMD64
2025-10-29 12:26:17,692:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-29 12:26:17,692:INFO:Memory: svmem(total=16788250624, available=3617267712, percent=78.5, used=13170982912, free=3617267712)
2025-10-29 12:26:17,692:INFO:Physical Core: 12
2025-10-29 12:26:17,692:INFO:Logical Core: 16
2025-10-29 12:26:17,692:INFO:Checking libraries
2025-10-29 12:26:17,692:INFO:System:
2025-10-29 12:26:17,692:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-29 12:26:17,692:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-29 12:26:17,692:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-29 12:26:17,692:INFO:PyCaret required dependencies:
2025-10-29 12:26:17,692:INFO:                 pip: 25.2
2025-10-29 12:26:17,692:INFO:          setuptools: 80.9.0
2025-10-29 12:26:17,692:INFO:             pycaret: 3.3.2
2025-10-29 12:26:17,692:INFO:             IPython: 9.6.0
2025-10-29 12:26:17,692:INFO:          ipywidgets: 8.1.7
2025-10-29 12:26:17,692:INFO:                tqdm: 4.67.1
2025-10-29 12:26:17,692:INFO:               numpy: 1.26.4
2025-10-29 12:26:17,692:INFO:              pandas: 2.1.4
2025-10-29 12:26:17,692:INFO:              jinja2: 3.1.6
2025-10-29 12:26:17,692:INFO:               scipy: 1.11.4
2025-10-29 12:26:17,692:INFO:              joblib: 1.3.2
2025-10-29 12:26:17,692:INFO:             sklearn: 1.4.2
2025-10-29 12:26:17,692:INFO:                pyod: 2.0.5
2025-10-29 12:26:17,692:INFO:            imblearn: 0.14.0
2025-10-29 12:26:17,692:INFO:   category_encoders: 2.7.0
2025-10-29 12:26:17,692:INFO:            lightgbm: 4.6.0
2025-10-29 12:26:17,692:INFO:               numba: 0.62.1
2025-10-29 12:26:17,692:INFO:            requests: 2.32.5
2025-10-29 12:26:17,692:INFO:          matplotlib: 3.10.7
2025-10-29 12:26:17,692:INFO:          scikitplot: 0.3.7
2025-10-29 12:26:17,692:INFO:         yellowbrick: 1.5
2025-10-29 12:26:17,692:INFO:              plotly: 6.3.1
2025-10-29 12:26:17,692:INFO:    plotly-resampler: Not installed
2025-10-29 12:26:17,692:INFO:             kaleido: 0.2.1
2025-10-29 12:26:17,692:INFO:           schemdraw: 0.15
2025-10-29 12:26:17,692:INFO:         statsmodels: 0.14.5
2025-10-29 12:26:17,692:INFO:              sktime: 0.26.0
2025-10-29 12:26:17,692:INFO:               tbats: 1.1.3
2025-10-29 12:26:17,692:INFO:            pmdarima: 2.0.4
2025-10-29 12:26:17,692:INFO:              psutil: 7.1.1
2025-10-29 12:26:17,692:INFO:          markupsafe: 3.0.3
2025-10-29 12:26:17,692:INFO:             pickle5: Not installed
2025-10-29 12:26:17,692:INFO:         cloudpickle: 3.1.1
2025-10-29 12:26:17,692:INFO:         deprecation: 2.1.0
2025-10-29 12:26:17,692:INFO:              xxhash: 3.6.0
2025-10-29 12:26:17,692:INFO:           wurlitzer: 3.1.1
2025-10-29 12:26:17,692:INFO:PyCaret optional dependencies:
2025-10-29 12:26:17,718:INFO:                shap: Not installed
2025-10-29 12:26:17,718:INFO:           interpret: Not installed
2025-10-29 12:26:17,718:INFO:                umap: 0.5.9.post2
2025-10-29 12:26:17,718:INFO:     ydata_profiling: Not installed
2025-10-29 12:26:17,718:INFO:  explainerdashboard: Not installed
2025-10-29 12:26:17,718:INFO:             autoviz: Not installed
2025-10-29 12:26:17,718:INFO:           fairlearn: Not installed
2025-10-29 12:26:17,718:INFO:          deepchecks: Not installed
2025-10-29 12:26:17,718:INFO:             xgboost: Not installed
2025-10-29 12:26:17,718:INFO:            catboost: Not installed
2025-10-29 12:26:17,718:INFO:              kmodes: Not installed
2025-10-29 12:26:17,718:INFO:             mlxtend: Not installed
2025-10-29 12:26:17,718:INFO:       statsforecast: Not installed
2025-10-29 12:26:17,718:INFO:        tune_sklearn: Not installed
2025-10-29 12:26:17,718:INFO:                 ray: Not installed
2025-10-29 12:26:17,718:INFO:            hyperopt: Not installed
2025-10-29 12:26:17,720:INFO:              optuna: Not installed
2025-10-29 12:26:17,720:INFO:               skopt: Not installed
2025-10-29 12:26:17,720:INFO:              mlflow: Not installed
2025-10-29 12:26:17,720:INFO:              gradio: Not installed
2025-10-29 12:26:17,720:INFO:             fastapi: Not installed
2025-10-29 12:26:17,720:INFO:             uvicorn: Not installed
2025-10-29 12:26:17,720:INFO:              m2cgen: Not installed
2025-10-29 12:26:17,720:INFO:           evidently: Not installed
2025-10-29 12:26:17,720:INFO:               fugue: Not installed
2025-10-29 12:26:17,720:INFO:           streamlit: 1.50.0
2025-10-29 12:26:17,720:INFO:             prophet: Not installed
2025-10-29 12:26:17,720:INFO:None
2025-10-29 12:26:17,720:INFO:Set up data.
2025-10-29 12:26:17,722:INFO:Set up folding strategy.
2025-10-29 12:26:17,722:INFO:Set up train/test split.
2025-10-29 12:26:17,736:INFO:Set up index.
2025-10-29 12:26:17,736:INFO:Assigning column types.
2025-10-29 12:26:17,742:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-29 12:26:17,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:26:17,832:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:26:17,902:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,062:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,142:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:26:18,142:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:26:18,202:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,202:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,204:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-29 12:26:18,295:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:26:18,342:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,342:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,430:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:26:18,517:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,517:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,522:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-29 12:26:18,665:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,665:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,789:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,792:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:18,794:INFO:Preparing preprocessing pipeline...
2025-10-29 12:26:18,802:INFO:Set up simple imputation.
2025-10-29 12:26:18,802:INFO:Set up column name cleaning.
2025-10-29 12:26:18,855:INFO:Finished creating preprocessing pipeline.
2025-10-29 12:26:18,863:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-29 12:26:18,863:INFO:Creating final display dataframe.
2025-10-29 12:26:19,018:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                 1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              43a4
2025-10-29 12:26:19,154:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:19,154:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:19,287:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:19,288:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:26:19,290:INFO:setup() successfully completed in 1.63s...............
2025-10-29 12:26:19,290:INFO:Initializing compare_models()
2025-10-29 12:26:19,292:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-29 12:26:19,292:INFO:Checking exceptions
2025-10-29 12:26:19,300:INFO:Preparing display monitor
2025-10-29 12:26:19,310:INFO:Initializing Logistic Regression
2025-10-29 12:26:19,310:INFO:Total runtime is 0.0 minutes
2025-10-29 12:26:19,310:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:19,311:INFO:Initializing create_model()
2025-10-29 12:26:19,311:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:19,311:INFO:Checking exceptions
2025-10-29 12:26:19,311:INFO:Importing libraries
2025-10-29 12:26:19,311:INFO:Copying training dataset
2025-10-29 12:26:19,315:INFO:Defining folds
2025-10-29 12:26:19,316:INFO:Declaring metric variables
2025-10-29 12:26:19,316:INFO:Importing untrained model
2025-10-29 12:26:19,317:INFO:Logistic Regression Imported successfully
2025-10-29 12:26:19,317:INFO:Starting cross validation
2025-10-29 12:26:19,319:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:19,487:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,554:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,613:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,693:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,759:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,826:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,888:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:19,962:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:20,026:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:20,083:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:20,099:INFO:Calculating mean and std
2025-10-29 12:26:20,103:INFO:Creating metrics dataframe
2025-10-29 12:26:20,106:INFO:Uploading results into container
2025-10-29 12:26:20,107:INFO:Uploading model into container now
2025-10-29 12:26:20,108:INFO:_master_model_container: 1
2025-10-29 12:26:20,108:INFO:_display_container: 2
2025-10-29 12:26:20,109:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-29 12:26:20,109:INFO:create_model() successfully completed......................................
2025-10-29 12:26:20,240:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:20,240:INFO:Creating metrics dataframe
2025-10-29 12:26:20,248:INFO:Initializing K Neighbors Classifier
2025-10-29 12:26:20,248:INFO:Total runtime is 0.01563530365626017 minutes
2025-10-29 12:26:20,249:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:20,249:INFO:Initializing create_model()
2025-10-29 12:26:20,249:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:20,250:INFO:Checking exceptions
2025-10-29 12:26:20,250:INFO:Importing libraries
2025-10-29 12:26:20,250:INFO:Copying training dataset
2025-10-29 12:26:20,256:INFO:Defining folds
2025-10-29 12:26:20,256:INFO:Declaring metric variables
2025-10-29 12:26:20,256:INFO:Importing untrained model
2025-10-29 12:26:20,257:INFO:K Neighbors Classifier Imported successfully
2025-10-29 12:26:20,258:INFO:Starting cross validation
2025-10-29 12:26:20,259:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:20,880:INFO:Calculating mean and std
2025-10-29 12:26:20,881:INFO:Creating metrics dataframe
2025-10-29 12:26:20,883:INFO:Uploading results into container
2025-10-29 12:26:20,884:INFO:Uploading model into container now
2025-10-29 12:26:20,885:INFO:_master_model_container: 2
2025-10-29 12:26:20,885:INFO:_display_container: 2
2025-10-29 12:26:20,885:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-29 12:26:20,885:INFO:create_model() successfully completed......................................
2025-10-29 12:26:21,036:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:21,036:INFO:Creating metrics dataframe
2025-10-29 12:26:21,044:INFO:Initializing Naive Bayes
2025-10-29 12:26:21,044:INFO:Total runtime is 0.028902920087178548 minutes
2025-10-29 12:26:21,045:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:21,045:INFO:Initializing create_model()
2025-10-29 12:26:21,045:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:21,045:INFO:Checking exceptions
2025-10-29 12:26:21,045:INFO:Importing libraries
2025-10-29 12:26:21,045:INFO:Copying training dataset
2025-10-29 12:26:21,051:INFO:Defining folds
2025-10-29 12:26:21,051:INFO:Declaring metric variables
2025-10-29 12:26:21,051:INFO:Importing untrained model
2025-10-29 12:26:21,052:INFO:Naive Bayes Imported successfully
2025-10-29 12:26:21,052:INFO:Starting cross validation
2025-10-29 12:26:21,054:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:21,649:INFO:Calculating mean and std
2025-10-29 12:26:21,650:INFO:Creating metrics dataframe
2025-10-29 12:26:21,654:INFO:Uploading results into container
2025-10-29 12:26:21,656:INFO:Uploading model into container now
2025-10-29 12:26:21,657:INFO:_master_model_container: 3
2025-10-29 12:26:21,657:INFO:_display_container: 2
2025-10-29 12:26:21,657:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-29 12:26:21,657:INFO:create_model() successfully completed......................................
2025-10-29 12:26:21,779:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:21,779:INFO:Creating metrics dataframe
2025-10-29 12:26:21,784:INFO:Initializing Decision Tree Classifier
2025-10-29 12:26:21,784:INFO:Total runtime is 0.041243179639180505 minutes
2025-10-29 12:26:21,784:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:21,785:INFO:Initializing create_model()
2025-10-29 12:26:21,785:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:21,785:INFO:Checking exceptions
2025-10-29 12:26:21,785:INFO:Importing libraries
2025-10-29 12:26:21,785:INFO:Copying training dataset
2025-10-29 12:26:21,790:INFO:Defining folds
2025-10-29 12:26:21,790:INFO:Declaring metric variables
2025-10-29 12:26:21,792:INFO:Importing untrained model
2025-10-29 12:26:21,793:INFO:Decision Tree Classifier Imported successfully
2025-10-29 12:26:21,793:INFO:Starting cross validation
2025-10-29 12:26:21,794:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:22,302:INFO:Calculating mean and std
2025-10-29 12:26:22,304:INFO:Creating metrics dataframe
2025-10-29 12:26:22,306:INFO:Uploading results into container
2025-10-29 12:26:22,307:INFO:Uploading model into container now
2025-10-29 12:26:22,308:INFO:_master_model_container: 4
2025-10-29 12:26:22,308:INFO:_display_container: 2
2025-10-29 12:26:22,309:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-29 12:26:22,309:INFO:create_model() successfully completed......................................
2025-10-29 12:26:22,442:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:22,442:INFO:Creating metrics dataframe
2025-10-29 12:26:22,448:INFO:Initializing SVM - Linear Kernel
2025-10-29 12:26:22,448:INFO:Total runtime is 0.05230125983556112 minutes
2025-10-29 12:26:22,448:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:22,448:INFO:Initializing create_model()
2025-10-29 12:26:22,449:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:22,449:INFO:Checking exceptions
2025-10-29 12:26:22,449:INFO:Importing libraries
2025-10-29 12:26:22,449:INFO:Copying training dataset
2025-10-29 12:26:22,454:INFO:Defining folds
2025-10-29 12:26:22,454:INFO:Declaring metric variables
2025-10-29 12:26:22,454:INFO:Importing untrained model
2025-10-29 12:26:22,455:INFO:SVM - Linear Kernel Imported successfully
2025-10-29 12:26:22,455:INFO:Starting cross validation
2025-10-29 12:26:22,457:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:22,526:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,536:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:22,574:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,580:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:22,620:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,668:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,676:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:22,715:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,759:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,802:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,848:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,854:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:22,902:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,907:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:22,946:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:22,952:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:22,966:INFO:Calculating mean and std
2025-10-29 12:26:22,967:INFO:Creating metrics dataframe
2025-10-29 12:26:22,969:INFO:Uploading results into container
2025-10-29 12:26:22,970:INFO:Uploading model into container now
2025-10-29 12:26:22,972:INFO:_master_model_container: 5
2025-10-29 12:26:22,972:INFO:_display_container: 2
2025-10-29 12:26:22,973:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-29 12:26:22,974:INFO:create_model() successfully completed......................................
2025-10-29 12:26:23,108:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:23,108:INFO:Creating metrics dataframe
2025-10-29 12:26:23,114:INFO:Initializing Ridge Classifier
2025-10-29 12:26:23,114:INFO:Total runtime is 0.0633970856666565 minutes
2025-10-29 12:26:23,115:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:23,115:INFO:Initializing create_model()
2025-10-29 12:26:23,115:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:23,115:INFO:Checking exceptions
2025-10-29 12:26:23,116:INFO:Importing libraries
2025-10-29 12:26:23,116:INFO:Copying training dataset
2025-10-29 12:26:23,123:INFO:Defining folds
2025-10-29 12:26:23,123:INFO:Declaring metric variables
2025-10-29 12:26:23,124:INFO:Importing untrained model
2025-10-29 12:26:23,124:INFO:Ridge Classifier Imported successfully
2025-10-29 12:26:23,125:INFO:Starting cross validation
2025-10-29 12:26:23,127:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:23,245:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,315:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,368:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,427:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,475:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,521:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,628:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,688:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,748:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,810:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:23,834:INFO:Calculating mean and std
2025-10-29 12:26:23,835:INFO:Creating metrics dataframe
2025-10-29 12:26:23,838:INFO:Uploading results into container
2025-10-29 12:26:23,839:INFO:Uploading model into container now
2025-10-29 12:26:23,839:INFO:_master_model_container: 6
2025-10-29 12:26:23,840:INFO:_display_container: 2
2025-10-29 12:26:23,840:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-29 12:26:23,840:INFO:create_model() successfully completed......................................
2025-10-29 12:26:23,991:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:23,991:INFO:Creating metrics dataframe
2025-10-29 12:26:23,999:INFO:Initializing Random Forest Classifier
2025-10-29 12:26:24,000:INFO:Total runtime is 0.07816164096196493 minutes
2025-10-29 12:26:24,000:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:24,001:INFO:Initializing create_model()
2025-10-29 12:26:24,001:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:24,001:INFO:Checking exceptions
2025-10-29 12:26:24,001:INFO:Importing libraries
2025-10-29 12:26:24,001:INFO:Copying training dataset
2025-10-29 12:26:24,010:INFO:Defining folds
2025-10-29 12:26:24,010:INFO:Declaring metric variables
2025-10-29 12:26:24,011:INFO:Importing untrained model
2025-10-29 12:26:24,011:INFO:Random Forest Classifier Imported successfully
2025-10-29 12:26:24,012:INFO:Starting cross validation
2025-10-29 12:26:24,014:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:27,259:INFO:Calculating mean and std
2025-10-29 12:26:27,260:INFO:Creating metrics dataframe
2025-10-29 12:26:27,265:INFO:Uploading results into container
2025-10-29 12:26:27,266:INFO:Uploading model into container now
2025-10-29 12:26:27,267:INFO:_master_model_container: 7
2025-10-29 12:26:27,267:INFO:_display_container: 2
2025-10-29 12:26:27,268:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-29 12:26:27,268:INFO:create_model() successfully completed......................................
2025-10-29 12:26:27,412:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:27,412:INFO:Creating metrics dataframe
2025-10-29 12:26:27,418:INFO:Initializing Quadratic Discriminant Analysis
2025-10-29 12:26:27,419:INFO:Total runtime is 0.13514577150344848 minutes
2025-10-29 12:26:27,419:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:27,419:INFO:Initializing create_model()
2025-10-29 12:26:27,420:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:27,420:INFO:Checking exceptions
2025-10-29 12:26:27,420:INFO:Importing libraries
2025-10-29 12:26:27,420:INFO:Copying training dataset
2025-10-29 12:26:27,428:INFO:Defining folds
2025-10-29 12:26:27,428:INFO:Declaring metric variables
2025-10-29 12:26:27,429:INFO:Importing untrained model
2025-10-29 12:26:27,429:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-29 12:26:27,430:INFO:Starting cross validation
2025-10-29 12:26:27,432:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:27,528:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,581:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,676:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,728:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,798:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,860:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,916:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:27,969:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:28,036:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:28,111:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:28,132:INFO:Calculating mean and std
2025-10-29 12:26:28,134:INFO:Creating metrics dataframe
2025-10-29 12:26:28,138:INFO:Uploading results into container
2025-10-29 12:26:28,139:INFO:Uploading model into container now
2025-10-29 12:26:28,139:INFO:_master_model_container: 8
2025-10-29 12:26:28,139:INFO:_display_container: 2
2025-10-29 12:26:28,140:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-29 12:26:28,140:INFO:create_model() successfully completed......................................
2025-10-29 12:26:28,267:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:28,267:INFO:Creating metrics dataframe
2025-10-29 12:26:28,273:INFO:Initializing Ada Boost Classifier
2025-10-29 12:26:28,274:INFO:Total runtime is 0.1494094173113505 minutes
2025-10-29 12:26:28,274:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:28,275:INFO:Initializing create_model()
2025-10-29 12:26:28,275:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:28,275:INFO:Checking exceptions
2025-10-29 12:26:28,275:INFO:Importing libraries
2025-10-29 12:26:28,275:INFO:Copying training dataset
2025-10-29 12:26:28,282:INFO:Defining folds
2025-10-29 12:26:28,282:INFO:Declaring metric variables
2025-10-29 12:26:28,282:INFO:Importing untrained model
2025-10-29 12:26:28,283:INFO:Ada Boost Classifier Imported successfully
2025-10-29 12:26:28,284:INFO:Starting cross validation
2025-10-29 12:26:28,285:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:28,317:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:28,534:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:28,567:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:28,751:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:28,795:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:28,972:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:28,999:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:29,169:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:29,197:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:29,389:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:29,417:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:29,629:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:29,672:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:29,837:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:29,867:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:30,035:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:30,065:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:30,256:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:30,286:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:26:30,485:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:30,500:INFO:Calculating mean and std
2025-10-29 12:26:30,501:INFO:Creating metrics dataframe
2025-10-29 12:26:30,505:INFO:Uploading results into container
2025-10-29 12:26:30,506:INFO:Uploading model into container now
2025-10-29 12:26:30,513:INFO:_master_model_container: 9
2025-10-29 12:26:30,513:INFO:_display_container: 2
2025-10-29 12:26:30,514:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-29 12:26:30,514:INFO:create_model() successfully completed......................................
2025-10-29 12:26:30,655:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:30,655:INFO:Creating metrics dataframe
2025-10-29 12:26:30,660:INFO:Initializing Gradient Boosting Classifier
2025-10-29 12:26:30,660:INFO:Total runtime is 0.18917616208394367 minutes
2025-10-29 12:26:30,662:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:30,663:INFO:Initializing create_model()
2025-10-29 12:26:30,663:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:30,663:INFO:Checking exceptions
2025-10-29 12:26:30,663:INFO:Importing libraries
2025-10-29 12:26:30,663:INFO:Copying training dataset
2025-10-29 12:26:30,668:INFO:Defining folds
2025-10-29 12:26:30,668:INFO:Declaring metric variables
2025-10-29 12:26:30,668:INFO:Importing untrained model
2025-10-29 12:26:30,670:INFO:Gradient Boosting Classifier Imported successfully
2025-10-29 12:26:30,670:INFO:Starting cross validation
2025-10-29 12:26:30,672:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:31,267:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:31,849:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:32,381:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:32,883:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:33,378:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:33,907:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:34,466:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:34,974:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:35,490:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:35,984:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,001:INFO:Calculating mean and std
2025-10-29 12:26:36,002:INFO:Creating metrics dataframe
2025-10-29 12:26:36,006:INFO:Uploading results into container
2025-10-29 12:26:36,006:INFO:Uploading model into container now
2025-10-29 12:26:36,007:INFO:_master_model_container: 10
2025-10-29 12:26:36,007:INFO:_display_container: 2
2025-10-29 12:26:36,008:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-29 12:26:36,008:INFO:create_model() successfully completed......................................
2025-10-29 12:26:36,160:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:36,161:INFO:Creating metrics dataframe
2025-10-29 12:26:36,169:INFO:Initializing Linear Discriminant Analysis
2025-10-29 12:26:36,170:INFO:Total runtime is 0.2810014923413594 minutes
2025-10-29 12:26:36,170:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:36,171:INFO:Initializing create_model()
2025-10-29 12:26:36,171:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:36,171:INFO:Checking exceptions
2025-10-29 12:26:36,171:INFO:Importing libraries
2025-10-29 12:26:36,171:INFO:Copying training dataset
2025-10-29 12:26:36,177:INFO:Defining folds
2025-10-29 12:26:36,177:INFO:Declaring metric variables
2025-10-29 12:26:36,178:INFO:Importing untrained model
2025-10-29 12:26:36,178:INFO:Linear Discriminant Analysis Imported successfully
2025-10-29 12:26:36,180:INFO:Starting cross validation
2025-10-29 12:26:36,181:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:36,297:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,342:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,410:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,493:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,574:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,647:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,702:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,747:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,795:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,859:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:26:36,878:INFO:Calculating mean and std
2025-10-29 12:26:36,879:INFO:Creating metrics dataframe
2025-10-29 12:26:36,883:INFO:Uploading results into container
2025-10-29 12:26:36,883:INFO:Uploading model into container now
2025-10-29 12:26:36,885:INFO:_master_model_container: 11
2025-10-29 12:26:36,885:INFO:_display_container: 2
2025-10-29 12:26:36,885:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-29 12:26:36,885:INFO:create_model() successfully completed......................................
2025-10-29 12:26:37,061:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:37,062:INFO:Creating metrics dataframe
2025-10-29 12:26:37,067:INFO:Initializing Extra Trees Classifier
2025-10-29 12:26:37,067:INFO:Total runtime is 0.29595273335774736 minutes
2025-10-29 12:26:37,068:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:37,068:INFO:Initializing create_model()
2025-10-29 12:26:37,069:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:37,069:INFO:Checking exceptions
2025-10-29 12:26:37,069:INFO:Importing libraries
2025-10-29 12:26:37,069:INFO:Copying training dataset
2025-10-29 12:26:37,075:INFO:Defining folds
2025-10-29 12:26:37,076:INFO:Declaring metric variables
2025-10-29 12:26:37,076:INFO:Importing untrained model
2025-10-29 12:26:37,077:INFO:Extra Trees Classifier Imported successfully
2025-10-29 12:26:37,078:INFO:Starting cross validation
2025-10-29 12:26:37,079:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:39,375:INFO:Calculating mean and std
2025-10-29 12:26:39,376:INFO:Creating metrics dataframe
2025-10-29 12:26:39,380:INFO:Uploading results into container
2025-10-29 12:26:39,381:INFO:Uploading model into container now
2025-10-29 12:26:39,381:INFO:_master_model_container: 12
2025-10-29 12:26:39,382:INFO:_display_container: 2
2025-10-29 12:26:39,382:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-29 12:26:39,382:INFO:create_model() successfully completed......................................
2025-10-29 12:26:39,507:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:39,507:INFO:Creating metrics dataframe
2025-10-29 12:26:39,511:INFO:Initializing Light Gradient Boosting Machine
2025-10-29 12:26:39,511:INFO:Total runtime is 0.33668236335118606 minutes
2025-10-29 12:26:39,512:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:39,512:INFO:Initializing create_model()
2025-10-29 12:26:39,512:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:39,512:INFO:Checking exceptions
2025-10-29 12:26:39,512:INFO:Importing libraries
2025-10-29 12:26:39,512:INFO:Copying training dataset
2025-10-29 12:26:39,518:INFO:Defining folds
2025-10-29 12:26:39,519:INFO:Declaring metric variables
2025-10-29 12:26:39,519:INFO:Importing untrained model
2025-10-29 12:26:39,521:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-29 12:26:39,522:INFO:Starting cross validation
2025-10-29 12:26:39,524:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:39,585:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:39,592:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000396 seconds.
2025-10-29 12:26:39,593:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:39,594:INFO:[LightGBM] [Info] Total Bins 75
2025-10-29 12:26:39,595:INFO:[LightGBM] [Info] Number of data points in the train set: 94, number of used features: 4
2025-10-29 12:26:39,597:INFO:[LightGBM] [Info] Start training from score -1.077559
2025-10-29 12:26:39,598:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,598:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,604:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,605:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,606:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,607:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,608:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,609:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,610:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,611:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,612:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,613:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,614:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,615:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,616:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,617:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,618:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,619:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,620:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,621:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,622:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,623:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,624:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,625:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,626:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,628:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,632:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,641:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,711:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:39,712:INFO:[LightGBM] [Info] Auto-choosing row-wise multi-threading, the overhead of testing was 0.000016 seconds.
2025-10-29 12:26:39,712:INFO:You can set `force_row_wise=true` to remove the overhead.
2025-10-29 12:26:39,712:INFO:And if memory is not enough, you can set `force_col_wise=true`.
2025-10-29 12:26:39,712:INFO:[LightGBM] [Info] Total Bins 77
2025-10-29 12:26:39,712:INFO:[LightGBM] [Info] Number of data points in the train set: 94, number of used features: 4
2025-10-29 12:26:39,712:INFO:[LightGBM] [Info] Start training from score -1.077559
2025-10-29 12:26:39,712:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,712:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,712:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,713:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,714:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,715:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,716:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,717:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,718:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,719:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,720:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,722:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,723:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,724:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,725:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,726:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,727:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,728:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,729:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,730:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,732:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,733:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,734:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,735:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,736:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,737:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,738:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,739:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,740:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,742:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,743:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,744:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,745:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,746:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,747:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,748:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,750:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,822:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:39,822:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000028 seconds.
2025-10-29 12:26:39,822:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:39,823:INFO:[LightGBM] [Info] Total Bins 78
2025-10-29 12:26:39,823:INFO:[LightGBM] [Info] Number of data points in the train set: 94, number of used features: 4
2025-10-29 12:26:39,823:INFO:[LightGBM] [Info] Start training from score -1.077559
2025-10-29 12:26:39,823:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,823:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,823:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,824:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,825:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,826:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,827:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,828:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,829:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,830:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,831:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,834:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,835:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,836:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,837:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,838:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,839:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,840:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,841:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,842:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,844:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,845:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,846:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,847:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,848:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,849:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,852:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,853:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,854:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,855:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,856:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,857:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,858:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,859:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,860:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,861:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,862:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,864:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,867:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,868:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,869:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,870:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,871:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,872:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,979:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:39,980:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.
2025-10-29 12:26:39,980:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:39,980:INFO:[LightGBM] [Info] Total Bins 78
2025-10-29 12:26:39,980:INFO:[LightGBM] [Info] Number of data points in the train set: 94, number of used features: 4
2025-10-29 12:26:39,980:INFO:[LightGBM] [Info] Start training from score -1.077559
2025-10-29 12:26:39,981:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,981:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:39,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,981:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,982:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,983:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,984:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,985:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,986:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,987:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,988:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,989:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,990:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,992:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,993:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,994:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,995:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,996:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,997:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:39,998:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,000:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,001:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,002:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,003:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,004:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,005:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,006:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,007:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,008:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,009:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,010:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,012:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,013:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,014:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,015:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,019:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,020:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,021:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,022:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,023:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,024:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,025:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,026:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,027:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,028:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,029:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,030:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,035:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,036:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,037:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,038:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,039:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,040:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,041:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,042:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,043:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,044:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,190:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:40,192:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000042 seconds.
2025-10-29 12:26:40,192:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:40,192:INFO:[LightGBM] [Info] Total Bins 79
2025-10-29 12:26:40,192:INFO:[LightGBM] [Info] Number of data points in the train set: 94, number of used features: 4
2025-10-29 12:26:40,193:INFO:[LightGBM] [Info] Start training from score -1.077559
2025-10-29 12:26:40,193:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:40,194:INFO:[LightGBM] [Info] Start training from score -1.109308
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,194:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,196:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,197:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,198:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,199:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,200:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,201:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,202:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,204:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,205:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,206:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,207:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,208:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,209:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,210:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,212:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,213:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,214:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,215:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,216:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,217:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,218:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,220:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,221:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,222:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,223:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,224:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,225:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,226:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,227:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,228:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,229:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,230:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,231:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,232:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,233:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,234:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,235:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,236:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,237:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,238:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,239:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,240:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,242:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,243:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,244:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,245:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,246:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,247:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,248:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,249:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,250:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,251:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,252:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,253:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,254:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,255:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,256:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,376:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:40,377:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000040 seconds.
2025-10-29 12:26:40,377:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:40,378:INFO:[LightGBM] [Info] Total Bins 75
2025-10-29 12:26:40,378:INFO:[LightGBM] [Info] Number of data points in the train set: 95, number of used features: 4
2025-10-29 12:26:40,378:INFO:[LightGBM] [Info] Start training from score -1.119890
2025-10-29 12:26:40,379:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,379:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,379:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,380:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,382:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,383:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,384:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,385:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,386:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,387:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,388:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,389:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,390:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,392:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,393:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,394:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,396:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,397:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,398:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,399:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,400:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,401:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,402:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,403:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,404:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,405:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,406:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,407:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,408:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,410:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,412:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,413:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,414:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,415:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,416:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,417:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,418:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,419:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,420:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,421:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,422:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,423:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,424:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,425:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,426:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,427:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,428:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,429:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,430:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,431:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,432:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,433:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,434:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,435:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,437:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,438:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,439:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,440:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,508:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:40,509:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000018 seconds.
2025-10-29 12:26:40,509:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:40,509:INFO:[LightGBM] [Info] Total Bins 78
2025-10-29 12:26:40,509:INFO:[LightGBM] [Info] Number of data points in the train set: 95, number of used features: 4
2025-10-29 12:26:40,509:INFO:[LightGBM] [Info] Start training from score -1.119890
2025-10-29 12:26:40,509:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,509:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,510:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,512:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,513:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,514:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,515:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,516:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,517:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,518:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,519:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,520:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,521:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,522:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,523:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,524:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,525:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,526:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,527:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,528:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,529:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,530:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,532:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,533:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,534:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,535:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,536:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,537:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,538:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,539:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,540:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,541:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,542:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,543:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,544:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,545:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,546:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,547:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,548:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,549:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,550:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,551:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,552:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,553:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,555:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,556:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,557:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,558:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,559:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,560:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,561:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,562:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,625:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:40,626:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000024 seconds.
2025-10-29 12:26:40,626:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:40,626:INFO:[LightGBM] [Info] Total Bins 78
2025-10-29 12:26:40,626:INFO:[LightGBM] [Info] Number of data points in the train set: 95, number of used features: 4
2025-10-29 12:26:40,626:INFO:[LightGBM] [Info] Start training from score -1.119890
2025-10-29 12:26:40,626:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,626:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,627:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,629:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,630:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,631:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,633:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,634:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,635:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,636:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,637:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,638:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,639:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,640:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,642:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,643:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,644:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,645:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,646:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,647:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,648:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,649:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,651:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,652:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,653:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,654:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,655:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,656:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,657:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,658:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,659:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,660:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,662:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,663:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,664:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,665:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,666:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,667:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,668:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,669:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,670:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,747:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:40,748:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.
2025-10-29 12:26:40,748:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:40,748:INFO:[LightGBM] [Info] Total Bins 75
2025-10-29 12:26:40,748:INFO:[LightGBM] [Info] Number of data points in the train set: 95, number of used features: 4
2025-10-29 12:26:40,748:INFO:[LightGBM] [Info] Start training from score -1.119890
2025-10-29 12:26:40,748:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,749:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,749:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,751:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,752:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,753:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,754:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,755:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,756:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,757:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,758:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,759:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,760:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,761:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,762:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,763:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,764:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,765:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,766:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,767:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,768:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,769:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,770:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,772:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,773:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,774:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,775:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,776:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,777:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,778:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,779:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,780:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,781:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,782:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,783:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,784:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,872:INFO:[LightGBM] [Warning] Found whitespace in feature_names, replace with underlines
2025-10-29 12:26:40,872:INFO:[LightGBM] [Info] Auto-choosing col-wise multi-threading, the overhead of testing was 0.000027 seconds.
2025-10-29 12:26:40,873:INFO:You can set `force_col_wise=true` to remove the overhead.
2025-10-29 12:26:40,873:INFO:[LightGBM] [Info] Total Bins 78
2025-10-29 12:26:40,873:INFO:[LightGBM] [Info] Number of data points in the train set: 95, number of used features: 4
2025-10-29 12:26:40,873:INFO:[LightGBM] [Info] Start training from score -1.119890
2025-10-29 12:26:40,873:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,873:INFO:[LightGBM] [Info] Start training from score -1.088141
2025-10-29 12:26:40,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,873:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,874:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,875:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,876:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,877:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,878:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,879:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,880:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,882:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,883:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,884:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,885:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,886:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,887:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,888:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,889:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,890:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,891:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,892:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,893:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,894:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,895:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,896:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,897:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,898:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,899:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,900:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,902:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,903:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,904:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,905:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,906:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:40,907:INFO:[LightGBM] [Warning] No further splits with positive gain, best gain: -inf
2025-10-29 12:26:41,003:INFO:Calculating mean and std
2025-10-29 12:26:41,004:INFO:Creating metrics dataframe
2025-10-29 12:26:41,007:INFO:Uploading results into container
2025-10-29 12:26:41,008:INFO:Uploading model into container now
2025-10-29 12:26:41,009:INFO:_master_model_container: 13
2025-10-29 12:26:41,009:INFO:_display_container: 2
2025-10-29 12:26:41,010:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-29 12:26:41,010:INFO:create_model() successfully completed......................................
2025-10-29 12:26:41,139:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:41,140:INFO:Creating metrics dataframe
2025-10-29 12:26:41,144:INFO:Initializing Dummy Classifier
2025-10-29 12:26:41,144:INFO:Total runtime is 0.36390966574350986 minutes
2025-10-29 12:26:41,145:INFO:SubProcess create_model() called ==================================
2025-10-29 12:26:41,145:INFO:Initializing create_model()
2025-10-29 12:26:41,145:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C089BF50>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:41,145:INFO:Checking exceptions
2025-10-29 12:26:41,145:INFO:Importing libraries
2025-10-29 12:26:41,146:INFO:Copying training dataset
2025-10-29 12:26:41,152:INFO:Defining folds
2025-10-29 12:26:41,152:INFO:Declaring metric variables
2025-10-29 12:26:41,152:INFO:Importing untrained model
2025-10-29 12:26:41,153:INFO:Dummy Classifier Imported successfully
2025-10-29 12:26:41,153:INFO:Starting cross validation
2025-10-29 12:26:41,154:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:26:41,192:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,232:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,279:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,326:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,379:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,422:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,462:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,505:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,543:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,583:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:26:41,592:INFO:Calculating mean and std
2025-10-29 12:26:41,593:INFO:Creating metrics dataframe
2025-10-29 12:26:41,595:INFO:Uploading results into container
2025-10-29 12:26:41,596:INFO:Uploading model into container now
2025-10-29 12:26:41,597:INFO:_master_model_container: 14
2025-10-29 12:26:41,597:INFO:_display_container: 2
2025-10-29 12:26:41,598:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-29 12:26:41,598:INFO:create_model() successfully completed......................................
2025-10-29 12:26:41,750:INFO:SubProcess create_model() end ==================================
2025-10-29 12:26:41,751:INFO:Creating metrics dataframe
2025-10-29 12:26:41,760:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-29 12:26:41,765:INFO:Initializing create_model()
2025-10-29 12:26:41,765:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:41,765:INFO:Checking exceptions
2025-10-29 12:26:41,766:INFO:Importing libraries
2025-10-29 12:26:41,767:INFO:Copying training dataset
2025-10-29 12:26:41,774:INFO:Defining folds
2025-10-29 12:26:41,774:INFO:Declaring metric variables
2025-10-29 12:26:41,774:INFO:Importing untrained model
2025-10-29 12:26:41,775:INFO:Declaring custom model
2025-10-29 12:26:41,776:INFO:Logistic Regression Imported successfully
2025-10-29 12:26:41,777:INFO:Cross validation set to False
2025-10-29 12:26:41,777:INFO:Fitting Model
2025-10-29 12:26:41,828:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-29 12:26:41,828:INFO:create_model() successfully completed......................................
2025-10-29 12:26:41,971:INFO:Initializing create_model()
2025-10-29 12:26:41,972:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:41,972:INFO:Checking exceptions
2025-10-29 12:26:41,973:INFO:Importing libraries
2025-10-29 12:26:41,973:INFO:Copying training dataset
2025-10-29 12:26:41,978:INFO:Defining folds
2025-10-29 12:26:41,978:INFO:Declaring metric variables
2025-10-29 12:26:41,978:INFO:Importing untrained model
2025-10-29 12:26:41,978:INFO:Declaring custom model
2025-10-29 12:26:41,979:INFO:K Neighbors Classifier Imported successfully
2025-10-29 12:26:41,980:INFO:Cross validation set to False
2025-10-29 12:26:41,980:INFO:Fitting Model
2025-10-29 12:26:41,998:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-29 12:26:42,002:INFO:create_model() successfully completed......................................
2025-10-29 12:26:42,150:INFO:Initializing create_model()
2025-10-29 12:26:42,150:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x00000187800F6D10>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:26:42,150:INFO:Checking exceptions
2025-10-29 12:26:42,152:INFO:Importing libraries
2025-10-29 12:26:42,152:INFO:Copying training dataset
2025-10-29 12:26:42,157:INFO:Defining folds
2025-10-29 12:26:42,157:INFO:Declaring metric variables
2025-10-29 12:26:42,157:INFO:Importing untrained model
2025-10-29 12:26:42,157:INFO:Declaring custom model
2025-10-29 12:26:42,158:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-29 12:26:42,159:INFO:Cross validation set to False
2025-10-29 12:26:42,160:INFO:Fitting Model
2025-10-29 12:26:42,179:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-29 12:26:42,179:INFO:create_model() successfully completed......................................
2025-10-29 12:26:42,349:INFO:_master_model_container: 14
2025-10-29 12:26:42,349:INFO:_display_container: 2
2025-10-29 12:26:42,354:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)]
2025-10-29 12:26:42,354:INFO:compare_models() successfully completed......................................
2025-10-29 12:29:29,748:INFO:PyCaret ClassificationExperiment
2025-10-29 12:29:29,748:INFO:Logging name: clf-default-name
2025-10-29 12:29:29,748:INFO:ML Usecase: MLUsecase.CLASSIFICATION
2025-10-29 12:29:29,748:INFO:version 3.3.2
2025-10-29 12:29:29,748:INFO:Initializing setup()
2025-10-29 12:29:29,748:INFO:self.USI: ee0f
2025-10-29 12:29:29,748:INFO:self._variable_keys: {'gpu_param', 'target_param', 'logging_param', 'y_train', 'exp_name_log', '_ml_usecase', 'X', 'fix_imbalance', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'seed', '_available_plots', 'y', 'fold_generator', 'USI', 'is_multiclass', 'exp_id', 'pipeline', 'n_jobs_param', 'fold_groups_param', 'memory', 'idx', 'X_train', 'X_test', 'html_param', 'data', 'log_plots_param'}
2025-10-29 12:29:29,748:INFO:Checking environment
2025-10-29 12:29:29,748:INFO:python_version: 3.11.14
2025-10-29 12:29:29,748:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-29 12:29:29,748:INFO:machine: AMD64
2025-10-29 12:29:29,748:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-29 12:29:29,750:INFO:Memory: svmem(total=16788250624, available=3380412416, percent=79.9, used=13407838208, free=3380412416)
2025-10-29 12:29:29,751:INFO:Physical Core: 12
2025-10-29 12:29:29,751:INFO:Logical Core: 16
2025-10-29 12:29:29,751:INFO:Checking libraries
2025-10-29 12:29:29,751:INFO:System:
2025-10-29 12:29:29,751:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-29 12:29:29,751:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-29 12:29:29,751:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-29 12:29:29,751:INFO:PyCaret required dependencies:
2025-10-29 12:29:29,751:INFO:                 pip: 25.2
2025-10-29 12:29:29,751:INFO:          setuptools: 80.9.0
2025-10-29 12:29:29,751:INFO:             pycaret: 3.3.2
2025-10-29 12:29:29,751:INFO:             IPython: 9.6.0
2025-10-29 12:29:29,751:INFO:          ipywidgets: 8.1.7
2025-10-29 12:29:29,751:INFO:                tqdm: 4.67.1
2025-10-29 12:29:29,751:INFO:               numpy: 1.26.4
2025-10-29 12:29:29,751:INFO:              pandas: 2.1.4
2025-10-29 12:29:29,751:INFO:              jinja2: 3.1.6
2025-10-29 12:29:29,751:INFO:               scipy: 1.11.4
2025-10-29 12:29:29,753:INFO:              joblib: 1.3.2
2025-10-29 12:29:29,753:INFO:             sklearn: 1.4.2
2025-10-29 12:29:29,753:INFO:                pyod: 2.0.5
2025-10-29 12:29:29,753:INFO:            imblearn: 0.14.0
2025-10-29 12:29:29,753:INFO:   category_encoders: 2.7.0
2025-10-29 12:29:29,753:INFO:            lightgbm: 4.6.0
2025-10-29 12:29:29,753:INFO:               numba: 0.62.1
2025-10-29 12:29:29,753:INFO:            requests: 2.32.5
2025-10-29 12:29:29,753:INFO:          matplotlib: 3.10.7
2025-10-29 12:29:29,753:INFO:          scikitplot: 0.3.7
2025-10-29 12:29:29,753:INFO:         yellowbrick: 1.5
2025-10-29 12:29:29,753:INFO:              plotly: 6.3.1
2025-10-29 12:29:29,753:INFO:    plotly-resampler: Not installed
2025-10-29 12:29:29,753:INFO:             kaleido: 0.2.1
2025-10-29 12:29:29,753:INFO:           schemdraw: 0.15
2025-10-29 12:29:29,753:INFO:         statsmodels: 0.14.5
2025-10-29 12:29:29,753:INFO:              sktime: 0.26.0
2025-10-29 12:29:29,753:INFO:               tbats: 1.1.3
2025-10-29 12:29:29,753:INFO:            pmdarima: 2.0.4
2025-10-29 12:29:29,753:INFO:              psutil: 7.1.1
2025-10-29 12:29:29,753:INFO:          markupsafe: 3.0.3
2025-10-29 12:29:29,753:INFO:             pickle5: Not installed
2025-10-29 12:29:29,753:INFO:         cloudpickle: 3.1.1
2025-10-29 12:29:29,753:INFO:         deprecation: 2.1.0
2025-10-29 12:29:29,753:INFO:              xxhash: 3.6.0
2025-10-29 12:29:29,753:INFO:           wurlitzer: 3.1.1
2025-10-29 12:29:29,753:INFO:PyCaret optional dependencies:
2025-10-29 12:29:29,753:INFO:                shap: Not installed
2025-10-29 12:29:29,753:INFO:           interpret: Not installed
2025-10-29 12:29:29,753:INFO:                umap: 0.5.9.post2
2025-10-29 12:29:29,753:INFO:     ydata_profiling: Not installed
2025-10-29 12:29:29,753:INFO:  explainerdashboard: Not installed
2025-10-29 12:29:29,753:INFO:             autoviz: Not installed
2025-10-29 12:29:29,753:INFO:           fairlearn: Not installed
2025-10-29 12:29:29,753:INFO:          deepchecks: Not installed
2025-10-29 12:29:29,753:INFO:             xgboost: Not installed
2025-10-29 12:29:29,753:INFO:            catboost: Not installed
2025-10-29 12:29:29,753:INFO:              kmodes: Not installed
2025-10-29 12:29:29,753:INFO:             mlxtend: Not installed
2025-10-29 12:29:29,753:INFO:       statsforecast: Not installed
2025-10-29 12:29:29,753:INFO:        tune_sklearn: Not installed
2025-10-29 12:29:29,755:INFO:                 ray: Not installed
2025-10-29 12:29:29,755:INFO:            hyperopt: Not installed
2025-10-29 12:29:29,755:INFO:              optuna: Not installed
2025-10-29 12:29:29,755:INFO:               skopt: Not installed
2025-10-29 12:29:29,755:INFO:              mlflow: Not installed
2025-10-29 12:29:29,755:INFO:              gradio: Not installed
2025-10-29 12:29:29,755:INFO:             fastapi: Not installed
2025-10-29 12:29:29,755:INFO:             uvicorn: Not installed
2025-10-29 12:29:29,755:INFO:              m2cgen: Not installed
2025-10-29 12:29:29,755:INFO:           evidently: Not installed
2025-10-29 12:29:29,755:INFO:               fugue: Not installed
2025-10-29 12:29:29,755:INFO:           streamlit: 1.50.0
2025-10-29 12:29:29,755:INFO:             prophet: Not installed
2025-10-29 12:29:29,755:INFO:None
2025-10-29 12:29:29,755:INFO:Set up data.
2025-10-29 12:29:29,759:INFO:Set up folding strategy.
2025-10-29 12:29:29,759:INFO:Set up train/test split.
2025-10-29 12:29:29,763:INFO:Set up index.
2025-10-29 12:29:29,763:INFO:Assigning column types.
2025-10-29 12:29:29,767:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-29 12:29:29,822:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:29:29,823:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:29:29,852:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:29,852:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:29,895:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:29:29,896:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:29:29,926:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:29,927:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:29,927:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-29 12:29:29,992:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:29:30,040:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,040:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,118:INFO:Engine for model 'rbfsvm' has not been set explicitly, hence returning None.
2025-10-29 12:29:30,163:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,163:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,163:INFO:Engine successfully changes for model 'rbfsvm' to 'sklearn'.
2025-10-29 12:29:30,245:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,245:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,339:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,341:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,343:INFO:Preparing preprocessing pipeline...
2025-10-29 12:29:30,344:INFO:Set up simple imputation.
2025-10-29 12:29:30,344:INFO:Set up column name cleaning.
2025-10-29 12:29:30,374:INFO:Finished creating preprocessing pipeline.
2025-10-29 12:29:30,378:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(exclude=None,
                                    include=['sepal length (cm)',
                                             'sepal width (cm)',
                                             'petal length (cm)',
                                             'petal width (cm)'],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='mean'...
                ('categorical_imputer',
                 TransformerWrapper(exclude=None, include=[],
                                    transformer=SimpleImputer(add_indicator=False,
                                                              copy=True,
                                                              fill_value=None,
                                                              keep_empty_features=False,
                                                              missing_values=nan,
                                                              strategy='most_frequent'))),
                ('clean_column_names',
                 TransformerWrapper(exclude=None, include=None,
                                    transformer=CleanColumnNames(match='[\\]\\[\\,\\{\\}\\"\\:]+')))],
         verbose=False)
2025-10-29 12:29:30,378:INFO:Creating final display dataframe.
2025-10-29 12:29:30,468:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target            target
2                   Target type        Multiclass
3           Original data shape          (150, 5)
4        Transformed data shape          (150, 5)
5   Transformed train set shape          (105, 5)
6    Transformed test set shape           (45, 5)
7              Numeric features                 4
8                    Preprocess              True
9               Imputation type            simple
10           Numeric imputation              mean
11       Categorical imputation              mode
12               Fold Generator   StratifiedKFold
13                  Fold Number                10
14                     CPU Jobs                 1
15                      Use GPU             False
16               Log Experiment             False
17              Experiment Name  clf-default-name
18                          USI              ee0f
2025-10-29 12:29:30,548:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,549:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,660:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,660:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:29:30,661:INFO:setup() successfully completed in 0.92s...............
2025-10-29 12:29:30,661:INFO:Initializing compare_models()
2025-10-29 12:29:30,662:INFO:compare_models(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=Accuracy, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'Accuracy', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'probability_threshold': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.classification.oop.ClassificationExperiment'>})
2025-10-29 12:29:30,662:INFO:Checking exceptions
2025-10-29 12:29:30,665:INFO:Preparing display monitor
2025-10-29 12:29:30,670:INFO:Initializing Logistic Regression
2025-10-29 12:29:30,676:INFO:Total runtime is 0.00011638402938842773 minutes
2025-10-29 12:29:30,676:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:30,678:INFO:Initializing create_model()
2025-10-29 12:29:30,678:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=lr, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:30,678:INFO:Checking exceptions
2025-10-29 12:29:30,678:INFO:Importing libraries
2025-10-29 12:29:30,679:INFO:Copying training dataset
2025-10-29 12:29:30,685:INFO:Defining folds
2025-10-29 12:29:30,685:INFO:Declaring metric variables
2025-10-29 12:29:30,685:INFO:Importing untrained model
2025-10-29 12:29:30,686:INFO:Logistic Regression Imported successfully
2025-10-29 12:29:30,688:INFO:Starting cross validation
2025-10-29 12:29:30,690:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:30,725:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:30,779:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:30,828:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:30,884:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:30,951:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:30,997:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:31,037:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:31,081:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:31,123:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:31,181:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:31,196:INFO:Calculating mean and std
2025-10-29 12:29:31,197:INFO:Creating metrics dataframe
2025-10-29 12:29:31,200:INFO:Uploading results into container
2025-10-29 12:29:31,201:INFO:Uploading model into container now
2025-10-29 12:29:31,201:INFO:_master_model_container: 1
2025-10-29 12:29:31,201:INFO:_display_container: 2
2025-10-29 12:29:31,202:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-29 12:29:31,202:INFO:create_model() successfully completed......................................
2025-10-29 12:29:31,364:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:31,364:INFO:Creating metrics dataframe
2025-10-29 12:29:31,367:INFO:Initializing K Neighbors Classifier
2025-10-29 12:29:31,368:INFO:Total runtime is 0.011647546291351318 minutes
2025-10-29 12:29:31,368:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:31,368:INFO:Initializing create_model()
2025-10-29 12:29:31,368:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=knn, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:31,368:INFO:Checking exceptions
2025-10-29 12:29:31,368:INFO:Importing libraries
2025-10-29 12:29:31,368:INFO:Copying training dataset
2025-10-29 12:29:31,373:INFO:Defining folds
2025-10-29 12:29:31,373:INFO:Declaring metric variables
2025-10-29 12:29:31,374:INFO:Importing untrained model
2025-10-29 12:29:31,375:INFO:K Neighbors Classifier Imported successfully
2025-10-29 12:29:31,375:INFO:Starting cross validation
2025-10-29 12:29:31,376:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:31,745:INFO:Calculating mean and std
2025-10-29 12:29:31,746:INFO:Creating metrics dataframe
2025-10-29 12:29:31,748:INFO:Uploading results into container
2025-10-29 12:29:31,749:INFO:Uploading model into container now
2025-10-29 12:29:31,750:INFO:_master_model_container: 2
2025-10-29 12:29:31,750:INFO:_display_container: 2
2025-10-29 12:29:31,750:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-29 12:29:31,750:INFO:create_model() successfully completed......................................
2025-10-29 12:29:31,898:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:31,898:INFO:Creating metrics dataframe
2025-10-29 12:29:31,906:INFO:Initializing Naive Bayes
2025-10-29 12:29:31,906:INFO:Total runtime is 0.020613892873128255 minutes
2025-10-29 12:29:31,907:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:31,908:INFO:Initializing create_model()
2025-10-29 12:29:31,908:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=nb, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:31,908:INFO:Checking exceptions
2025-10-29 12:29:31,910:INFO:Importing libraries
2025-10-29 12:29:31,910:INFO:Copying training dataset
2025-10-29 12:29:31,917:INFO:Defining folds
2025-10-29 12:29:31,918:INFO:Declaring metric variables
2025-10-29 12:29:31,918:INFO:Importing untrained model
2025-10-29 12:29:31,918:INFO:Naive Bayes Imported successfully
2025-10-29 12:29:31,920:INFO:Starting cross validation
2025-10-29 12:29:31,921:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:32,324:INFO:Calculating mean and std
2025-10-29 12:29:32,325:INFO:Creating metrics dataframe
2025-10-29 12:29:32,327:INFO:Uploading results into container
2025-10-29 12:29:32,327:INFO:Uploading model into container now
2025-10-29 12:29:32,328:INFO:_master_model_container: 3
2025-10-29 12:29:32,328:INFO:_display_container: 2
2025-10-29 12:29:32,328:INFO:GaussianNB(priors=None, var_smoothing=1e-09)
2025-10-29 12:29:32,328:INFO:create_model() successfully completed......................................
2025-10-29 12:29:32,473:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:32,474:INFO:Creating metrics dataframe
2025-10-29 12:29:32,483:INFO:Initializing Decision Tree Classifier
2025-10-29 12:29:32,483:INFO:Total runtime is 0.030234066645304362 minutes
2025-10-29 12:29:32,484:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:32,484:INFO:Initializing create_model()
2025-10-29 12:29:32,484:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=dt, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:32,485:INFO:Checking exceptions
2025-10-29 12:29:32,485:INFO:Importing libraries
2025-10-29 12:29:32,485:INFO:Copying training dataset
2025-10-29 12:29:32,493:INFO:Defining folds
2025-10-29 12:29:32,493:INFO:Declaring metric variables
2025-10-29 12:29:32,494:INFO:Importing untrained model
2025-10-29 12:29:32,495:INFO:Decision Tree Classifier Imported successfully
2025-10-29 12:29:32,495:INFO:Starting cross validation
2025-10-29 12:29:32,497:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:32,851:INFO:Calculating mean and std
2025-10-29 12:29:32,854:INFO:Creating metrics dataframe
2025-10-29 12:29:32,858:INFO:Uploading results into container
2025-10-29 12:29:32,858:INFO:Uploading model into container now
2025-10-29 12:29:32,859:INFO:_master_model_container: 4
2025-10-29 12:29:32,859:INFO:_display_container: 2
2025-10-29 12:29:32,860:INFO:DecisionTreeClassifier(ccp_alpha=0.0, class_weight=None, criterion='gini',
                       max_depth=None, max_features=None, max_leaf_nodes=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, random_state=123, splitter='best')
2025-10-29 12:29:32,860:INFO:create_model() successfully completed......................................
2025-10-29 12:29:32,990:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:32,991:INFO:Creating metrics dataframe
2025-10-29 12:29:32,995:INFO:Initializing SVM - Linear Kernel
2025-10-29 12:29:32,996:INFO:Total runtime is 0.03877369562784831 minutes
2025-10-29 12:29:32,996:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:32,996:INFO:Initializing create_model()
2025-10-29 12:29:32,996:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=svm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:32,997:INFO:Checking exceptions
2025-10-29 12:29:32,997:INFO:Importing libraries
2025-10-29 12:29:32,997:INFO:Copying training dataset
2025-10-29 12:29:33,001:INFO:Defining folds
2025-10-29 12:29:33,002:INFO:Declaring metric variables
2025-10-29 12:29:33,002:INFO:Importing untrained model
2025-10-29 12:29:33,002:INFO:SVM - Linear Kernel Imported successfully
2025-10-29 12:29:33,003:INFO:Starting cross validation
2025-10-29 12:29:33,004:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:33,031:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,038:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:33,070:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,079:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:33,114:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,148:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,152:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:33,184:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,219:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,256:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,296:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,306:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:33,336:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,343:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:33,378:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,384:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:33,390:INFO:Calculating mean and std
2025-10-29 12:29:33,390:INFO:Creating metrics dataframe
2025-10-29 12:29:33,392:INFO:Uploading results into container
2025-10-29 12:29:33,393:INFO:Uploading model into container now
2025-10-29 12:29:33,394:INFO:_master_model_container: 5
2025-10-29 12:29:33,394:INFO:_display_container: 2
2025-10-29 12:29:33,394:INFO:SGDClassifier(alpha=0.0001, average=False, class_weight=None,
              early_stopping=False, epsilon=0.1, eta0=0.001, fit_intercept=True,
              l1_ratio=0.15, learning_rate='optimal', loss='hinge',
              max_iter=1000, n_iter_no_change=5, n_jobs=1, penalty='l2',
              power_t=0.5, random_state=123, shuffle=True, tol=0.001,
              validation_fraction=0.1, verbose=0, warm_start=False)
2025-10-29 12:29:33,394:INFO:create_model() successfully completed......................................
2025-10-29 12:29:33,514:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:33,515:INFO:Creating metrics dataframe
2025-10-29 12:29:33,518:INFO:Initializing Ridge Classifier
2025-10-29 12:29:33,518:INFO:Total runtime is 0.047479502360026044 minutes
2025-10-29 12:29:33,518:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:33,518:INFO:Initializing create_model()
2025-10-29 12:29:33,519:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=ridge, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:33,519:INFO:Checking exceptions
2025-10-29 12:29:33,519:INFO:Importing libraries
2025-10-29 12:29:33,519:INFO:Copying training dataset
2025-10-29 12:29:33,526:INFO:Defining folds
2025-10-29 12:29:33,526:INFO:Declaring metric variables
2025-10-29 12:29:33,526:INFO:Importing untrained model
2025-10-29 12:29:33,527:INFO:Ridge Classifier Imported successfully
2025-10-29 12:29:33,527:INFO:Starting cross validation
2025-10-29 12:29:33,528:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:33,551:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,589:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,615:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,641:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,667:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,697:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,726:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,750:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,776:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,801:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:33,810:INFO:Calculating mean and std
2025-10-29 12:29:33,811:INFO:Creating metrics dataframe
2025-10-29 12:29:33,813:INFO:Uploading results into container
2025-10-29 12:29:33,814:INFO:Uploading model into container now
2025-10-29 12:29:33,814:INFO:_master_model_container: 6
2025-10-29 12:29:33,814:INFO:_display_container: 2
2025-10-29 12:29:33,814:INFO:RidgeClassifier(alpha=1.0, class_weight=None, copy_X=True, fit_intercept=True,
                max_iter=None, positive=False, random_state=123, solver='auto',
                tol=0.0001)
2025-10-29 12:29:33,814:INFO:create_model() successfully completed......................................
2025-10-29 12:29:33,915:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:33,915:INFO:Creating metrics dataframe
2025-10-29 12:29:33,919:INFO:Initializing Random Forest Classifier
2025-10-29 12:29:33,919:INFO:Total runtime is 0.05415985186894735 minutes
2025-10-29 12:29:33,920:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:33,921:INFO:Initializing create_model()
2025-10-29 12:29:33,921:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=rf, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:33,921:INFO:Checking exceptions
2025-10-29 12:29:33,921:INFO:Importing libraries
2025-10-29 12:29:33,921:INFO:Copying training dataset
2025-10-29 12:29:33,925:INFO:Defining folds
2025-10-29 12:29:33,925:INFO:Declaring metric variables
2025-10-29 12:29:33,926:INFO:Importing untrained model
2025-10-29 12:29:33,926:INFO:Random Forest Classifier Imported successfully
2025-10-29 12:29:33,927:INFO:Starting cross validation
2025-10-29 12:29:33,928:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:36,204:INFO:Calculating mean and std
2025-10-29 12:29:36,205:INFO:Creating metrics dataframe
2025-10-29 12:29:36,207:INFO:Uploading results into container
2025-10-29 12:29:36,207:INFO:Uploading model into container now
2025-10-29 12:29:36,208:INFO:_master_model_container: 7
2025-10-29 12:29:36,208:INFO:_display_container: 2
2025-10-29 12:29:36,208:INFO:RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,
                       criterion='gini', max_depth=None, max_features='sqrt',
                       max_leaf_nodes=None, max_samples=None,
                       min_impurity_decrease=0.0, min_samples_leaf=1,
                       min_samples_split=2, min_weight_fraction_leaf=0.0,
                       monotonic_cst=None, n_estimators=100, n_jobs=1,
                       oob_score=False, random_state=123, verbose=0,
                       warm_start=False)
2025-10-29 12:29:36,208:INFO:create_model() successfully completed......................................
2025-10-29 12:29:36,318:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:36,318:INFO:Creating metrics dataframe
2025-10-29 12:29:36,322:INFO:Initializing Quadratic Discriminant Analysis
2025-10-29 12:29:36,322:INFO:Total runtime is 0.09421656529108682 minutes
2025-10-29 12:29:36,323:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:36,323:INFO:Initializing create_model()
2025-10-29 12:29:36,323:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=qda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:36,323:INFO:Checking exceptions
2025-10-29 12:29:36,323:INFO:Importing libraries
2025-10-29 12:29:36,323:INFO:Copying training dataset
2025-10-29 12:29:36,327:INFO:Defining folds
2025-10-29 12:29:36,327:INFO:Declaring metric variables
2025-10-29 12:29:36,327:INFO:Importing untrained model
2025-10-29 12:29:36,327:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-29 12:29:36,328:INFO:Starting cross validation
2025-10-29 12:29:36,330:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:36,355:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,385:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,414:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,449:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,484:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,511:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,538:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,570:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,599:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,627:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,638:INFO:Calculating mean and std
2025-10-29 12:29:36,639:INFO:Creating metrics dataframe
2025-10-29 12:29:36,642:INFO:Uploading results into container
2025-10-29 12:29:36,642:INFO:Uploading model into container now
2025-10-29 12:29:36,643:INFO:_master_model_container: 8
2025-10-29 12:29:36,643:INFO:_display_container: 2
2025-10-29 12:29:36,643:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-29 12:29:36,643:INFO:create_model() successfully completed......................................
2025-10-29 12:29:36,747:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:36,747:INFO:Creating metrics dataframe
2025-10-29 12:29:36,750:INFO:Initializing Ada Boost Classifier
2025-10-29 12:29:36,750:INFO:Total runtime is 0.10134238004684447 minutes
2025-10-29 12:29:36,750:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:36,750:INFO:Initializing create_model()
2025-10-29 12:29:36,750:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=ada, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:36,750:INFO:Checking exceptions
2025-10-29 12:29:36,750:INFO:Importing libraries
2025-10-29 12:29:36,750:INFO:Copying training dataset
2025-10-29 12:29:36,754:INFO:Defining folds
2025-10-29 12:29:36,754:INFO:Declaring metric variables
2025-10-29 12:29:36,754:INFO:Importing untrained model
2025-10-29 12:29:36,755:INFO:Ada Boost Classifier Imported successfully
2025-10-29 12:29:36,755:INFO:Starting cross validation
2025-10-29 12:29:36,756:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:36,768:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:36,918:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:36,946:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:37,072:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:37,092:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:37,213:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:37,244:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:37,403:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:37,434:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:37,585:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:37,616:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:37,725:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:37,747:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:37,898:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:37,918:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:38,060:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:38,081:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:38,220:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:38,245:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\ensemble\_weight_boosting.py:519: FutureWarning: The SAMME.R algorithm (the default) is deprecated and will be removed in 1.6. Use the SAMME algorithm to circumvent this warning.
  warnings.warn(

2025-10-29 12:29:38,381:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:38,396:INFO:Calculating mean and std
2025-10-29 12:29:38,397:INFO:Creating metrics dataframe
2025-10-29 12:29:38,400:INFO:Uploading results into container
2025-10-29 12:29:38,400:INFO:Uploading model into container now
2025-10-29 12:29:38,400:INFO:_master_model_container: 9
2025-10-29 12:29:38,400:INFO:_display_container: 2
2025-10-29 12:29:38,401:INFO:AdaBoostClassifier(algorithm='SAMME.R', estimator=None, learning_rate=1.0,
                   n_estimators=50, random_state=123)
2025-10-29 12:29:38,401:INFO:create_model() successfully completed......................................
2025-10-29 12:29:38,507:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:38,507:INFO:Creating metrics dataframe
2025-10-29 12:29:38,510:INFO:Initializing Gradient Boosting Classifier
2025-10-29 12:29:38,510:INFO:Total runtime is 0.13068145910898843 minutes
2025-10-29 12:29:38,511:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:38,511:INFO:Initializing create_model()
2025-10-29 12:29:38,511:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=gbc, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:38,511:INFO:Checking exceptions
2025-10-29 12:29:38,511:INFO:Importing libraries
2025-10-29 12:29:38,511:INFO:Copying training dataset
2025-10-29 12:29:38,515:INFO:Defining folds
2025-10-29 12:29:38,515:INFO:Declaring metric variables
2025-10-29 12:29:38,515:INFO:Importing untrained model
2025-10-29 12:29:38,515:INFO:Gradient Boosting Classifier Imported successfully
2025-10-29 12:29:38,517:INFO:Starting cross validation
2025-10-29 12:29:38,518:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:38,862:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:39,268:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:39,728:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:40,196:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:40,618:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:40,971:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:41,268:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:41,612:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:41,914:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,212:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,221:INFO:Calculating mean and std
2025-10-29 12:29:42,222:INFO:Creating metrics dataframe
2025-10-29 12:29:42,224:INFO:Uploading results into container
2025-10-29 12:29:42,224:INFO:Uploading model into container now
2025-10-29 12:29:42,224:INFO:_master_model_container: 10
2025-10-29 12:29:42,225:INFO:_display_container: 2
2025-10-29 12:29:42,225:INFO:GradientBoostingClassifier(ccp_alpha=0.0, criterion='friedman_mse', init=None,
                           learning_rate=0.1, loss='log_loss', max_depth=3,
                           max_features=None, max_leaf_nodes=None,
                           min_impurity_decrease=0.0, min_samples_leaf=1,
                           min_samples_split=2, min_weight_fraction_leaf=0.0,
                           n_estimators=100, n_iter_no_change=None,
                           random_state=123, subsample=1.0, tol=0.0001,
                           validation_fraction=0.1, verbose=0,
                           warm_start=False)
2025-10-29 12:29:42,225:INFO:create_model() successfully completed......................................
2025-10-29 12:29:42,322:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:42,322:INFO:Creating metrics dataframe
2025-10-29 12:29:42,325:INFO:Initializing Linear Discriminant Analysis
2025-10-29 12:29:42,325:INFO:Total runtime is 0.1942671179771423 minutes
2025-10-29 12:29:42,325:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:42,326:INFO:Initializing create_model()
2025-10-29 12:29:42,326:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=lda, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:42,326:INFO:Checking exceptions
2025-10-29 12:29:42,326:INFO:Importing libraries
2025-10-29 12:29:42,326:INFO:Copying training dataset
2025-10-29 12:29:42,330:INFO:Defining folds
2025-10-29 12:29:42,330:INFO:Declaring metric variables
2025-10-29 12:29:42,330:INFO:Importing untrained model
2025-10-29 12:29:42,330:INFO:Linear Discriminant Analysis Imported successfully
2025-10-29 12:29:42,330:INFO:Starting cross validation
2025-10-29 12:29:42,331:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:42,351:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,376:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,401:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,426:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,456:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,487:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,516:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,550:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,574:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,599:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py:204: FitFailedWarning: Metric 'make_scorer(roc_auc_score, response_method=('decision_function', 'predict_proba'), average=weighted, multi_class=ovr)' failed and error score 0.0 has been returned instead. If this is a custom metric, this usually means that the error is in the metric code. Full exception below:
Traceback (most recent call last):
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 196, in _score
    return super()._score(
           ^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_scorer.py", line 350, in _score
    return self._sign * self._score_func(y_true, y_pred, **scoring_kwargs)
                        ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\metrics.py", line 144, in __call__
    return self.score_func(y_true, y_pred, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\utils\_param_validation.py", line 213, in wrapper
    return func(*args, **kwargs)
           ^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 634, in roc_auc_score
    return _multiclass_roc_auc_score(
           ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_ranking.py", line 707, in _multiclass_roc_auc_score
    raise ValueError(
ValueError: Target scores need to be probabilities for multiclass roc_auc, i.e. they should sum up to 1.0 over classes

  warnings.warn(

2025-10-29 12:29:42,610:INFO:Calculating mean and std
2025-10-29 12:29:42,611:INFO:Creating metrics dataframe
2025-10-29 12:29:42,614:INFO:Uploading results into container
2025-10-29 12:29:42,614:INFO:Uploading model into container now
2025-10-29 12:29:42,615:INFO:_master_model_container: 11
2025-10-29 12:29:42,615:INFO:_display_container: 2
2025-10-29 12:29:42,615:INFO:LinearDiscriminantAnalysis(covariance_estimator=None, n_components=None,
                           priors=None, shrinkage=None, solver='svd',
                           store_covariance=False, tol=0.0001)
2025-10-29 12:29:42,615:INFO:create_model() successfully completed......................................
2025-10-29 12:29:42,720:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:42,720:INFO:Creating metrics dataframe
2025-10-29 12:29:42,724:INFO:Initializing Extra Trees Classifier
2025-10-29 12:29:42,724:INFO:Total runtime is 0.2009072343508402 minutes
2025-10-29 12:29:42,725:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:42,725:INFO:Initializing create_model()
2025-10-29 12:29:42,725:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=et, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:42,725:INFO:Checking exceptions
2025-10-29 12:29:42,725:INFO:Importing libraries
2025-10-29 12:29:42,725:INFO:Copying training dataset
2025-10-29 12:29:42,728:INFO:Defining folds
2025-10-29 12:29:42,728:INFO:Declaring metric variables
2025-10-29 12:29:42,728:INFO:Importing untrained model
2025-10-29 12:29:42,729:INFO:Extra Trees Classifier Imported successfully
2025-10-29 12:29:42,729:INFO:Starting cross validation
2025-10-29 12:29:42,730:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:43,998:INFO:Calculating mean and std
2025-10-29 12:29:43,999:INFO:Creating metrics dataframe
2025-10-29 12:29:44,000:INFO:Uploading results into container
2025-10-29 12:29:44,001:INFO:Uploading model into container now
2025-10-29 12:29:44,001:INFO:_master_model_container: 12
2025-10-29 12:29:44,001:INFO:_display_container: 2
2025-10-29 12:29:44,002:INFO:ExtraTreesClassifier(bootstrap=False, ccp_alpha=0.0, class_weight=None,
                     criterion='gini', max_depth=None, max_features='sqrt',
                     max_leaf_nodes=None, max_samples=None,
                     min_impurity_decrease=0.0, min_samples_leaf=1,
                     min_samples_split=2, min_weight_fraction_leaf=0.0,
                     monotonic_cst=None, n_estimators=100, n_jobs=1,
                     oob_score=False, random_state=123, verbose=0,
                     warm_start=False)
2025-10-29 12:29:44,002:INFO:create_model() successfully completed......................................
2025-10-29 12:29:44,103:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:44,103:INFO:Creating metrics dataframe
2025-10-29 12:29:44,106:INFO:Initializing Light Gradient Boosting Machine
2025-10-29 12:29:44,106:INFO:Total runtime is 0.2239519079526265 minutes
2025-10-29 12:29:44,106:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:44,106:INFO:Initializing create_model()
2025-10-29 12:29:44,106:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=lightgbm, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:44,106:INFO:Checking exceptions
2025-10-29 12:29:44,106:INFO:Importing libraries
2025-10-29 12:29:44,106:INFO:Copying training dataset
2025-10-29 12:29:44,111:INFO:Defining folds
2025-10-29 12:29:44,112:INFO:Declaring metric variables
2025-10-29 12:29:44,112:INFO:Importing untrained model
2025-10-29 12:29:44,113:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-29 12:29:44,113:INFO:Starting cross validation
2025-10-29 12:29:44,114:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:45,088:INFO:Calculating mean and std
2025-10-29 12:29:45,089:INFO:Creating metrics dataframe
2025-10-29 12:29:45,090:INFO:Uploading results into container
2025-10-29 12:29:45,091:INFO:Uploading model into container now
2025-10-29 12:29:45,091:INFO:_master_model_container: 13
2025-10-29 12:29:45,091:INFO:_display_container: 2
2025-10-29 12:29:45,092:INFO:LGBMClassifier(boosting_type='gbdt', class_weight=None, colsample_bytree=1.0,
               importance_type='split', learning_rate=0.1, max_depth=-1,
               min_child_samples=20, min_child_weight=0.001, min_split_gain=0.0,
               n_estimators=100, n_jobs=1, num_leaves=31, objective=None,
               random_state=123, reg_alpha=0.0, reg_lambda=0.0, subsample=1.0,
               subsample_for_bin=200000, subsample_freq=0)
2025-10-29 12:29:45,092:INFO:create_model() successfully completed......................................
2025-10-29 12:29:45,189:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:45,190:INFO:Creating metrics dataframe
2025-10-29 12:29:45,192:INFO:Initializing Dummy Classifier
2025-10-29 12:29:45,192:INFO:Total runtime is 0.24205511808395383 minutes
2025-10-29 12:29:45,193:INFO:SubProcess create_model() called ==================================
2025-10-29 12:29:45,193:INFO:Initializing create_model()
2025-10-29 12:29:45,193:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=dummy, fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1D33F90>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:45,193:INFO:Checking exceptions
2025-10-29 12:29:45,193:INFO:Importing libraries
2025-10-29 12:29:45,193:INFO:Copying training dataset
2025-10-29 12:29:45,196:INFO:Defining folds
2025-10-29 12:29:45,197:INFO:Declaring metric variables
2025-10-29 12:29:45,197:INFO:Importing untrained model
2025-10-29 12:29:45,197:INFO:Dummy Classifier Imported successfully
2025-10-29 12:29:45,197:INFO:Starting cross validation
2025-10-29 12:29:45,198:INFO:Cross validating with StratifiedKFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:29:45,223:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,250:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,279:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,312:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,338:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,370:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,396:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,421:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,444:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,468:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\metrics\_classification.py:1509: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.
  _warn_prf(average, modifier, f"{metric.capitalize()} is", len(result))

2025-10-29 12:29:45,474:INFO:Calculating mean and std
2025-10-29 12:29:45,475:INFO:Creating metrics dataframe
2025-10-29 12:29:45,477:INFO:Uploading results into container
2025-10-29 12:29:45,478:INFO:Uploading model into container now
2025-10-29 12:29:45,479:INFO:_master_model_container: 14
2025-10-29 12:29:45,479:INFO:_display_container: 2
2025-10-29 12:29:45,479:INFO:DummyClassifier(constant=None, random_state=123, strategy='prior')
2025-10-29 12:29:45,479:INFO:create_model() successfully completed......................................
2025-10-29 12:29:45,605:INFO:SubProcess create_model() end ==================================
2025-10-29 12:29:45,605:INFO:Creating metrics dataframe
2025-10-29 12:29:45,609:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-29 12:29:45,612:INFO:Initializing create_model()
2025-10-29 12:29:45,612:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:45,612:INFO:Checking exceptions
2025-10-29 12:29:45,613:INFO:Importing libraries
2025-10-29 12:29:45,614:INFO:Copying training dataset
2025-10-29 12:29:45,618:INFO:Defining folds
2025-10-29 12:29:45,619:INFO:Declaring metric variables
2025-10-29 12:29:45,619:INFO:Importing untrained model
2025-10-29 12:29:45,619:INFO:Declaring custom model
2025-10-29 12:29:45,620:INFO:Logistic Regression Imported successfully
2025-10-29 12:29:45,622:INFO:Cross validation set to False
2025-10-29 12:29:45,622:INFO:Fitting Model
2025-10-29 12:29:45,644:INFO:LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False)
2025-10-29 12:29:45,644:INFO:create_model() successfully completed......................................
2025-10-29 12:29:45,749:INFO:Initializing create_model()
2025-10-29 12:29:45,749:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform'), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:45,750:INFO:Checking exceptions
2025-10-29 12:29:45,751:INFO:Importing libraries
2025-10-29 12:29:45,751:INFO:Copying training dataset
2025-10-29 12:29:45,755:INFO:Defining folds
2025-10-29 12:29:45,755:INFO:Declaring metric variables
2025-10-29 12:29:45,755:INFO:Importing untrained model
2025-10-29 12:29:45,755:INFO:Declaring custom model
2025-10-29 12:29:45,755:INFO:K Neighbors Classifier Imported successfully
2025-10-29 12:29:45,756:INFO:Cross validation set to False
2025-10-29 12:29:45,756:INFO:Fitting Model
2025-10-29 12:29:45,766:INFO:KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform')
2025-10-29 12:29:45,766:INFO:create_model() successfully completed......................................
2025-10-29 12:29:45,866:INFO:Initializing create_model()
2025-10-29 12:29:45,866:INFO:create_model(self=<pycaret.classification.oop.ClassificationExperiment object at 0x0000018780082010>, estimator=QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001), fold=StratifiedKFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:29:45,866:INFO:Checking exceptions
2025-10-29 12:29:45,867:INFO:Importing libraries
2025-10-29 12:29:45,867:INFO:Copying training dataset
2025-10-29 12:29:45,871:INFO:Defining folds
2025-10-29 12:29:45,872:INFO:Declaring metric variables
2025-10-29 12:29:45,872:INFO:Importing untrained model
2025-10-29 12:29:45,872:INFO:Declaring custom model
2025-10-29 12:29:45,872:INFO:Quadratic Discriminant Analysis Imported successfully
2025-10-29 12:29:45,873:INFO:Cross validation set to False
2025-10-29 12:29:45,873:INFO:Fitting Model
2025-10-29 12:29:45,881:INFO:QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)
2025-10-29 12:29:45,881:INFO:create_model() successfully completed......................................
2025-10-29 12:29:46,010:INFO:_master_model_container: 14
2025-10-29 12:29:46,010:INFO:_display_container: 2
2025-10-29 12:29:46,010:INFO:[LogisticRegression(C=1.0, class_weight=None, dual=False, fit_intercept=True,
                   intercept_scaling=1, l1_ratio=None, max_iter=1000,
                   multi_class='auto', n_jobs=None, penalty='l2',
                   random_state=123, solver='lbfgs', tol=0.0001, verbose=0,
                   warm_start=False), KNeighborsClassifier(algorithm='auto', leaf_size=30, metric='minkowski',
                     metric_params=None, n_jobs=1, n_neighbors=5, p=2,
                     weights='uniform'), QuadraticDiscriminantAnalysis(priors=None, reg_param=0.0,
                              store_covariance=False, tol=0.0001)]
2025-10-29 12:29:46,010:INFO:compare_models() successfully completed......................................
2025-10-29 12:30:46,263:INFO:PyCaret RegressionExperiment
2025-10-29 12:30:46,263:INFO:Logging name: reg-default-name
2025-10-29 12:30:46,263:INFO:ML Usecase: MLUsecase.REGRESSION
2025-10-29 12:30:46,263:INFO:version 3.3.2
2025-10-29 12:30:46,263:INFO:Initializing setup()
2025-10-29 12:30:46,263:INFO:self.USI: dad2
2025-10-29 12:30:46,263:INFO:self._variable_keys: {'gpu_param', 'target_param', 'logging_param', 'y_train', 'exp_name_log', '_ml_usecase', 'X', 'y_test', 'fold_shuffle_param', 'gpu_n_jobs_param', 'seed', '_available_plots', 'y', 'fold_generator', 'transform_target_param', 'USI', 'exp_id', 'pipeline', 'n_jobs_param', 'fold_groups_param', 'memory', 'idx', 'X_train', 'X_test', 'html_param', 'data', 'log_plots_param'}
2025-10-29 12:30:46,263:INFO:Checking environment
2025-10-29 12:30:46,263:INFO:python_version: 3.11.14
2025-10-29 12:30:46,263:INFO:python_build: ('main', 'Oct 21 2025 18:30:03')
2025-10-29 12:30:46,263:INFO:machine: AMD64
2025-10-29 12:30:46,263:INFO:platform: Windows-10-10.0.26100-SP0
2025-10-29 12:30:46,265:INFO:Memory: svmem(total=16788250624, available=3480657920, percent=79.3, used=13307592704, free=3480657920)
2025-10-29 12:30:46,265:INFO:Physical Core: 12
2025-10-29 12:30:46,265:INFO:Logical Core: 16
2025-10-29 12:30:46,265:INFO:Checking libraries
2025-10-29 12:30:46,265:INFO:System:
2025-10-29 12:30:46,267:INFO:    python: 3.11.14 | packaged by Anaconda, Inc. | (main, Oct 21 2025, 18:30:03) [MSC v.1929 64 bit (AMD64)]
2025-10-29 12:30:46,269:INFO:executable: C:\Users\slast\miniconda3\envs\features\python.exe
2025-10-29 12:30:46,271:INFO:   machine: Windows-10-10.0.26100-SP0
2025-10-29 12:30:46,271:INFO:PyCaret required dependencies:
2025-10-29 12:30:46,271:INFO:                 pip: 25.2
2025-10-29 12:30:46,271:INFO:          setuptools: 80.9.0
2025-10-29 12:30:46,271:INFO:             pycaret: 3.3.2
2025-10-29 12:30:46,271:INFO:             IPython: 9.6.0
2025-10-29 12:30:46,271:INFO:          ipywidgets: 8.1.7
2025-10-29 12:30:46,273:INFO:                tqdm: 4.67.1
2025-10-29 12:30:46,273:INFO:               numpy: 1.26.4
2025-10-29 12:30:46,273:INFO:              pandas: 2.1.4
2025-10-29 12:30:46,273:INFO:              jinja2: 3.1.6
2025-10-29 12:30:46,275:INFO:               scipy: 1.11.4
2025-10-29 12:30:46,275:INFO:              joblib: 1.3.2
2025-10-29 12:30:46,275:INFO:             sklearn: 1.4.2
2025-10-29 12:30:46,275:INFO:                pyod: 2.0.5
2025-10-29 12:30:46,275:INFO:            imblearn: 0.14.0
2025-10-29 12:30:46,275:INFO:   category_encoders: 2.7.0
2025-10-29 12:30:46,275:INFO:            lightgbm: 4.6.0
2025-10-29 12:30:46,275:INFO:               numba: 0.62.1
2025-10-29 12:30:46,275:INFO:            requests: 2.32.5
2025-10-29 12:30:46,275:INFO:          matplotlib: 3.10.7
2025-10-29 12:30:46,277:INFO:          scikitplot: 0.3.7
2025-10-29 12:30:46,278:INFO:         yellowbrick: 1.5
2025-10-29 12:30:46,280:INFO:              plotly: 6.3.1
2025-10-29 12:30:46,280:INFO:    plotly-resampler: Not installed
2025-10-29 12:30:46,280:INFO:             kaleido: 0.2.1
2025-10-29 12:30:46,280:INFO:           schemdraw: 0.15
2025-10-29 12:30:46,280:INFO:         statsmodels: 0.14.5
2025-10-29 12:30:46,280:INFO:              sktime: 0.26.0
2025-10-29 12:30:46,280:INFO:               tbats: 1.1.3
2025-10-29 12:30:46,281:INFO:            pmdarima: 2.0.4
2025-10-29 12:30:46,281:INFO:              psutil: 7.1.1
2025-10-29 12:30:46,281:INFO:          markupsafe: 3.0.3
2025-10-29 12:30:46,281:INFO:             pickle5: Not installed
2025-10-29 12:30:46,281:INFO:         cloudpickle: 3.1.1
2025-10-29 12:30:46,281:INFO:         deprecation: 2.1.0
2025-10-29 12:30:46,281:INFO:              xxhash: 3.6.0
2025-10-29 12:30:46,281:INFO:           wurlitzer: 3.1.1
2025-10-29 12:30:46,281:INFO:PyCaret optional dependencies:
2025-10-29 12:30:46,281:INFO:                shap: Not installed
2025-10-29 12:30:46,281:INFO:           interpret: Not installed
2025-10-29 12:30:46,281:INFO:                umap: 0.5.9.post2
2025-10-29 12:30:46,281:INFO:     ydata_profiling: Not installed
2025-10-29 12:30:46,281:INFO:  explainerdashboard: Not installed
2025-10-29 12:30:46,281:INFO:             autoviz: Not installed
2025-10-29 12:30:46,281:INFO:           fairlearn: Not installed
2025-10-29 12:30:46,283:INFO:          deepchecks: Not installed
2025-10-29 12:30:46,283:INFO:             xgboost: Not installed
2025-10-29 12:30:46,283:INFO:            catboost: Not installed
2025-10-29 12:30:46,283:INFO:              kmodes: Not installed
2025-10-29 12:30:46,283:INFO:             mlxtend: Not installed
2025-10-29 12:30:46,283:INFO:       statsforecast: Not installed
2025-10-29 12:30:46,283:INFO:        tune_sklearn: Not installed
2025-10-29 12:30:46,283:INFO:                 ray: Not installed
2025-10-29 12:30:46,285:INFO:            hyperopt: Not installed
2025-10-29 12:30:46,285:INFO:              optuna: Not installed
2025-10-29 12:30:46,285:INFO:               skopt: Not installed
2025-10-29 12:30:46,285:INFO:              mlflow: Not installed
2025-10-29 12:30:46,285:INFO:              gradio: Not installed
2025-10-29 12:30:46,285:INFO:             fastapi: Not installed
2025-10-29 12:30:46,285:INFO:             uvicorn: Not installed
2025-10-29 12:30:46,286:INFO:              m2cgen: Not installed
2025-10-29 12:30:46,287:INFO:           evidently: Not installed
2025-10-29 12:30:46,288:INFO:               fugue: Not installed
2025-10-29 12:30:46,288:INFO:           streamlit: 1.50.0
2025-10-29 12:30:46,288:INFO:             prophet: Not installed
2025-10-29 12:30:46,288:INFO:None
2025-10-29 12:30:46,288:INFO:Set up data.
2025-10-29 12:30:46,299:INFO:Set up folding strategy.
2025-10-29 12:30:46,299:INFO:Set up train/test split.
2025-10-29 12:30:46,317:INFO:Set up index.
2025-10-29 12:30:46,317:INFO:Assigning column types.
2025-10-29 12:30:46,322:INFO:Engine successfully changes for model 'lr' to 'sklearn'.
2025-10-29 12:30:46,322:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,328:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,333:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,398:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,455:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,456:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,456:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,457:INFO:Engine for model 'lasso' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,462:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,468:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,544:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,602:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,603:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,603:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,603:INFO:Engine successfully changes for model 'lasso' to 'sklearn'.
2025-10-29 12:30:46,609:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,615:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,686:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,736:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,737:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,738:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,742:INFO:Engine for model 'ridge' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,748:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,814:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,867:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,867:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,868:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:46,868:INFO:Engine successfully changes for model 'ridge' to 'sklearn'.
2025-10-29 12:30:46,880:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-29 12:30:46,953:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,004:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,005:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,006:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,015:INFO:Engine for model 'en' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,090:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,147:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,148:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,149:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,150:INFO:Engine successfully changes for model 'en' to 'sklearn'.
2025-10-29 12:30:47,252:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,307:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,308:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,308:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,384:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,446:INFO:Engine for model 'knn' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,447:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,447:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,448:INFO:Engine successfully changes for model 'knn' to 'sklearn'.
2025-10-29 12:30:47,541:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,589:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,589:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,676:INFO:Engine for model 'svm' has not been set explicitly, hence returning None.
2025-10-29 12:30:47,731:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,731:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,732:INFO:Engine successfully changes for model 'svm' to 'sklearn'.
2025-10-29 12:30:47,876:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:47,877:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,049:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,050:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,052:INFO:Preparing preprocessing pipeline...
2025-10-29 12:30:48,052:INFO:Set up simple imputation.
2025-10-29 12:30:48,056:INFO:Set up encoding of categorical features.
2025-10-29 12:30:48,057:INFO:Set up column name cleaning.
2025-10-29 12:30:48,152:INFO:Finished creating preprocessing pipeline.
2025-10-29 12:30:48,159:INFO:Pipeline: Pipeline(memory=FastMemory(location=C:\Users\slast\AppData\Local\Temp\joblib),
         steps=[('numerical_imputer',
                 TransformerWrapper(include=['Year', 'GDP', 'Social support',
                                             'Healthy life expectancy at birth',
                                             'Freedom to make life choices',
                                             'Generosity',
                                             'Perceptions of corruption',
                                             'Positive affect',
                                             'Negative affect'],
                                    transformer=SimpleImputer())),
                ('categorical_imputer',
                 TransformerWrapper(include=['Country name'],
                                    transformer=SimpleImputer(strategy='most_frequent'))),
                ('rest_encoding',
                 TransformerWrapper(include=['Country name'],
                                    transformer=TargetEncoder(cols=['Country '
                                                                    'name'],
                                                              handle_missing='return_nan'))),
                ('clean_column_names',
                 TransformerWrapper(transformer=CleanColumnNames()))])
2025-10-29 12:30:48,159:INFO:Creating final display dataframe.
2025-10-29 12:30:48,405:INFO:Setup _display_container:                     Description             Value
0                    Session id               123
1                        Target   Happiness Score
2                   Target type        Regression
3           Original data shape        (2363, 11)
4        Transformed data shape        (2363, 11)
5   Transformed train set shape        (1654, 11)
6    Transformed test set shape         (709, 11)
7              Numeric features                 9
8          Categorical features                 1
9      Rows with missing values             11.3%
10                   Preprocess              True
11              Imputation type            simple
12           Numeric imputation              mean
13       Categorical imputation              mode
14     Maximum one-hot encoding                25
15              Encoding method              None
16               Fold Generator             KFold
17                  Fold Number                10
18                     CPU Jobs                 1
19                      Use GPU             False
20               Log Experiment             False
21              Experiment Name  reg-default-name
22                          USI              dad2
2025-10-29 12:30:48,522:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,524:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,644:WARNING:
'xgboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install xgboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,645:WARNING:
'catboost' is a soft dependency and not included in the pycaret installation. Please run: `pip install catboost` to install.
Alternately, you can install this by running `pip install pycaret[models]`
2025-10-29 12:30:48,646:INFO:setup() successfully completed in 2.39s...............
2025-10-29 12:30:48,646:INFO:Initializing compare_models()
2025-10-29 12:30:48,646:INFO:compare_models(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, include=None, exclude=None, fold=None, round=4, cross_validation=True, sort=R2, n_select=3, budget_time=None, turbo=True, errors=ignore, fit_kwargs=None, groups=None, experiment_custom_tags=None, probability_threshold=None, verbose=True, parallel=None, caller_params={'self': <pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, 'include': None, 'exclude': None, 'fold': None, 'round': 4, 'cross_validation': True, 'sort': 'R2', 'n_select': 3, 'budget_time': None, 'turbo': True, 'errors': 'ignore', 'fit_kwargs': None, 'groups': None, 'experiment_custom_tags': None, 'engine': None, 'verbose': True, 'parallel': None, '__class__': <class 'pycaret.regression.oop.RegressionExperiment'>})
2025-10-29 12:30:48,646:INFO:Checking exceptions
2025-10-29 12:30:48,648:INFO:Preparing display monitor
2025-10-29 12:30:48,651:INFO:Initializing Linear Regression
2025-10-29 12:30:48,651:INFO:Total runtime is 0.0 minutes
2025-10-29 12:30:48,651:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:48,651:INFO:Initializing create_model()
2025-10-29 12:30:48,651:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=lr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:48,651:INFO:Checking exceptions
2025-10-29 12:30:48,651:INFO:Importing libraries
2025-10-29 12:30:48,651:INFO:Copying training dataset
2025-10-29 12:30:48,656:INFO:Defining folds
2025-10-29 12:30:48,656:INFO:Declaring metric variables
2025-10-29 12:30:48,657:INFO:Importing untrained model
2025-10-29 12:30:48,657:INFO:Linear Regression Imported successfully
2025-10-29 12:30:48,657:INFO:Starting cross validation
2025-10-29 12:30:48,658:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:49,391:INFO:Calculating mean and std
2025-10-29 12:30:49,392:INFO:Creating metrics dataframe
2025-10-29 12:30:49,395:INFO:Uploading results into container
2025-10-29 12:30:49,396:INFO:Uploading model into container now
2025-10-29 12:30:49,396:INFO:_master_model_container: 1
2025-10-29 12:30:49,396:INFO:_display_container: 2
2025-10-29 12:30:49,397:INFO:LinearRegression(n_jobs=1)
2025-10-29 12:30:49,397:INFO:create_model() successfully completed......................................
2025-10-29 12:30:49,568:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:49,569:INFO:Creating metrics dataframe
2025-10-29 12:30:49,572:INFO:Initializing Lasso Regression
2025-10-29 12:30:49,572:INFO:Total runtime is 0.015355229377746582 minutes
2025-10-29 12:30:49,572:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:49,572:INFO:Initializing create_model()
2025-10-29 12:30:49,572:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=lasso, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:49,572:INFO:Checking exceptions
2025-10-29 12:30:49,572:INFO:Importing libraries
2025-10-29 12:30:49,573:INFO:Copying training dataset
2025-10-29 12:30:49,584:INFO:Defining folds
2025-10-29 12:30:49,584:INFO:Declaring metric variables
2025-10-29 12:30:49,584:INFO:Importing untrained model
2025-10-29 12:30:49,584:INFO:Lasso Regression Imported successfully
2025-10-29 12:30:49,584:INFO:Starting cross validation
2025-10-29 12:30:49,585:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:50,241:INFO:Calculating mean and std
2025-10-29 12:30:50,242:INFO:Creating metrics dataframe
2025-10-29 12:30:50,243:INFO:Uploading results into container
2025-10-29 12:30:50,244:INFO:Uploading model into container now
2025-10-29 12:30:50,244:INFO:_master_model_container: 2
2025-10-29 12:30:50,244:INFO:_display_container: 2
2025-10-29 12:30:50,245:INFO:Lasso(random_state=123)
2025-10-29 12:30:50,245:INFO:create_model() successfully completed......................................
2025-10-29 12:30:50,349:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:50,349:INFO:Creating metrics dataframe
2025-10-29 12:30:50,353:INFO:Initializing Ridge Regression
2025-10-29 12:30:50,353:INFO:Total runtime is 0.02837266524632772 minutes
2025-10-29 12:30:50,353:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:50,354:INFO:Initializing create_model()
2025-10-29 12:30:50,354:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=ridge, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:50,354:INFO:Checking exceptions
2025-10-29 12:30:50,354:INFO:Importing libraries
2025-10-29 12:30:50,354:INFO:Copying training dataset
2025-10-29 12:30:50,361:INFO:Defining folds
2025-10-29 12:30:50,361:INFO:Declaring metric variables
2025-10-29 12:30:50,362:INFO:Importing untrained model
2025-10-29 12:30:50,363:INFO:Ridge Regression Imported successfully
2025-10-29 12:30:50,363:INFO:Starting cross validation
2025-10-29 12:30:50,364:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:50,929:INFO:Calculating mean and std
2025-10-29 12:30:50,931:INFO:Creating metrics dataframe
2025-10-29 12:30:50,933:INFO:Uploading results into container
2025-10-29 12:30:50,933:INFO:Uploading model into container now
2025-10-29 12:30:50,934:INFO:_master_model_container: 3
2025-10-29 12:30:50,934:INFO:_display_container: 2
2025-10-29 12:30:50,934:INFO:Ridge(random_state=123)
2025-10-29 12:30:50,934:INFO:create_model() successfully completed......................................
2025-10-29 12:30:51,030:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:51,032:INFO:Creating metrics dataframe
2025-10-29 12:30:51,035:INFO:Initializing Elastic Net
2025-10-29 12:30:51,035:INFO:Total runtime is 0.03972529172897339 minutes
2025-10-29 12:30:51,035:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:51,036:INFO:Initializing create_model()
2025-10-29 12:30:51,036:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=en, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:51,036:INFO:Checking exceptions
2025-10-29 12:30:51,036:INFO:Importing libraries
2025-10-29 12:30:51,036:INFO:Copying training dataset
2025-10-29 12:30:51,039:INFO:Defining folds
2025-10-29 12:30:51,041:INFO:Declaring metric variables
2025-10-29 12:30:51,041:INFO:Importing untrained model
2025-10-29 12:30:51,041:INFO:Elastic Net Imported successfully
2025-10-29 12:30:51,042:INFO:Starting cross validation
2025-10-29 12:30:51,042:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:51,759:INFO:Calculating mean and std
2025-10-29 12:30:51,759:INFO:Creating metrics dataframe
2025-10-29 12:30:51,764:INFO:Uploading results into container
2025-10-29 12:30:51,765:INFO:Uploading model into container now
2025-10-29 12:30:51,766:INFO:_master_model_container: 4
2025-10-29 12:30:51,767:INFO:_display_container: 2
2025-10-29 12:30:51,768:INFO:ElasticNet(random_state=123)
2025-10-29 12:30:51,768:INFO:create_model() successfully completed......................................
2025-10-29 12:30:51,912:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:51,912:INFO:Creating metrics dataframe
2025-10-29 12:30:51,916:INFO:Initializing Least Angle Regression
2025-10-29 12:30:51,916:INFO:Total runtime is 0.05441617568333944 minutes
2025-10-29 12:30:51,917:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:51,917:INFO:Initializing create_model()
2025-10-29 12:30:51,917:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=lar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:51,917:INFO:Checking exceptions
2025-10-29 12:30:51,917:INFO:Importing libraries
2025-10-29 12:30:51,917:INFO:Copying training dataset
2025-10-29 12:30:51,926:INFO:Defining folds
2025-10-29 12:30:51,926:INFO:Declaring metric variables
2025-10-29 12:30:51,926:INFO:Importing untrained model
2025-10-29 12:30:51,927:INFO:Least Angle Regression Imported successfully
2025-10-29 12:30:51,927:INFO:Starting cross validation
2025-10-29 12:30:51,929:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:52,731:INFO:Calculating mean and std
2025-10-29 12:30:52,732:INFO:Creating metrics dataframe
2025-10-29 12:30:52,735:INFO:Uploading results into container
2025-10-29 12:30:52,736:INFO:Uploading model into container now
2025-10-29 12:30:52,736:INFO:_master_model_container: 5
2025-10-29 12:30:52,736:INFO:_display_container: 2
2025-10-29 12:30:52,737:INFO:Lars(random_state=123)
2025-10-29 12:30:52,737:INFO:create_model() successfully completed......................................
2025-10-29 12:30:52,880:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:52,880:INFO:Creating metrics dataframe
2025-10-29 12:30:52,886:INFO:Initializing Lasso Least Angle Regression
2025-10-29 12:30:52,886:INFO:Total runtime is 0.07059083779652914 minutes
2025-10-29 12:30:52,887:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:52,887:INFO:Initializing create_model()
2025-10-29 12:30:52,887:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=llar, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:52,887:INFO:Checking exceptions
2025-10-29 12:30:52,887:INFO:Importing libraries
2025-10-29 12:30:52,887:INFO:Copying training dataset
2025-10-29 12:30:52,896:INFO:Defining folds
2025-10-29 12:30:52,896:INFO:Declaring metric variables
2025-10-29 12:30:52,896:INFO:Importing untrained model
2025-10-29 12:30:52,897:INFO:Lasso Least Angle Regression Imported successfully
2025-10-29 12:30:52,897:INFO:Starting cross validation
2025-10-29 12:30:52,899:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:53,579:INFO:Calculating mean and std
2025-10-29 12:30:53,581:INFO:Creating metrics dataframe
2025-10-29 12:30:53,582:INFO:Uploading results into container
2025-10-29 12:30:53,582:INFO:Uploading model into container now
2025-10-29 12:30:53,583:INFO:_master_model_container: 6
2025-10-29 12:30:53,583:INFO:_display_container: 2
2025-10-29 12:30:53,583:INFO:LassoLars(random_state=123)
2025-10-29 12:30:53,583:INFO:create_model() successfully completed......................................
2025-10-29 12:30:53,692:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:53,692:INFO:Creating metrics dataframe
2025-10-29 12:30:53,698:INFO:Initializing Orthogonal Matching Pursuit
2025-10-29 12:30:53,698:INFO:Total runtime is 0.08411225477854412 minutes
2025-10-29 12:30:53,698:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:53,699:INFO:Initializing create_model()
2025-10-29 12:30:53,699:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=omp, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:53,699:INFO:Checking exceptions
2025-10-29 12:30:53,699:INFO:Importing libraries
2025-10-29 12:30:53,699:INFO:Copying training dataset
2025-10-29 12:30:53,707:INFO:Defining folds
2025-10-29 12:30:53,707:INFO:Declaring metric variables
2025-10-29 12:30:53,707:INFO:Importing untrained model
2025-10-29 12:30:53,708:INFO:Orthogonal Matching Pursuit Imported successfully
2025-10-29 12:30:53,708:INFO:Starting cross validation
2025-10-29 12:30:53,709:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:54,249:INFO:Calculating mean and std
2025-10-29 12:30:54,250:INFO:Creating metrics dataframe
2025-10-29 12:30:54,251:INFO:Uploading results into container
2025-10-29 12:30:54,253:INFO:Uploading model into container now
2025-10-29 12:30:54,253:INFO:_master_model_container: 7
2025-10-29 12:30:54,253:INFO:_display_container: 2
2025-10-29 12:30:54,253:INFO:OrthogonalMatchingPursuit()
2025-10-29 12:30:54,253:INFO:create_model() successfully completed......................................
2025-10-29 12:30:54,359:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:54,359:INFO:Creating metrics dataframe
2025-10-29 12:30:54,362:INFO:Initializing Bayesian Ridge
2025-10-29 12:30:54,362:INFO:Total runtime is 0.09518966674804688 minutes
2025-10-29 12:30:54,363:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:54,363:INFO:Initializing create_model()
2025-10-29 12:30:54,363:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=br, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:54,363:INFO:Checking exceptions
2025-10-29 12:30:54,363:INFO:Importing libraries
2025-10-29 12:30:54,363:INFO:Copying training dataset
2025-10-29 12:30:54,367:INFO:Defining folds
2025-10-29 12:30:54,368:INFO:Declaring metric variables
2025-10-29 12:30:54,368:INFO:Importing untrained model
2025-10-29 12:30:54,368:INFO:Bayesian Ridge Imported successfully
2025-10-29 12:30:54,368:INFO:Starting cross validation
2025-10-29 12:30:54,369:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:54,963:INFO:Calculating mean and std
2025-10-29 12:30:54,965:INFO:Creating metrics dataframe
2025-10-29 12:30:54,966:INFO:Uploading results into container
2025-10-29 12:30:54,967:INFO:Uploading model into container now
2025-10-29 12:30:54,967:INFO:_master_model_container: 8
2025-10-29 12:30:54,967:INFO:_display_container: 2
2025-10-29 12:30:54,967:INFO:BayesianRidge()
2025-10-29 12:30:54,967:INFO:create_model() successfully completed......................................
2025-10-29 12:30:55,078:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:55,078:INFO:Creating metrics dataframe
2025-10-29 12:30:55,081:INFO:Initializing Passive Aggressive Regressor
2025-10-29 12:30:55,081:INFO:Total runtime is 0.10716627836227417 minutes
2025-10-29 12:30:55,082:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:55,082:INFO:Initializing create_model()
2025-10-29 12:30:55,082:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=par, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:55,082:INFO:Checking exceptions
2025-10-29 12:30:55,082:INFO:Importing libraries
2025-10-29 12:30:55,082:INFO:Copying training dataset
2025-10-29 12:30:55,087:INFO:Defining folds
2025-10-29 12:30:55,087:INFO:Declaring metric variables
2025-10-29 12:30:55,087:INFO:Importing untrained model
2025-10-29 12:30:55,087:INFO:Passive Aggressive Regressor Imported successfully
2025-10-29 12:30:55,088:INFO:Starting cross validation
2025-10-29 12:30:55,089:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:55,896:INFO:Calculating mean and std
2025-10-29 12:30:55,896:INFO:Creating metrics dataframe
2025-10-29 12:30:55,900:INFO:Uploading results into container
2025-10-29 12:30:55,901:INFO:Uploading model into container now
2025-10-29 12:30:55,901:INFO:_master_model_container: 9
2025-10-29 12:30:55,901:INFO:_display_container: 2
2025-10-29 12:30:55,901:INFO:PassiveAggressiveRegressor(random_state=123)
2025-10-29 12:30:55,901:INFO:create_model() successfully completed......................................
2025-10-29 12:30:56,043:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:56,044:INFO:Creating metrics dataframe
2025-10-29 12:30:56,049:INFO:Initializing Huber Regressor
2025-10-29 12:30:56,049:INFO:Total runtime is 0.1233009139696757 minutes
2025-10-29 12:30:56,049:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:56,049:INFO:Initializing create_model()
2025-10-29 12:30:56,049:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=huber, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:56,049:INFO:Checking exceptions
2025-10-29 12:30:56,051:INFO:Importing libraries
2025-10-29 12:30:56,051:INFO:Copying training dataset
2025-10-29 12:30:56,060:INFO:Defining folds
2025-10-29 12:30:56,060:INFO:Declaring metric variables
2025-10-29 12:30:56,060:INFO:Importing untrained model
2025-10-29 12:30:56,061:INFO:Huber Regressor Imported successfully
2025-10-29 12:30:56,061:INFO:Starting cross validation
2025-10-29 12:30:56,063:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:56,287:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:56,452:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:56,646:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:56,790:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:56,963:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:57,208:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:57,464:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:57,617:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:57,816:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:58,034:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\sklearn\linear_model\_huber.py:342: ConvergenceWarning: lbfgs failed to converge (status=1):
STOP: TOTAL NO. of ITERATIONS REACHED LIMIT.

Increase the number of iterations (max_iter) or scale the data as shown in:
    https://scikit-learn.org/stable/modules/preprocessing.html
  self.n_iter_ = _check_optimize_result("lbfgs", opt_res, self.max_iter)

2025-10-29 12:30:58,052:INFO:Calculating mean and std
2025-10-29 12:30:58,052:INFO:Creating metrics dataframe
2025-10-29 12:30:58,054:INFO:Uploading results into container
2025-10-29 12:30:58,054:INFO:Uploading model into container now
2025-10-29 12:30:58,055:INFO:_master_model_container: 10
2025-10-29 12:30:58,055:INFO:_display_container: 2
2025-10-29 12:30:58,055:INFO:HuberRegressor()
2025-10-29 12:30:58,055:INFO:create_model() successfully completed......................................
2025-10-29 12:30:58,181:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:58,181:INFO:Creating metrics dataframe
2025-10-29 12:30:58,186:INFO:Initializing K Neighbors Regressor
2025-10-29 12:30:58,186:INFO:Total runtime is 0.158911927541097 minutes
2025-10-29 12:30:58,187:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:58,187:INFO:Initializing create_model()
2025-10-29 12:30:58,187:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=knn, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:58,187:INFO:Checking exceptions
2025-10-29 12:30:58,187:INFO:Importing libraries
2025-10-29 12:30:58,187:INFO:Copying training dataset
2025-10-29 12:30:58,196:INFO:Defining folds
2025-10-29 12:30:58,196:INFO:Declaring metric variables
2025-10-29 12:30:58,196:INFO:Importing untrained model
2025-10-29 12:30:58,197:INFO:K Neighbors Regressor Imported successfully
2025-10-29 12:30:58,197:INFO:Starting cross validation
2025-10-29 12:30:58,198:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:58,876:INFO:Calculating mean and std
2025-10-29 12:30:58,877:INFO:Creating metrics dataframe
2025-10-29 12:30:58,878:INFO:Uploading results into container
2025-10-29 12:30:58,879:INFO:Uploading model into container now
2025-10-29 12:30:58,879:INFO:_master_model_container: 11
2025-10-29 12:30:58,879:INFO:_display_container: 2
2025-10-29 12:30:58,879:INFO:KNeighborsRegressor(n_jobs=1)
2025-10-29 12:30:58,879:INFO:create_model() successfully completed......................................
2025-10-29 12:30:59,006:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:59,007:INFO:Creating metrics dataframe
2025-10-29 12:30:59,012:INFO:Initializing Decision Tree Regressor
2025-10-29 12:30:59,012:INFO:Total runtime is 0.1726777195930481 minutes
2025-10-29 12:30:59,012:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:59,013:INFO:Initializing create_model()
2025-10-29 12:30:59,013:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=dt, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:59,013:INFO:Checking exceptions
2025-10-29 12:30:59,013:INFO:Importing libraries
2025-10-29 12:30:59,013:INFO:Copying training dataset
2025-10-29 12:30:59,018:INFO:Defining folds
2025-10-29 12:30:59,018:INFO:Declaring metric variables
2025-10-29 12:30:59,018:INFO:Importing untrained model
2025-10-29 12:30:59,019:INFO:Decision Tree Regressor Imported successfully
2025-10-29 12:30:59,019:INFO:Starting cross validation
2025-10-29 12:30:59,020:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:30:59,832:INFO:Calculating mean and std
2025-10-29 12:30:59,833:INFO:Creating metrics dataframe
2025-10-29 12:30:59,836:INFO:Uploading results into container
2025-10-29 12:30:59,836:INFO:Uploading model into container now
2025-10-29 12:30:59,837:INFO:_master_model_container: 12
2025-10-29 12:30:59,837:INFO:_display_container: 2
2025-10-29 12:30:59,837:INFO:DecisionTreeRegressor(random_state=123)
2025-10-29 12:30:59,837:INFO:create_model() successfully completed......................................
2025-10-29 12:30:59,942:INFO:SubProcess create_model() end ==================================
2025-10-29 12:30:59,942:INFO:Creating metrics dataframe
2025-10-29 12:30:59,946:INFO:Initializing Random Forest Regressor
2025-10-29 12:30:59,946:INFO:Total runtime is 0.18824657599131267 minutes
2025-10-29 12:30:59,946:INFO:SubProcess create_model() called ==================================
2025-10-29 12:30:59,946:INFO:Initializing create_model()
2025-10-29 12:30:59,947:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=rf, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:30:59,947:INFO:Checking exceptions
2025-10-29 12:30:59,947:INFO:Importing libraries
2025-10-29 12:30:59,947:INFO:Copying training dataset
2025-10-29 12:30:59,953:INFO:Defining folds
2025-10-29 12:30:59,953:INFO:Declaring metric variables
2025-10-29 12:30:59,954:INFO:Importing untrained model
2025-10-29 12:30:59,954:INFO:Random Forest Regressor Imported successfully
2025-10-29 12:30:59,955:INFO:Starting cross validation
2025-10-29 12:30:59,956:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:31:25,793:INFO:Calculating mean and std
2025-10-29 12:31:25,794:INFO:Creating metrics dataframe
2025-10-29 12:31:25,794:INFO:Uploading results into container
2025-10-29 12:31:25,794:INFO:Uploading model into container now
2025-10-29 12:31:25,794:INFO:_master_model_container: 13
2025-10-29 12:31:25,794:INFO:_display_container: 2
2025-10-29 12:31:25,794:INFO:RandomForestRegressor(n_jobs=1, random_state=123)
2025-10-29 12:31:25,794:INFO:create_model() successfully completed......................................
2025-10-29 12:31:25,911:INFO:SubProcess create_model() end ==================================
2025-10-29 12:31:25,911:INFO:Creating metrics dataframe
2025-10-29 12:31:25,914:INFO:Initializing Extra Trees Regressor
2025-10-29 12:31:25,914:INFO:Total runtime is 0.621050735314687 minutes
2025-10-29 12:31:25,914:INFO:SubProcess create_model() called ==================================
2025-10-29 12:31:25,914:INFO:Initializing create_model()
2025-10-29 12:31:25,914:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=et, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:25,914:INFO:Checking exceptions
2025-10-29 12:31:25,914:INFO:Importing libraries
2025-10-29 12:31:25,914:INFO:Copying training dataset
2025-10-29 12:31:25,920:INFO:Defining folds
2025-10-29 12:31:25,920:INFO:Declaring metric variables
2025-10-29 12:31:25,920:INFO:Importing untrained model
2025-10-29 12:31:25,920:INFO:Extra Trees Regressor Imported successfully
2025-10-29 12:31:25,920:INFO:Starting cross validation
2025-10-29 12:31:25,920:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:31:33,553:INFO:  Stopping...
2025-10-29 12:31:36,499:INFO:Calculating mean and std
2025-10-29 12:31:36,500:INFO:Creating metrics dataframe
2025-10-29 12:31:36,502:INFO:Uploading results into container
2025-10-29 12:31:36,502:INFO:Uploading model into container now
2025-10-29 12:31:36,502:INFO:_master_model_container: 14
2025-10-29 12:31:36,502:INFO:_display_container: 2
2025-10-29 12:31:36,502:INFO:ExtraTreesRegressor(n_jobs=1, random_state=123)
2025-10-29 12:31:36,502:INFO:create_model() successfully completed......................................
2025-10-29 12:31:36,623:INFO:SubProcess create_model() end ==================================
2025-10-29 12:31:36,623:INFO:Creating metrics dataframe
2025-10-29 12:31:36,625:INFO:Initializing AdaBoost Regressor
2025-10-29 12:31:36,625:INFO:Total runtime is 0.7995718916257222 minutes
2025-10-29 12:31:36,625:INFO:SubProcess create_model() called ==================================
2025-10-29 12:31:36,627:INFO:Initializing create_model()
2025-10-29 12:31:36,627:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=ada, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:36,627:INFO:Checking exceptions
2025-10-29 12:31:36,627:INFO:Importing libraries
2025-10-29 12:31:36,627:INFO:Copying training dataset
2025-10-29 12:31:36,630:INFO:Defining folds
2025-10-29 12:31:36,630:INFO:Declaring metric variables
2025-10-29 12:31:36,630:INFO:Importing untrained model
2025-10-29 12:31:36,630:INFO:AdaBoost Regressor Imported successfully
2025-10-29 12:31:36,630:INFO:Starting cross validation
2025-10-29 12:31:36,630:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:31:40,202:INFO:Calculating mean and std
2025-10-29 12:31:40,207:INFO:Creating metrics dataframe
2025-10-29 12:31:40,210:INFO:Uploading results into container
2025-10-29 12:31:40,210:INFO:Uploading model into container now
2025-10-29 12:31:40,210:INFO:_master_model_container: 15
2025-10-29 12:31:40,210:INFO:_display_container: 2
2025-10-29 12:31:40,210:INFO:AdaBoostRegressor(random_state=123)
2025-10-29 12:31:40,210:INFO:create_model() successfully completed......................................
2025-10-29 12:31:40,370:INFO:SubProcess create_model() end ==================================
2025-10-29 12:31:40,370:INFO:Creating metrics dataframe
2025-10-29 12:31:40,376:INFO:Initializing Gradient Boosting Regressor
2025-10-29 12:31:40,376:INFO:Total runtime is 0.8620790123939513 minutes
2025-10-29 12:31:40,376:INFO:SubProcess create_model() called ==================================
2025-10-29 12:31:40,376:INFO:Initializing create_model()
2025-10-29 12:31:40,376:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=gbr, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:40,376:INFO:Checking exceptions
2025-10-29 12:31:40,376:INFO:Importing libraries
2025-10-29 12:31:40,376:INFO:Copying training dataset
2025-10-29 12:31:40,385:INFO:Defining folds
2025-10-29 12:31:40,385:INFO:Declaring metric variables
2025-10-29 12:31:40,385:INFO:Importing untrained model
2025-10-29 12:31:40,385:INFO:Gradient Boosting Regressor Imported successfully
2025-10-29 12:31:40,387:INFO:Starting cross validation
2025-10-29 12:31:40,387:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:31:49,307:INFO:Calculating mean and std
2025-10-29 12:31:49,307:INFO:Creating metrics dataframe
2025-10-29 12:31:49,311:INFO:Uploading results into container
2025-10-29 12:31:49,311:INFO:Uploading model into container now
2025-10-29 12:31:49,311:INFO:_master_model_container: 16
2025-10-29 12:31:49,311:INFO:_display_container: 2
2025-10-29 12:31:49,311:INFO:GradientBoostingRegressor(random_state=123)
2025-10-29 12:31:49,311:INFO:create_model() successfully completed......................................
2025-10-29 12:31:49,420:INFO:SubProcess create_model() end ==================================
2025-10-29 12:31:49,420:INFO:Creating metrics dataframe
2025-10-29 12:31:49,427:INFO:Initializing Light Gradient Boosting Machine
2025-10-29 12:31:49,427:INFO:Total runtime is 1.0129379987716673 minutes
2025-10-29 12:31:49,427:INFO:SubProcess create_model() called ==================================
2025-10-29 12:31:49,427:INFO:Initializing create_model()
2025-10-29 12:31:49,427:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=lightgbm, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:49,427:INFO:Checking exceptions
2025-10-29 12:31:49,427:INFO:Importing libraries
2025-10-29 12:31:49,427:INFO:Copying training dataset
2025-10-29 12:31:49,433:INFO:Defining folds
2025-10-29 12:31:49,433:INFO:Declaring metric variables
2025-10-29 12:31:49,433:INFO:Importing untrained model
2025-10-29 12:31:49,435:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-29 12:31:49,435:INFO:Starting cross validation
2025-10-29 12:31:49,435:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:31:51,141:INFO:Calculating mean and std
2025-10-29 12:31:51,141:INFO:Creating metrics dataframe
2025-10-29 12:31:51,141:INFO:Uploading results into container
2025-10-29 12:31:51,141:INFO:Uploading model into container now
2025-10-29 12:31:51,141:INFO:_master_model_container: 17
2025-10-29 12:31:51,141:INFO:_display_container: 2
2025-10-29 12:31:51,141:INFO:LGBMRegressor(n_jobs=1, random_state=123)
2025-10-29 12:31:51,141:INFO:create_model() successfully completed......................................
2025-10-29 12:31:51,315:INFO:SubProcess create_model() end ==================================
2025-10-29 12:31:51,315:INFO:Creating metrics dataframe
2025-10-29 12:31:51,321:INFO:Initializing Dummy Regressor
2025-10-29 12:31:51,321:INFO:Total runtime is 1.0444921135902403 minutes
2025-10-29 12:31:51,321:INFO:SubProcess create_model() called ==================================
2025-10-29 12:31:51,321:INFO:Initializing create_model()
2025-10-29 12:31:51,321:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=dummy, fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=True, predict=True, fit_kwargs={}, groups=None, refit=False, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=<pycaret.internal.display.display.CommonDisplay object at 0x00000187C1EDF210>, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:51,321:INFO:Checking exceptions
2025-10-29 12:31:51,321:INFO:Importing libraries
2025-10-29 12:31:51,321:INFO:Copying training dataset
2025-10-29 12:31:51,331:INFO:Defining folds
2025-10-29 12:31:51,331:INFO:Declaring metric variables
2025-10-29 12:31:51,331:INFO:Importing untrained model
2025-10-29 12:31:51,331:INFO:Dummy Regressor Imported successfully
2025-10-29 12:31:51,331:INFO:Starting cross validation
2025-10-29 12:31:51,334:INFO:Cross validating with KFold(n_splits=10, random_state=None, shuffle=False), n_jobs=1
2025-10-29 12:31:51,822:INFO:Calculating mean and std
2025-10-29 12:31:51,822:INFO:Creating metrics dataframe
2025-10-29 12:31:51,822:INFO:Uploading results into container
2025-10-29 12:31:51,822:INFO:Uploading model into container now
2025-10-29 12:31:51,822:INFO:_master_model_container: 18
2025-10-29 12:31:51,822:INFO:_display_container: 2
2025-10-29 12:31:51,822:INFO:DummyRegressor()
2025-10-29 12:31:51,822:INFO:create_model() successfully completed......................................
2025-10-29 12:31:51,927:INFO:SubProcess create_model() end ==================================
2025-10-29 12:31:51,927:INFO:Creating metrics dataframe
2025-10-29 12:31:51,930:WARNING:C:\Users\slast\miniconda3\envs\features\Lib\site-packages\pycaret\internal\pycaret_experiment\supervised_experiment.py:339: FutureWarning: Styler.applymap has been deprecated. Use Styler.map instead.
  .applymap(highlight_cols, subset=["TT (Sec)"])

2025-10-29 12:31:51,932:INFO:Initializing create_model()
2025-10-29 12:31:51,934:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=ExtraTreesRegressor(n_jobs=1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:51,934:INFO:Checking exceptions
2025-10-29 12:31:51,936:INFO:Importing libraries
2025-10-29 12:31:51,936:INFO:Copying training dataset
2025-10-29 12:31:51,938:INFO:Defining folds
2025-10-29 12:31:51,940:INFO:Declaring metric variables
2025-10-29 12:31:51,940:INFO:Importing untrained model
2025-10-29 12:31:51,940:INFO:Declaring custom model
2025-10-29 12:31:51,940:INFO:Extra Trees Regressor Imported successfully
2025-10-29 12:31:51,941:INFO:Cross validation set to False
2025-10-29 12:31:51,941:INFO:Fitting Model
2025-10-29 12:31:52,810:INFO:ExtraTreesRegressor(n_jobs=1, random_state=123)
2025-10-29 12:31:52,810:INFO:create_model() successfully completed......................................
2025-10-29 12:31:52,921:INFO:Initializing create_model()
2025-10-29 12:31:52,921:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=LGBMRegressor(n_jobs=1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:52,921:INFO:Checking exceptions
2025-10-29 12:31:52,921:INFO:Importing libraries
2025-10-29 12:31:52,921:INFO:Copying training dataset
2025-10-29 12:31:52,936:INFO:Defining folds
2025-10-29 12:31:52,936:INFO:Declaring metric variables
2025-10-29 12:31:52,936:INFO:Importing untrained model
2025-10-29 12:31:52,936:INFO:Declaring custom model
2025-10-29 12:31:52,943:INFO:Light Gradient Boosting Machine Imported successfully
2025-10-29 12:31:52,945:INFO:Cross validation set to False
2025-10-29 12:31:52,945:INFO:Fitting Model
2025-10-29 12:31:53,108:INFO:LGBMRegressor(n_jobs=1, random_state=123)
2025-10-29 12:31:53,108:INFO:create_model() successfully completed......................................
2025-10-29 12:31:53,220:INFO:Initializing create_model()
2025-10-29 12:31:53,220:INFO:create_model(self=<pycaret.regression.oop.RegressionExperiment object at 0x00000187C0679ED0>, estimator=RandomForestRegressor(n_jobs=1, random_state=123), fold=KFold(n_splits=10, random_state=None, shuffle=False), round=4, cross_validation=False, predict=False, fit_kwargs={}, groups=None, refit=True, probability_threshold=None, experiment_custom_tags=None, verbose=False, system=False, add_to_model_list=True, metrics=None, display=None, model_only=True, return_train_score=False, error_score=0.0, kwargs={})
2025-10-29 12:31:53,220:INFO:Checking exceptions
2025-10-29 12:31:53,220:INFO:Importing libraries
2025-10-29 12:31:53,220:INFO:Copying training dataset
2025-10-29 12:31:53,238:INFO:Defining folds
2025-10-29 12:31:53,238:INFO:Declaring metric variables
2025-10-29 12:31:53,238:INFO:Importing untrained model
2025-10-29 12:31:53,238:INFO:Declaring custom model
2025-10-29 12:31:53,238:INFO:Random Forest Regressor Imported successfully
2025-10-29 12:31:53,240:INFO:Cross validation set to False
2025-10-29 12:31:53,240:INFO:Fitting Model
2025-10-29 12:31:55,240:INFO:RandomForestRegressor(n_jobs=1, random_state=123)
2025-10-29 12:31:55,240:INFO:create_model() successfully completed......................................
2025-10-29 12:31:55,389:INFO:_master_model_container: 18
2025-10-29 12:31:55,389:INFO:_display_container: 2
2025-10-29 12:31:55,389:INFO:[ExtraTreesRegressor(n_jobs=1, random_state=123), LGBMRegressor(n_jobs=1, random_state=123), RandomForestRegressor(n_jobs=1, random_state=123)]
2025-10-29 12:31:55,389:INFO:compare_models() successfully completed......................................
